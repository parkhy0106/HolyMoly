{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINALFINALFINALFINALFINALFINALFINALFINAL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wsvuO-csm3UT",
        "N8GjIeVAwZRj",
        "2USx2T_HNWHl",
        "o_K-3zfGoyaY",
        "oMJc5Sh3zRbs",
        "dFUgNBP-z1IU",
        "oxjYdTkwz5FW"
      ],
      "authorship_tag": "ABX9TyPF/wjwQyueU3IbGHg1Ko1h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkhy0106/HolyMoly/blob/master/Autogluon-credit-score%2BEDA/FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJVTJKbmXW6"
      },
      "source": [
        "#Environment SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2sZqi_imb8C"
      },
      "source": [
        "##AutoGluonPreVersion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "01KeP2YSuX6e",
        "outputId": "49598850-6899-480a-ae1c-613d628830ab"
      },
      "source": [
        "# Uninstall mkl for faster neural-network training time\n",
        "!pip uninstall -y mkl\n",
        "# Upgrade pip to ensure the latest package versions are available\n",
        "!pip install -U pip\n",
        "# Upgrade setuptools to be compatible with namespace packages\n",
        "!pip install -U setuptools\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "# Install pre-release, frozen to a particual pre-release for stability\n",
        "!pip install --pre \"autogluon==0.0.16b20201214\"\n",
        "!pip install -U ipykernel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling mkl-2019.0:\n",
            "  Successfully uninstalled mkl-2019.0\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/6f/43037c7bcc8bd8ba7c9074256b1a11596daa15555808ec748048c1507f08/pip-21.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1.1\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (56.1.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-56.2.0-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 7.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 56.1.0\n",
            "    Uninstalling setuptools-56.1.0:\n",
            "      Successfully uninstalled setuptools-56.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed setuptools-56.2.0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet<2.0.0\n",
            "  Downloading mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9 MB 100 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting autogluon==0.0.16b20201214\n",
            "  Downloading autogluon-0.0.16b20201214-py3-none-any.whl (5.2 kB)\n",
            "Collecting autogluon.tabular==0.0.16b20201214\n",
            "  Downloading autogluon.tabular-0.0.16b20201214-py3-none-any.whl (309 kB)\n",
            "\u001b[K     |████████████████████████████████| 309 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting autogluon.text==0.0.16b20201214\n",
            "  Downloading autogluon.text-0.0.16b20201214-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 585 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon==0.0.16b20201214) (3.6.4)\n",
            "Collecting autogluon.mxnet==0.0.16b20201214\n",
            "  Downloading autogluon.mxnet-0.0.16b20201214-py3-none-any.whl (31 kB)\n",
            "Collecting autogluon.core==0.0.16b20201214\n",
            "  Downloading autogluon.core-0.0.16b20201214-py3-none-any.whl (242 kB)\n",
            "\u001b[K     |████████████████████████████████| 242 kB 30.2 MB/s \n",
            "\u001b[?25hCollecting autogluon.vision==0.0.16b20201214\n",
            "  Downloading autogluon.vision-0.0.16b20201214-py3-none-any.whl (18 kB)\n",
            "Collecting autogluon.extra==0.0.16b20201214\n",
            "  Downloading autogluon.extra-0.0.16b20201214-py3-none-any.whl (22 kB)\n",
            "Collecting distributed>=2.6.0\n",
            "  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.12.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.8.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (3.2.2)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (4.41.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.29.23)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.23.0)\n",
            "Collecting paramiko>=2.4\n",
            "  Downloading paramiko-2.7.2-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.1.5)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (5.1.1)\n",
            "Collecting ConfigSpace<=0.4.16\n",
            "  Downloading ConfigSpace-0.4.16.tar.gz (964 kB)\n",
            "\u001b[K     |████████████████████████████████| 964 kB 55.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.19.5)\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<1.5.0,>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.4.1)\n",
            "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.3.3)\n",
            "Requirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.22.2.post1)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.17.78-py2.py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (2.3.2)\n",
            "Collecting openml\n",
            "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 69.2 MB/s \n",
            "\u001b[?25hCollecting gluoncv==0.9.0\n",
            "  Downloading gluoncv-0.9.0-py2.py3-none-any.whl (997 kB)\n",
            "\u001b[K     |████████████████████████████████| 997 kB 58.1 MB/s \n",
            "\u001b[?25hCollecting Pillow<=6.2.1\n",
            "  Downloading Pillow-6.2.1-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 54.0 MB/s \n",
            "\u001b[?25hCollecting lightgbm<4.0,>=3.0\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 57.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (2.5.1)\n",
            "Collecting xgboost<1.3,>=1.2\n",
            "  Downloading xgboost-1.2.1-py3-none-manylinux2010_x86_64.whl (148.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 148.9 MB 82 kB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil<=5.7.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (5.4.8)\n",
            "Collecting catboost<0.25,>=0.23.0\n",
            "  Downloading catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 65.7 MB 20 kB/s \n",
            "\u001b[?25hCollecting autogluon-contrib-nlp\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 65.7 MB/s \n",
            "\u001b[?25hCollecting pyarrow<=1.0.0\n",
            "  Downloading pyarrow-1.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.2 MB 275 kB/s \n",
            "\u001b[?25hCollecting d8<1.0,>=0.0.2\n",
            "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
            "Collecting tensorboardx\n",
            "  Downloading tensorboardX-2.2-py2.py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 66.9 MB/s \n",
            "\u001b[?25hCollecting decord\n",
            "  Downloading decord-0.5.2-py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.1 MB 15.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.9.0->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv==0.9.0->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (3.13)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (4.4.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<=0.4.16->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.4.7)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (1.5.12)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.7.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.11.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.3.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (8.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (56.2.0)\n",
            "Collecting dask>=2.6.0\n",
            "  Downloading dask-2021.5.0-py3-none-any.whl (960 kB)\n",
            "\u001b[K     |████████████████████████████████| 960 kB 38.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle>=1.5.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (0.36.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx<3.0,>=2.3->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (4.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2018.9)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 3.1 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 26.4 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.20)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24,>=0.22.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.0.1)\n",
            "Collecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 29.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 41.4 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting flake8\n",
            "  Downloading flake8-3.9.2-py2.py3-none-any.whl (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (3.12.4)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 26.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (20.9)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (3.7.4.3)\n",
            "Collecting bokeh\n",
            "  Downloading bokeh-2.3.2rc1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 15.0 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 34.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1rc2.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 13.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1rc1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 102 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.1.dev1.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 16.1 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 152 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc4.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 18.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc3.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 52 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0rc2.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 12.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev14.tar.gz (10.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 22 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev13.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 17.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev12.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 15.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev11.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 20.3 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev10.tar.gz (10.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 8.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev9.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 15.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev8.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 83 kB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev7.tar.gz (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 5.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev5.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 23.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev3.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 9.0 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev2.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 8.4 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.3.0.dev1.tar.gz (9.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.3 MB 37.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.3.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 11.4 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.2.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 13.2 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.1.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 15.2 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 19.7 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc3.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 13.8 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc2.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 16.0 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0rc1.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 20.6 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev8.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 20.7 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev7.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 12.5 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev6.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 26.4 MB/s \n",
            "\u001b[?25h  Downloading bokeh-2.2.0.dev4.tar.gz (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->autogluon.extra==0.0.16b20201214->autogluon==0.0.16b20201214) (2.0.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.5.0,>=0.4.0\n",
            "  Downloading s3transfer-0.4.2-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.3 MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.78\n",
            "  Downloading botocore-1.20.78-py2.py3-none-any.whl (7.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5 MB 52.3 MB/s \n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 61.3 MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "  Downloading immutables-0.15-cp37-cp37m-manylinux1_x86_64.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (4.0.1)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting pyflakes<2.4.0,>=2.3.0\n",
            "  Downloading pyflakes-2.3.1-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.8.0,>=2.7.0\n",
            "  Downloading pycodestyle-2.7.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 791 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->flake8->autogluon-contrib-nlp->autogluon.text==0.0.16b20201214->autogluon==0.0.16b20201214) (3.4.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (2020.12.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3.1)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting minio\n",
            "  Downloading minio-7.0.3-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.25,>=0.23.0->autogluon.tabular==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (1.10.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (8.7.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon==0.0.16b20201214) (21.2.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.0.16b20201214->autogluon==0.0.16b20201214) (1.3)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.0.16b20201214->autogluon==0.0.16b20201214) (2.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: ConfigSpace, bokeh, contextvars, openml, liac-arff\n",
            "  Building wheel for ConfigSpace (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.16-cp37-cp37m-linux_x86_64.whl size=2866438 sha256=e02b9a308df33029fbeca3be6cd7f2ffa58162a460da487f95d7b18b558d4ef0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/d8/3f/9d2d97b19d7ee91c9ec915c8432cd0ec1d85d54cb02e33847c\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-2.2.0.dev4-py3-none-any.whl size=9259741 sha256=0ee586cff48dc620f0191188d41ae9b01e840203e24e592bfe749b93ed42bb11\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/38/11/cd7736e6c7a978720593bf4c21438514eb2221f613954e6aa8\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=ae3f76dd8fc1bf402345863a90ab3d3efa3b6904db193b6b09f22d9c6f748482\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137326 sha256=59de25aabeb8c1c43aa2c23e7b6f62bfceec8f59eea167f08bf9303e9563d085\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=34a45a301ac1023514bf829dad913e946b131799a40d26caa24ff745048e5964\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built ConfigSpace bokeh contextvars openml liac-arff\n",
            "Installing collected packages: urllib3, locket, jmespath, partd, fsspec, cloudpickle, botocore, s3transfer, pynacl, pyaml, dask, cryptography, bcrypt, xmltodict, scikit-optimize, pyflakes, pycodestyle, pyarrow, portalocker, paramiko, minio, mccabe, liac-arff, immutables, distributed, ConfigSpace, boto3, yacs, xxhash, tokenizers, tensorboardx, sentencepiece, sacremoses, sacrebleu, Pillow, openml, flake8, decord, contextvars, autogluon.core, autocfg, xgboost, lightgbm, gluoncv, d8, catboost, bokeh, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.tabular, autogluon.extra, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 2.3.2\n",
            "    Uninstalling bokeh-2.3.2:\n",
            "      Successfully uninstalled bokeh-2.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.11.3 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 2.2.0.dev4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.16 Pillow-6.2.1 autocfg-0.0.8 autogluon-0.0.16b20201214 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.0.16b20201214 autogluon.extra-0.0.16b20201214 autogluon.mxnet-0.0.16b20201214 autogluon.tabular-0.0.16b20201214 autogluon.text-0.0.16b20201214 autogluon.vision-0.0.16b20201214 bcrypt-3.2.0 bokeh-2.2.0.dev4 boto3-1.17.78 botocore-1.20.78 catboost-0.24.4 cloudpickle-1.6.0 contextvars-2.4 cryptography-3.4.7 d8-0.0.2.post0 dask-2021.5.0 decord-0.5.2 distributed-2021.5.0 flake8-3.9.2 fsspec-2021.5.0 gluoncv-0.9.0 immutables-0.15 jmespath-0.10.0 liac-arff-2.5.0 lightgbm-3.2.1 locket-0.2.1 mccabe-0.6.1 minio-7.0.3 openml-0.12.2 paramiko-2.7.2 partd-1.2.0 portalocker-2.0.0 pyaml-20.4.0 pyarrow-1.0.0 pycodestyle-2.7.0 pyflakes-2.3.1 pynacl-1.4.0 s3transfer-0.4.2 sacrebleu-1.5.1 sacremoses-0.0.45 scikit-optimize-0.8.1 sentencepiece-0.1.95 tensorboardx-2.2 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.2.1 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "contextvars",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (4.10.1)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.5.5-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 10.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.3.5)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.0.5)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (56.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (4.7.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (22.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel) (2.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=5.0.0->ipykernel) (0.7.0)\n",
            "Installing collected packages: ipykernel\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 4.10.1\n",
            "    Uninstalling ipykernel-4.10.1:\n",
            "      Successfully uninstalled ipykernel-4.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 5.5.5 which is incompatible.\u001b[0m\n",
            "Successfully installed ipykernel-5.5.5\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipykernel"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmmycfKJunwc",
        "outputId": "2930a345-7867-461d-a74c-b60efb436a45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amEZjPaSmiIj"
      },
      "source": [
        "##SDV(Need to be restarted and check numpy version which is 1.20)\n",
        "######_*NOT COMPATIBLE WITH TENSORFLOW AND PYTORCH_*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsvuO-csm3UT"
      },
      "source": [
        "##Auto preprossesing tool by Kaggler Sensei\n",
        "######(https://github.com/jeongyoonlee)현재 비활성화됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eurj6O9ev3Ca",
        "outputId": "9aa57002-2bee-45a4-d3d3-935f66a22c07"
      },
      "source": [
        "!git clone https://github.com/jeongyoonlee/Kaggler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Kaggler'...\n",
            "remote: Enumerating objects: 1392, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 1392 (delta 72), reused 70 (delta 32), pack-reused 1235\u001b[K\n",
            "Receiving objects: 100% (1392/1392), 2.07 MiB | 13.79 MiB/s, done.\n",
            "Resolving deltas: 100% (865/865), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qWTlH97mvzE"
      },
      "source": [
        "##My Own functions for This competition(굉장히 편협한 코드. 시간이 없어서 모듈화 못 함)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wW-nExlHde8q"
      },
      "source": [
        "directory = '/content/drive/MyDrive/mtfk/%~dp0/open/'\n",
        "index = 'index'\n",
        "import pandas as pd\n",
        "train = pd.read_csv(directory+\"train.csv\",index_col=index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlxJg2c7vOao"
      },
      "source": [
        "NaN=train['occyp_type'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqruI4H-vIIA"
      },
      "source": [
        "def adj_col(a):\n",
        "  a['occyp_type'] = a['occyp_type'].replace(NaN,'others')\n",
        "  a = a.drop('FLAG_MOBIL',axis=1)\n",
        "  a['begin_month'] = -a['begin_month']*30\n",
        "  \n",
        "  for x in a.index:\n",
        "    if a['DAYS_EMPLOYED'][x] == 365243:\n",
        "      a['occyp_type'][x] = 'beksu'\n",
        "      a[\"DAYS_EMPLOYED\"][x] = 0\n",
        "  a[\"DAYS_EMPLOYED\"] = -a[\"DAYS_EMPLOYED\"]\n",
        "  a[\"DAYS_BIRTH\"] = -a[\"DAYS_BIRTH\"]\n",
        " \n",
        " \n",
        "  return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiBGBNGIvRbr"
      },
      "source": [
        "def split_col(a,b,num):\n",
        " trains=[]\n",
        " c=[]\n",
        " e=[]\n",
        " f=[]\n",
        " for x in a[b].unique():\n",
        "  if len(x) >= num:\n",
        "   print(x)\n",
        "   trains.append(a[a[b]==x])\n",
        "   e.append(x)\n",
        "  else:\n",
        "   c.append(a[a[b]==x])\n",
        "   f.append(x)\n",
        " d = pd.concat(c)\n",
        " trains.append(d)\n",
        " e.append(f)\n",
        " return (trains, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aUwtLCEvTl0"
      },
      "source": [
        "def models(a):\n",
        "  d = []\n",
        "  e = []\n",
        "  f = []\n",
        "  for x in range(len(a)):\n",
        "    b = a[x].sample(int(len(a[x])/10))\n",
        "    c = a[x].drop(b.index)\n",
        "    fit_args = {'train_data': c, 'label': 'credit'}    \n",
        "    d.append(task.fit(**fit_args))\n",
        "    e.append(d[x].evaluate(b))\n",
        "    d[x].persist_models()\n",
        "    d[x].refit_full()\n",
        "    d[x].distill()\n",
        "    f.append(d[x].leaderboard(b, silent=True))\n",
        "  return (d,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr5cKkEXxY28"
      },
      "source": [
        "def fold(a, n):\n",
        "  b = []\n",
        "  c = int(len(a)/n)\n",
        "  for x in range(n-1):\n",
        "    b.append(a.sample(c))\n",
        "    a = a.drop(b[x].index)\n",
        "  b.append(a)\n",
        "  return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw8727_mLIOR"
      },
      "source": [
        "def fold_models(a):\n",
        "  b = a\n",
        "  d = []\n",
        "  e = []\n",
        "  f = []\n",
        "  for x in range(len(b)):\n",
        "    c = pd.concat(a).drop(b[x].index)\n",
        "    fit_args = {'train_data': c, 'label': 'credit'}    \n",
        "    d.append(task.fit(**fit_args,output_directory='/contect/Autogluon',eval_metric='log_loss'))\n",
        "    e.append(d[x].evaluate(b[x]))\n",
        "    d[x].persist_models()\n",
        "    d[x].refit_full()\n",
        "    #d[x].distill()\n",
        "    f.append(d[x].leaderboard(b[x], silent=True))\n",
        "  return (d,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43q1GG1OGz1J"
      },
      "source": [
        "def check_duplicate(df, *args):\n",
        "  check_list = list(set(df.columns.tolist())- set(args))\n",
        "  \n",
        "  # 중복되는 데이터 모두 저장하는 데이터 프레임  [boolean Seires]\n",
        "  dup_pair_df = df.duplicated(subset=check_list, keep=False) # 모든 중복 샘플을 모두 True 처리 \n",
        "  \n",
        "  sum_dup = dup_pair_df.sum()# 중복 데이터 개수 확인\n",
        "  print(f\"{args}을(를) 제외하고 중복되는 데이터 개수는\", sum_dup, \"입니다\")\n",
        "  \n",
        "\n",
        "  # 중복이 있을 경우 해당 데이터들의 index 반환\n",
        "  if dup_pair_df.sum() != 0:\n",
        "    print(\"중복 데이터 비율:\", round((sum_dup/len(df)*100),2))\n",
        "    print()\n",
        "    return df.loc[dup_pair_df].index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8-8iaMdNnAV"
      },
      "source": [
        "def group_same(df):\n",
        "  a = 0\n",
        "  b = []\n",
        "  c = []\n",
        "  for x in df['DAYS_BIRTH'].unique():\n",
        "    for y in df['income_total'].unique():\n",
        "      a = df[df['DAYS_BIRTH']==x]\n",
        "      if a.sum !=0:\n",
        "        pass\n",
        "      b.append(a[a['income_total']==y])\n",
        "      #출생일과 수입이 같으면 중복데이터라고 처리하기(너무 많은 값을 검사하면 시간이 오래 걸리고\n",
        "      #그렇다고 query를 쓰자고 하니 코드 중복이 많아져서 디버깅하는 시간이 부족한 나에게는 모자람.)\n",
        "      #라고해서 막 짰더니 실행속도가 너무 느려짐\n",
        "  for x in range(len(b)):\n",
        "    if len(b[x])!= 0:\n",
        "      c.append(x)\n",
        "  d = [] \n",
        "  for x in c:\n",
        "    d.append(b[x])\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USkhWZ1inXtA"
      },
      "source": [
        "#MODULE LOADING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBGRVLWGv5bb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n51j2vhwA55"
      },
      "source": [
        "from autogluon.tabular import TabularPrediction as task"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4FF1VcgwHSZ"
      },
      "source": [
        "cd Kaggler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtnT2c4rwMkv"
      },
      "source": [
        "from kaggler.preprocessing import LabelEncoder\n",
        "from kaggler.model import AutoLGB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9-r8xhEwONj"
      },
      "source": [
        "import kaggler\n",
        "print(kaggler.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY6yVqYtyey2"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KzgzX5z52Kn"
      },
      "source": [
        "from sklearn.metrics import log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x62aeEK2whzQ"
      },
      "source": [
        "directory = '/content/drive/MyDrive/mtfk/%~dp0/open/'  # directory where you have downloaded the data CSV files from the competition\n",
        "label_column = 'credit'  # name of target variable to predict in this competition\n",
        "eval_metric = log_loss  # Optional: specify that competition evaluation metric is  Log_loss\n",
        "output_directory = '/content/drive/MyDrive/mtfk/results' \n",
        "index = 'index'\n",
        "target_col = 'credit'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx_IO36OrQ7i"
      },
      "source": [
        "# DATA PROCESS SECTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8GjIeVAwZRj"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjTzCmSawcas"
      },
      "source": [
        "train = pd.read_csv(directory+\"train.csv\",index_col=index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HUg5SUzw2Q_"
      },
      "source": [
        "test = pd.read_csv(directory+\"test.csv\",index_col=index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3gEA4MMw3oO"
      },
      "source": [
        "sub = pd.read_csv(directory+'sample_submission.csv', index_col=index) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRtb9xxanpZh"
      },
      "source": [
        "##Data Cleansing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLXrfiLKyl19",
        "outputId": "93fdfada-6b5a-497e-a4b7-9dc47918c635"
      },
      "source": [
        "train = adj_col(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_F1QYOczFX4",
        "outputId": "fbe875d3-857e-4468-90f1-e10d2a045147"
      },
      "source": [
        "test = adj_col(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_NocJ-ayxbM"
      },
      "source": [
        "nan을 beksu(days_employed가 0인)와 others(고용상태이긴 한 사람들)로 나누어 표기하고 Days_emplyed가 양수(365243)면 0으로 치환 후 부호 양수로 변화\n",
        "그 외에도 이런저런 처리를 추가할 수 있도록 함수화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XaHofXdFnwb"
      },
      "source": [
        "### Overlapped data controling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHjQ-Y2uGmSG"
      },
      "source": [
        "일단 아예 완전히 일치하는 데이터들을 드랍하는 처리를 한 후에"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX5BDO60GeQh"
      },
      "source": [
        "train.drop_duplicates(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzcH6MORfYuK"
      },
      "source": [
        "##################################여기서부터 시작#####################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcQ5qrzdHArU"
      },
      "source": [
        "온전히 일치하는데 credit값이 흔들리는 불안정한 객체들의 갯수를 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CFjksH_EWn4"
      },
      "source": [
        "train_c = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdxCw5unG537"
      },
      "source": [
        "train = train_c.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XulgYtt8G4S1",
        "outputId": "c7145b99-e6ec-43b6-f173-1b603824fb0f"
      },
      "source": [
        "check_duplicate(train_c, 'credit')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('credit',)을(를) 제외하고 중복되는 데이터 개수는 4497 입니다\n",
            "중복 데이터 비율: 17.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([    1,     2,    19,    21,    24,    25,    29,    34,    48,\n",
              "               50,\n",
              "            ...\n",
              "            26391, 26393, 26397, 26403, 26428, 26430, 26431, 26432, 26446,\n",
              "            26451],\n",
              "           dtype='int64', name='index', length=4497)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "EnO0a600Gs8O",
        "outputId": "76580180-12c7-4256-f311-19e43b94cd1a"
      },
      "source": [
        "credit_noise = train_c.loc[check_duplicate(train_c, 'credit')]\n",
        "credit_noise.query('income_total==247500.0').query('begin_month==150.0')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('credit',)을(를) 제외하고 중복되는 데이터 개수는 4497 입니다\n",
            "중복 데이터 비율: 17.0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>11380</td>\n",
              "      <td>1540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>11380</td>\n",
              "      <td>1540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender car reality  ...  family_size  begin_month credit\n",
              "index                     ...                                 \n",
              "1          F   N       Y  ...          3.0        150.0    1.0\n",
              "5167       F   N       Y  ...          3.0        150.0    0.0\n",
              "\n",
              "[2 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAIrrjbsKgwU"
      },
      "source": [
        "#train = train.drop(credit_noise.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW6k5DK73Mbh"
      },
      "source": [
        "드랍했더니 성능이 소폭 하락했다. 즉슨 무언가 데이터에 중요한 의미가 있다는 뜻."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klrT6QFyIlRY",
        "outputId": "9dc055e8-c3f5-4586-9e50-f9d5962fdd5a"
      },
      "source": [
        "credit_noise['credit'].value_counts(normalize=True).mul(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    61.685568\n",
              "1.0    24.193907\n",
              "0.0    14.120525\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGT9uaHqIth5"
      },
      "source": [
        "즉슨 너어무 드랍해버리고 싶지만... 신용등급이 너무 높으신 분들이 많다는 것이 문제였다. 즉 이상치라고만 처리하기엔 경향성 분석에 중요한 희귀값인 친구들이라는 뜻으로도 해석될 것 같다..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvUtR5-MGDoC"
      },
      "source": [
        "a = 0\n",
        "b = []\n",
        "c = []\n",
        "for x in credit_noise['DAYS_BIRTH'].unique():\n",
        "  for y in credit_noise['income_total'].unique():\n",
        "    a = credit_noise[credit_noise['DAYS_BIRTH']==x]\n",
        "    b.append(a[a['income_total']==y])\n",
        "    #출생일과 수입이 같으면 중복데이터라고 처리하기(너무 많은 값을 검사하면 시간이 오래 걸리고\n",
        "    #그렇다고 query를 쓰자고 하니 코드 중복이 많아져서 디버깅하는 시간이 부족한 나에게는 모자람.)\n",
        "for x in range(len(b)):\n",
        "  if len(b[x])!= 0:\n",
        "    c.append(x)\n",
        "d = [] \n",
        "for x in c:\n",
        "  d.append(b[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHCenYLwm71e",
        "outputId": "c118e53a-9f2b-4afd-97d2-d2ecb9f79bbe"
      },
      "source": [
        "d[2].credit.value_counts().index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Float64Index([1.0, 2.0], dtype='float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sct1VUEf7Et1"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyFHHd31Fr2Q"
      },
      "source": [
        "m = copy.deepcopy(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1RCdW-vJqPw"
      },
      "source": [
        "d = copy.deepcopy(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJi36o_1ms6s"
      },
      "source": [
        "for x in range(len(d)):\n",
        "  for y in reversed(d[x].credit.value_counts().index): #각 행의 credit 별 갯수를 카운트한 인덱스에서\n",
        "    bnk=0\n",
        "    mom = 0\n",
        "    if d[x].credit.value_counts()[y] > bnk: # 각 값의 갯수가 적어도 0보다는 크므로 갯수에 대해서\n",
        "      bnk = d[x].credit.value_counts()[y] # 전 인덱스의 값보다 더 크게 된다면\n",
        "      mom = y # 그 행의 값을 받아와서\n",
        "  d[x]['credit']= mom # 그 행에 대해 일괄적으로 가장 많은 값을 입력하라"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOTadx2vLDcc"
      },
      "source": [
        "최대한 데이터를 긍정적으로 평가해보았더니, 드랍한 것 보다 성능이 안 나왔다. ( 갯수 많은 중복이 있으면 그걸 선택하되, 동일하다면 좋은 쪽 선택 )\n",
        "\n",
        "최대한 부정적으로 데이터를 평가해보자.(갯수 많은 중복이 있으면 그걸 선택하되, 동일하다면 낮은 쪽 선택 ) -> 성능 소폭 개선됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gga3BTwJzdO"
      },
      "source": [
        "credit_distilled = pd.concat(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOxHHjG5J7L6"
      },
      "source": [
        "for x in credit_distilled.index:\n",
        "  train.loc[x] = credit_distilled.loc[x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_VrLcwPKVSR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2USx2T_HNWHl"
      },
      "source": [
        "###이제 begin_month를 기준으로 발생한 노이즈값들을 살펴볼 차례는 스킵~\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y2KyXJpNEd6",
        "outputId": "78c31c98-f21c-4b62-dca2-486b39d84e8c"
      },
      "source": [
        "begin_noise = train.loc[check_duplicate(train, 'begin_month')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('begin_month',)을(를) 제외하고 중복되는 데이터 개수는 20564 입니다\n",
            "중복 데이터 비율: 77.73\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iPhlJsYZ96j",
        "outputId": "f42511b4-a25d-41ef-e0a4-7c4180198232"
      },
      "source": [
        "begin_noise_t = test.loc[check_duplicate(test, 'begin_month')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('begin_month',)을(를) 제외하고 중복되는 데이터 개수는 6877 입니다\n",
            "중복 데이터 비율: 68.77\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6vyaAsqNTme"
      },
      "source": [
        "d = group_same(begin_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klzr8PK9aDNR"
      },
      "source": [
        "e = group_same(begin_noise_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj_vYKnARTYl",
        "outputId": "de73c5df-b7ae-48d5-c9cc-5431236f492a"
      },
      "source": [
        "len(d[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLb0jfPMR-0I"
      },
      "source": [
        "train['card_num'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUTdnplXSDkU"
      },
      "source": [
        "test['card_num'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9wR-F5nTPvI"
      },
      "source": [
        "여전히 중복데이터이긴 하나... 발급받은 카드의 갯수가 될 것이라고 가정하고 카드 갯수 feature을 추가해주었다. predictor가 중복데이터간의 연관성을 파악할 수 있게 도와줄 수 있을 것으로 도움을 주기 위해서가 주 목적으로, 중복데이터를 아예 없앴을 때 발생한 문제점을 해결하기 위한 것. -> 문제가 발생했는데, 성능이 대폭 하락한다. 예측 도중 성능은 상승하는데 이유를 잘 모르겠다. 테스트셋과 트레인셋이 다르게 배치 될 여지가 있어서 그런가? 그럴 수 있는건가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMbRXkWmQ2HJ"
      },
      "source": [
        "for x in range(len(d)):\n",
        "  awef =len(d[x])\n",
        "  d[x]['card_num'] = awef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdDM1VnVaWVt"
      },
      "source": [
        "awef = 0\n",
        "for x in range(len(e)):\n",
        "  awef =len(e[x])\n",
        "  e[x]['card_num'] = awef"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmvcMhXiSQMp"
      },
      "source": [
        "begin_distill = pd.concat(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcMy47n5abdu"
      },
      "source": [
        "begin_distill_t = pd.concat(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFLSR0_5S3Lo",
        "outputId": "7fb147af-c3de-4c04-ab52-5dca8c428c7f"
      },
      "source": [
        "begin_distill.index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([    0,  1773, 11402, 17641, 20389,     1,  2199,  5167,  9605,\n",
              "            12550,\n",
              "            ...\n",
              "            24925, 26295, 24997, 25404, 25131, 25681, 25569, 25736, 26328,\n",
              "            26345],\n",
              "           dtype='int64', name='index', length=20564)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnYOMeOeSb7Z"
      },
      "source": [
        "train.loc[begin_distill.index] = begin_distill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsxwCvz4agCk"
      },
      "source": [
        "test.loc[begin_distill_t.index] = begin_distill_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoX1F8zHrmnV"
      },
      "source": [
        "###Collecting Extreamly abnormal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "689rLn88s40T",
        "outputId": "24120e3c-184f-42a1-ef08-e678d091cde9"
      },
      "source": [
        "train[(train['family_size']-train['child_num'])<1]['credit'].value_counts(normalize=True).mul(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    100.0\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l2zZP19sWwB",
        "outputId": "4c6556f4-1208-448e-932e-7ee1502c8ff4"
      },
      "source": [
        "train[train['DAYS_EMPLOYED']==0][train[train['DAYS_EMPLOYED']==0]['DAYS_BIRTH']<16491]['credit'].value_counts(normalize=True).mul(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    61.25\n",
              "0.0    23.75\n",
              "1.0    15.00\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FVXuNGlvag6",
        "outputId": "91cb3045-0af1-42ca-c272-02dbaee6f03c"
      },
      "source": [
        "train['house_type'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Municipal apartment', 'House / apartment', 'With parents',\n",
              "       'Co-op apartment', 'Rented apartment', 'Office apartment'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bHQjBMTyROE"
      },
      "source": [
        "dun = train[train['reality']=='N'][train[train['reality']=='N']['house_type']=='With parents']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMdqMpT82uM8",
        "outputId": "b2dd882a-4686-4188-cd38-9e1195ade4b2"
      },
      "source": [
        "dun[dun['family_size']<2]['credit'].value_counts(normalize=True).mul(100) # 가족이랑 같이 산다고 그랬는데 가족 구성원이 본인 한 명"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    61.988304\n",
              "1.0    32.163743\n",
              "0.0     5.847953\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1FYe4v03Apd",
        "outputId": "6e84b3ac-eb92-4cd0-b170-b799e0cc2b1b"
      },
      "source": [
        "dun[dun['family_size']>3]['credit'].value_counts(normalize=True).mul(100) #조부모 등의 가족이 포함되어있지 않은데, 가족 구성원이 본인 포함 4명 이상"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    68.041237\n",
              "1.0    21.649485\n",
              "0.0    10.309278\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "bSsXvgRI3VQE",
        "outputId": "6247073e-58d4-453a-9100-ff1d53189750"
      },
      "source": [
        "dun[dun['family_size']>4] #부모와 같이 사는데 가족구성원 5 이상 -> 자식이 있는데 부모와 같이 산다? 그런데 자식 수가 3명인 것을 보아 본인과 부모 한 명과 자식 3명인 것 같다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>13674</td>\n",
              "      <td>4491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>420.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4628</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>13674</td>\n",
              "      <td>4491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5730</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>126000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>12072</td>\n",
              "      <td>1422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1350.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7105</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>11757</td>\n",
              "      <td>658</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>810.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11130</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>11757</td>\n",
              "      <td>658</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11157</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>126000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>12072</td>\n",
              "      <td>1422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>5.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19223</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>126000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>12072</td>\n",
              "      <td>1422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>5.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19669</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>126000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>12072</td>\n",
              "      <td>1422</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>others</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20395</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>58500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>16087</td>\n",
              "      <td>1000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1470.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20742</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>11757</td>\n",
              "      <td>658</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "      <td>810.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender car reality  ...  family_size  begin_month credit\n",
              "index                     ...                                 \n",
              "987        F   N       N  ...          5.0        420.0    2.0\n",
              "4628       F   N       N  ...          5.0        210.0    2.0\n",
              "5730       M   N       N  ...          5.0       1350.0    2.0\n",
              "7105       M   N       N  ...          5.0        810.0    2.0\n",
              "11130      M   N       N  ...          5.0        840.0    2.0\n",
              "11157      M   N       N  ...          5.0        720.0    2.0\n",
              "19223      M   N       N  ...          5.0         60.0    1.0\n",
              "19669      M   N       N  ...          5.0         -0.0    1.0\n",
              "20395      M   N       N  ...          5.0       1470.0    2.0\n",
              "20742      M   N       N  ...          5.0        810.0    2.0\n",
              "\n",
              "[10 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "7-x9q_ZbvURF",
        "outputId": "27029b6c-5472-4f78-f0e9-c0ab680a0838"
      },
      "source": [
        "wd=train[train['family_type']=='Married']\n",
        "wd[wd['family_size']-wd['child_num']<2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14900</th>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>14776</td>\n",
              "      <td>2212</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Drivers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>900.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16791</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>126000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>12140</td>\n",
              "      <td>779</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1110.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21096</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>16424</td>\n",
              "      <td>1458</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Drivers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender car reality  ...  family_size  begin_month credit\n",
              "index                     ...                                 \n",
              "14900      M   Y       N  ...          1.0        900.0    2.0\n",
              "16791      F   N       Y  ...          1.0       1110.0    2.0\n",
              "21096      M   N       N  ...          1.0        750.0    2.0\n",
              "\n",
              "[3 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX_VVZg3sUwr"
      },
      "source": [
        "def abnorm_collec(data):\n",
        "    ab = []\n",
        "    df = copy.deepcopy(data)\n",
        "    \n",
        "    ab.append(df[(df['family_size']-df['child_num'])<1])    #자식수와 가족수가 같거나 자식수가 더 많음\n",
        "    \n",
        "    ab.append(df[df['child_num']>5])                        #자식의 수가 5명보다 많음\n",
        "    \n",
        "    wd = df[df['family_type']=='Single / not married']      #싱글인데\n",
        "    ab.append(wd[wd['family_size']-wd['child_num']>1])      #동거인이 2명 이상임\n",
        "    \n",
        "    wd = df[df['family_type']=='Married']                   #결혼했는데\n",
        "    ab.append(wd[wd['family_size']-wd['child_num']<2])      #동거인이 없음\n",
        "\n",
        "    wd = df[df['family_type']=='Civil marriage']            #동거한다는데\n",
        "    ab.append(wd[wd['family_size']-wd['child_num']<2])      #동거인이 없음\n",
        "\n",
        "    ab.append(df[df['family_size']<1]) #가족 크기가 1보다 작음\n",
        "\n",
        "    ab.append(df[(df['family_size']-df['child_num'])>3]) #동거를 3명 이상 함\n",
        "\n",
        "\n",
        "    fs = df[df['family_type']=='Single / not married'][df[df['family_type']=='Single / not married']['child_num']==0]\n",
        "    #싱글이고\n",
        "    ab.append(fs[fs['family_size']>1])\n",
        "    #동거인이 있음\n",
        "\n",
        "    a = df[df['family_type']=='Single / not married'][df[df['family_type']=='Single / not married']['family_size']>2]\n",
        "    #싱글이고 가족 크기가 3 이상인데\n",
        "    ab.append(a[a['reality']== 'N'][a[a['reality']== 'N']['DAYS_EMPLOYED']<2555])\n",
        "    #직장 근속을 7년 이상을 못 하고 집이 없음\n",
        "\n",
        "    ab.append(train[train['income_type']=='Pensioner'][train[train['income_type']=='Pensioner']['occyp_type']!='beksu'])\n",
        "    #일하면서 연금받음\n",
        "\n",
        "    wd = df[df['occyp_type']=='Drivers']\n",
        "    a = wd[wd['car']=='N'][wd[wd['car']=='N']['income_type']!='Commercial associate']\n",
        "    ab.append(a[a['DAYS_EMPLOYED']<200])\n",
        "    #드라이버인데, 차가 없고 어디 소속되어있지도 않으며 최소고용보장 이상 일하지 못함(6개월)\n",
        "\n",
        "\n",
        "    abnorm = pd.concat(ab)\n",
        "    abnorm.drop_duplicates(inplace=True)\n",
        "    return abnorm\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQnr1n04lG9"
      },
      "source": [
        "train = train.drop(abnorm_collec(train).index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYR9fIoXjCoh"
      },
      "source": [
        "train = train.drop(train[train['begin_month']==0][train[train['begin_month']==0]['credit']==2].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ds1PihVsF_C"
      },
      "source": [
        "### review the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        },
        "id": "iRRiZZhGG1Gr",
        "outputId": "64e2a02d-3235-446f-a8c4-835b956a98af"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>car</th>\n",
              "      <th>reality</th>\n",
              "      <th>child_num</th>\n",
              "      <th>income_total</th>\n",
              "      <th>income_type</th>\n",
              "      <th>edu_type</th>\n",
              "      <th>family_type</th>\n",
              "      <th>house_type</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>work_phone</th>\n",
              "      <th>phone</th>\n",
              "      <th>email</th>\n",
              "      <th>occyp_type</th>\n",
              "      <th>family_size</th>\n",
              "      <th>begin_month</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>Municipal apartment</td>\n",
              "      <td>13899</td>\n",
              "      <td>4709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "      <td>2.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>247500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>11380</td>\n",
              "      <td>1540</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>19087</td>\n",
              "      <td>4434</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>660.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>202500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>15088</td>\n",
              "      <td>2092</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1110.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>15037</td>\n",
              "      <td>2105</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Managers</td>\n",
              "      <td>2.0</td>\n",
              "      <td>780.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26452</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>2</td>\n",
              "      <td>225000.0</td>\n",
              "      <td>State servant</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>12079</td>\n",
              "      <td>1984</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26453</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>180000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>15291</td>\n",
              "      <td>2475</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>others</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26454</th>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>292500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>With parents</td>\n",
              "      <td>10082</td>\n",
              "      <td>2015</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26455</th>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>171000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Incomplete higher</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>10145</td>\n",
              "      <td>107</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1770.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26456</th>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>81000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>19569</td>\n",
              "      <td>1013</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Security staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24768 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      gender car reality  ...  family_size  begin_month credit\n",
              "index                     ...                                 \n",
              "0          F   N       N  ...          2.0        180.0    1.0\n",
              "1          F   N       Y  ...          3.0        150.0    0.0\n",
              "2          M   Y       Y  ...          2.0        660.0    1.0\n",
              "3          F   N       Y  ...          2.0       1110.0    0.0\n",
              "4          F   Y       Y  ...          2.0        780.0    2.0\n",
              "...      ...  ..     ...  ...          ...          ...    ...\n",
              "26452      F   N       N  ...          4.0         60.0    1.0\n",
              "26453      F   N       Y  ...          2.0       1410.0    2.0\n",
              "26454      F   Y       N  ...          2.0        750.0    2.0\n",
              "26455      M   N       Y  ...          1.0       1770.0    2.0\n",
              "26456      F   N       N  ...          2.0        270.0    2.0\n",
              "\n",
              "[24768 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JstUASzmLcX6",
        "outputId": "dc977512-c359-4e03-f0f1-bb20d2351d25"
      },
      "source": [
        "train.credit.value_counts(normalize=True).mul(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    63.505329\n",
              "1.0    24.051195\n",
              "0.0    12.443475\n",
              "Name: credit, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2tIPljZLcUF",
        "outputId": "1478c9a6-1302-4269-9ca5-aaff6e1ba3fe"
      },
      "source": [
        "check_duplicate(train, 'credit')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('credit',)을(를) 제외하고 중복되는 데이터 개수는 1425 입니다\n",
            "중복 데이터 비율: 5.75\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([    1,     2,    21,    24,    25,    34,    50,    53,    77,\n",
              "               78,\n",
              "            ...\n",
              "            26346, 26354, 26369, 26386, 26391, 26397, 26403, 26430, 26431,\n",
              "            26432],\n",
              "           dtype='int64', name='index', length=1425)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSx3DDj96jr8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flM2rc-F6kIa"
      },
      "source": [
        "오전 11시 38분 중복제거를 하지 않고 최대한 test의 분포에 맞게 해보았다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7S4fL6gNA6h"
      },
      "source": [
        "중복 제거 완료"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chB7zc_OTkog",
        "outputId": "df2bf735-edd8-474e-baff-991f9f5e7f5e"
      },
      "source": [
        "len (train_c)-len(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU3K-2S7TuFC"
      },
      "source": [
        "온전히 중복 데이터를 삭제한 train_c에서 716개 정도의 데이터가 결손되었다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwyB-CfZTs36"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cia1h87_oQFw"
      },
      "source": [
        "##Data Preprocessing and distillation with SDV(TVAE, CTGAN, SMOTE) - TVAE SELECTED\n",
        "######Using data pregenerated because of long fitting interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5XFG5tzbx6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNKyrsALkR6F"
      },
      "source": [
        "데이터를 최대한 정제(cleansing)한 후에 저장한 일종의 synthetic data table이므로 sampling하여 normalizing 하는데 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_K-3zfGoyaY"
      },
      "source": [
        "## (Unactivated)Data Recleansing for synthetic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26r-xbpaoW2H"
      },
      "source": [
        "##Data Spliting and Loading DATASETS for K-FOLD -- 1st way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq_KnGB9Kk3a"
      },
      "source": [
        "trains = fold(train,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18sF6gvYNZ0O",
        "outputId": "621998d6-4a5f-4f0d-82fc-fe0c6f2a33f7"
      },
      "source": [
        "a = 0\n",
        "for x in range(len(trains)):\n",
        "  a += len(trains[x])\n",
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMJc5Sh3zRbs"
      },
      "source": [
        "## Data Spliting by Occyp_type and Apply Synthetic for remove relation caused by data bias. -- 2nd way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEM8a6CkrOyZ"
      },
      "source": [
        "#Trainning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcezLDCpzxyd"
      },
      "source": [
        "## K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoYIU21UK3it",
        "outputId": "940461bc-9c31-490d-b7cc-81bfa86d1922"
      },
      "source": [
        "(predictors, ldbd) = fold_models(trains)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [0.0, 1.0, 2.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    8956.61 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.26s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.778\t = Validation log_loss score\n",
            "\t184.53s\t = Training runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.1081\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.0689\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7225\t = Validation log_loss score\n",
            "\t7.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7137\t = Validation log_loss score\n",
            "\t10.87s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8573\t = Validation log_loss score\n",
            "\t5.57s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.841\t = Validation log_loss score\n",
            "\t6.77s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7402\t = Validation log_loss score\n",
            "\t4.97s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7495\t = Validation log_loss score\n",
            "\t6.8s\t = Training runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7633\t = Validation log_loss score\n",
            "\t125.88s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7398\t = Validation log_loss score\n",
            "\t26.55s\t = Training runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7194\t = Validation log_loss score\n",
            "\t8.93s\t = Training runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.6911\t = Validation log_loss score\n",
            "\t1.7s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 409.72s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.6840990625994403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Persisting 6 models in memory. Models will require 6.53% of memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t68.35s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.67s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.87s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.53s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.38s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t4.35s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t6.15s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t128.03s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t28.21s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.88s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.6911\t = Validation log_loss score\n",
            "\t0.67s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    8333.3 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.7988\t = Validation log_loss score\n",
            "\t177.0s\t = Training runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.1817\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.165\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7376\t = Validation log_loss score\n",
            "\t7.77s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7405\t = Validation log_loss score\n",
            "\t10.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8982\t = Validation log_loss score\n",
            "\t5.69s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8772\t = Validation log_loss score\n",
            "\t6.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7478\t = Validation log_loss score\n",
            "\t5.03s\t = Training runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7628\t = Validation log_loss score\n",
            "\t6.85s\t = Training runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7738\t = Validation log_loss score\n",
            "\t116.07s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7341\t = Validation log_loss score\n",
            "\t39.62s\t = Training runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7237\t = Validation log_loss score\n",
            "\t8.34s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.7029\t = Validation log_loss score\n",
            "\t1.69s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 402.58s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.7219664866009935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Models will not be persisted in memory as they are expected to require 13.81% of memory, which is greater than the specified max_memory limit of 10.0%.\n",
            "\tModels will be loaded on-demand from disk to maintain safe memory usage, increasing inference latency. If inference latency is a concern, try to use smaller models or increase the value of max_memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t68.98s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.06s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.66s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.97s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.17s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.47s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t4.47s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t6.18s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t118.11s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t43.57s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.17s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.7029\t = Validation log_loss score\n",
            "\t0.87s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    7706.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.27s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.7853\t = Validation log_loss score\n",
            "\t189.64s\t = Training runtime\n",
            "\t0.54s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.3151\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.2982\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7367\t = Validation log_loss score\n",
            "\t7.77s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7374\t = Validation log_loss score\n",
            "\t10.88s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.864\t = Validation log_loss score\n",
            "\t5.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8902\t = Validation log_loss score\n",
            "\t6.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7336\t = Validation log_loss score\n",
            "\t4.77s\t = Training runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7543\t = Validation log_loss score\n",
            "\t5.9s\t = Training runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7586\t = Validation log_loss score\n",
            "\t165.82s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7387\t = Validation log_loss score\n",
            "\t37.15s\t = Training runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.715\t = Validation log_loss score\n",
            "\t9.17s\t = Training runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.7003\t = Validation log_loss score\n",
            "\t1.66s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 463.18s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.6719212814592282\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Models will not be persisted in memory as they are expected to require 14.98% of memory, which is greater than the specified max_memory limit of 10.0%.\n",
            "\tModels will be loaded on-demand from disk to maintain safe memory usage, increasing inference latency. If inference latency is a concern, try to use smaller models or increase the value of max_memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t68.81s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.67s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.99s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.2s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.49s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t4.15s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t5.32s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t171.38s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t40.85s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t8.29s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.7003\t = Validation log_loss score\n",
            "\t1.06s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    7662.06 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.7967\t = Validation log_loss score\n",
            "\t198.08s\t = Training runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.1457\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.118\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7135\t = Validation log_loss score\n",
            "\t7.88s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7203\t = Validation log_loss score\n",
            "\t10.98s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8685\t = Validation log_loss score\n",
            "\t5.69s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8523\t = Validation log_loss score\n",
            "\t6.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7393\t = Validation log_loss score\n",
            "\t4.07s\t = Training runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7439\t = Validation log_loss score\n",
            "\t6.41s\t = Training runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7635\t = Validation log_loss score\n",
            "\t131.41s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7394\t = Validation log_loss score\n",
            "\t34.76s\t = Training runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7105\t = Validation log_loss score\n",
            "\t9.79s\t = Training runtime\n",
            "\t0.39s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.69\t = Validation log_loss score\n",
            "\t1.71s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 439.12s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.7115376962127649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Persisting 7 models in memory. Models will require 7.54% of memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t70.15s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.69s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.98s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.28s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.39s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t3.39s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t5.8s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t133.18s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t38.42s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t8.83s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.69\t = Validation log_loss score\n",
            "\t0.6s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    7069.51 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.3s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.38s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8088\t = Validation log_loss score\n",
            "\t153.77s\t = Training runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.413\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.3799\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7376\t = Validation log_loss score\n",
            "\t7.99s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7461\t = Validation log_loss score\n",
            "\t10.89s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8732\t = Validation log_loss score\n",
            "\t5.69s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8948\t = Validation log_loss score\n",
            "\t6.8s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7556\t = Validation log_loss score\n",
            "\t4.43s\t = Training runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7731\t = Validation log_loss score\n",
            "\t6.27s\t = Training runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7861\t = Validation log_loss score\n",
            "\t115.62s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7518\t = Validation log_loss score\n",
            "\t30.63s\t = Training runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7402\t = Validation log_loss score\n",
            "\t8.55s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.7129\t = Validation log_loss score\n",
            "\t1.72s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 378.65s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.6913560943449328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Persisting 6 models in memory. Models will require 8.05% of memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t71.33s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.06s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.67s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.88s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.29s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.58s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t3.77s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t5.64s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t117.93s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t33.28s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.56s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.7129\t = Validation log_loss score\n",
            "\t0.78s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    6450.91 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8007\t = Validation log_loss score\n",
            "\t137.19s\t = Training runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.1392\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.0976\t = Validation log_loss score\n",
            "\t0.06s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7264\t = Validation log_loss score\n",
            "\t7.89s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7262\t = Validation log_loss score\n",
            "\t10.67s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8378\t = Validation log_loss score\n",
            "\t5.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8596\t = Validation log_loss score\n",
            "\t6.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7457\t = Validation log_loss score\n",
            "\t4.69s\t = Training runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7644\t = Validation log_loss score\n",
            "\t5.7s\t = Training runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7673\t = Validation log_loss score\n",
            "\t156.22s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7479\t = Validation log_loss score\n",
            "\t36.97s\t = Training runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7245\t = Validation log_loss score\n",
            "\t9.13s\t = Training runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.7\t = Validation log_loss score\n",
            "\t1.73s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 406.43s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.7031101118855972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Persisting 7 models in memory. Models will require 8.94% of memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t69.09s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.06s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.06s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.67s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.87s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.3s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.59s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t4.18s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t5.17s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t161.18s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t40.53s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t8.31s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.7\t = Validation log_loss score\n",
            "\t0.81s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    5857.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.32s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8025\t = Validation log_loss score\n",
            "\t160.52s\t = Training runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.2513\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.2203\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7252\t = Validation log_loss score\n",
            "\t7.8s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7141\t = Validation log_loss score\n",
            "\t10.69s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8571\t = Validation log_loss score\n",
            "\t5.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8364\t = Validation log_loss score\n",
            "\t6.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7434\t = Validation log_loss score\n",
            "\t4.4s\t = Training runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7553\t = Validation log_loss score\n",
            "\t6.14s\t = Training runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7755\t = Validation log_loss score\n",
            "\t98.02s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7424\t = Validation log_loss score\n",
            "\t32.29s\t = Training runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7163\t = Validation log_loss score\n",
            "\t8.68s\t = Training runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.693\t = Validation log_loss score\n",
            "\t1.72s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 366.81s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.7056118241873884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Persisting 6 models in memory. Models will require 9.77% of memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t69.64s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.78s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.98s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.39s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.5s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t3.81s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t6.0s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t98.27s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t35.25s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.7s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.693\t = Validation log_loss score\n",
            "\t0.47s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    5246.55 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.38s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8168\t = Validation log_loss score\n",
            "\t116.61s\t = Training runtime\n",
            "\t0.55s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.2611\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.2236\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7459\t = Validation log_loss score\n",
            "\t7.89s\t = Training runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7468\t = Validation log_loss score\n",
            "\t10.69s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8699\t = Validation log_loss score\n",
            "\t5.58s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8758\t = Validation log_loss score\n",
            "\t6.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7637\t = Validation log_loss score\n",
            "\t3.3s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7813\t = Validation log_loss score\n",
            "\t5.78s\t = Training runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7847\t = Validation log_loss score\n",
            "\t78.39s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7602\t = Validation log_loss score\n",
            "\t24.6s\t = Training runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7359\t = Validation log_loss score\n",
            "\t7.52s\t = Training runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.713\t = Validation log_loss score\n",
            "\t1.71s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 297.76s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.6913179153025825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Models will not be persisted in memory as they are expected to require 21.79% of memory, which is greater than the specified max_memory limit of 10.0%.\n",
            "\tModels will be loaded on-demand from disk to maintain safe memory usage, increasing inference latency. If inference latency is a concern, try to use smaller models or increase the value of max_memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t53.65s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.57s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.87s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.29s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.59s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t2.8s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t5.07s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t77.38s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t25.49s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t6.57s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.713\t = Validation log_loss score\n",
            "\t0.92s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22292\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    5239.18 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.42 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.36s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8256\t = Validation log_loss score\n",
            "\t136.12s\t = Training runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.3806\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.3497\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7479\t = Validation log_loss score\n",
            "\t7.78s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7483\t = Validation log_loss score\n",
            "\t10.77s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8786\t = Validation log_loss score\n",
            "\t5.68s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8665\t = Validation log_loss score\n",
            "\t6.79s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7647\t = Validation log_loss score\n",
            "\t3.76s\t = Training runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7774\t = Validation log_loss score\n",
            "\t5.08s\t = Training runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7895\t = Validation log_loss score\n",
            "\t104.17s\t = Training runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7703\t = Validation log_loss score\n",
            "\t27.96s\t = Training runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.737\t = Validation log_loss score\n",
            "\t8.22s\t = Training runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.718\t = Validation log_loss score\n",
            "\t1.72s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 343.23s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.6952480542802993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Models will not be persisted in memory as they are expected to require 27.49% of memory, which is greater than the specified max_memory limit of 10.0%.\n",
            "\tModels will be loaded on-demand from disk to maintain safe memory usage, increasing inference latency. If inference latency is a concern, try to use smaller models or increase the value of max_memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t70.36s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.06s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.67s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.97s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.18s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.59s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t3.19s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t4.38s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t105.2s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t29.74s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.2s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.718\t = Validation log_loss score\n",
            "\t0.75s\t = Training runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to /contect/Autogluon/\n",
            "AutoGluon Version:  0.0.16b20201214\n",
            "Train Data Rows:    22284\n",
            "Train Data Columns: 17\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == float, but few unique label-values observed and label-values can be converted to int).\n",
            "\t3 unique label values:  [2.0, 1.0, 0.0]\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    5216.7 MB\n",
            "\tTrain Data (Original)  Memory Usage: 13.41 MB (0.3% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])    : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t\t('object', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 8 | ['gender', 'car', 'reality', 'income_type', 'edu_type', ...]\n",
            "\t\t('float', [])    : 3 | ['income_total', 'family_size', 'begin_month']\n",
            "\t\t('int', [])      : 6 | ['child_num', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'work_phone', 'phone', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t17 features in original data used to generate 17 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.78 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.31s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'log_loss'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric argument of fit()\n",
            "AutoGluon will early stop models using evaluation metric: 'log_loss'\n",
            "Fitting model: NeuralNetMXNet ...\n",
            "\t-0.8215\t = Validation log_loss score\n",
            "\t165.32s\t = Training runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t-2.2786\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t-2.2422\t = Validation log_loss score\n",
            "\t0.05s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t-0.7522\t = Validation log_loss score\n",
            "\t7.79s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t-0.7503\t = Validation log_loss score\n",
            "\t10.77s\t = Training runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t-0.8793\t = Validation log_loss score\n",
            "\t5.59s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t-0.8893\t = Validation log_loss score\n",
            "\t6.79s\t = Training runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t-0.7673\t = Validation log_loss score\n",
            "\t3.29s\t = Training runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t-0.7792\t = Validation log_loss score\n",
            "\t5.61s\t = Training runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t-0.7832\t = Validation log_loss score\n",
            "\t122.63s\t = Training runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t-0.7695\t = Validation log_loss score\n",
            "\t19.78s\t = Training runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBMCustom ...\n",
            "\t-0.7418\t = Validation log_loss score\n",
            "\t8.87s\t = Training runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L1 ...\n",
            "\t-0.7182\t = Validation log_loss score\n",
            "\t1.74s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 382.49s ...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Predictive performance on given dataset: log_loss = 0.703029465811378\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Models will not be persisted in memory as they are expected to require 16.55% of memory, which is greater than the specified max_memory limit of 10.0%.\n",
            "\tModels will be loaded on-demand from disk to maintain safe memory usage, increasing inference latency. If inference latency is a concern, try to use smaller models or increase the value of max_memory.\n",
            "Fitting model: NeuralNetMXNet_FULL ...\n",
            "\t68.88s\t = Training runtime\n",
            "Fitting model: KNeighborsUnif_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: KNeighborsDist_FULL ...\n",
            "\t0.05s\t = Training runtime\n",
            "Fitting model: RandomForestGini_FULL ...\n",
            "\t8.68s\t = Training runtime\n",
            "Fitting model: RandomForestEntr_FULL ...\n",
            "\t11.88s\t = Training runtime\n",
            "Fitting model: ExtraTreesGini_FULL ...\n",
            "\t6.19s\t = Training runtime\n",
            "Fitting model: ExtraTreesEntr_FULL ...\n",
            "\t7.49s\t = Training runtime\n",
            "Fitting model: LightGBM_FULL ...\n",
            "\t2.57s\t = Training runtime\n",
            "Fitting model: LightGBMXT_FULL ...\n",
            "\t4.99s\t = Training runtime\n",
            "Fitting model: CatBoost_FULL ...\n",
            "\t125.84s\t = Training runtime\n",
            "Fitting model: XGBoost_FULL ...\n",
            "\t19.94s\t = Training runtime\n",
            "Fitting model: LightGBMCustom_FULL ...\n",
            "\t7.22s\t = Training runtime\n",
            "Fitting model: WeightedEnsemble_FULL_L1 ...\n",
            "\t-0.7182\t = Validation log_loss score\n",
            "\t0.76s\t = Training runtime\n",
            "\t0.0s\t = Validation runtime\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFUgNBP-z1IU"
      },
      "source": [
        "## Occyp_type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxjYdTkwz5FW"
      },
      "source": [
        "## abnormal data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1Lok1nltYNj"
      },
      "source": [
        "#Inference Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJFUGX7_z-v8"
      },
      "source": [
        "## Inferencing each models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0sd2pyqMDL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2310a1d7-0f36-4c92-a5f5-3d756a0a26b7"
      },
      "source": [
        "predictors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4056c40490>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4056b22a50>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4057396e50>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4060c74fd0>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4056b22d50>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4060ea4c10>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f40323a5410>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f403275e110>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f403177ed90>,\n",
              " <autogluon.tabular.task.tabular_prediction.predictor.TabularPredictor at 0x7f4031a7d210>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_vnn1okMEiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c406817d-8493-4e6f-d4ca-e2eedbaf3e30"
      },
      "source": [
        "ldbd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[                       model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.675648  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.684099  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.689813  ...       True         25\n",
              " 3             LightGBMCustom   -0.692859  ...       True         12\n",
              " 4              LightGBM_FULL   -0.706017  ...       True         21\n",
              " 5                   LightGBM   -0.708045  ...       True          8\n",
              " 6               XGBoost_FULL   -0.708836  ...       True         24\n",
              " 7      RandomForestGini_FULL   -0.711343  ...       True         17\n",
              " 8           RandomForestEntr   -0.715397  ...       True          5\n",
              " 9                    XGBoost   -0.718564  ...       True         11\n",
              " 10           LightGBMXT_FULL   -0.720969  ...       True         22\n",
              " 11     RandomForestEntr_FULL   -0.721902  ...       True         18\n",
              " 12                LightGBMXT   -0.724585  ...       True          9\n",
              " 13          RandomForestGini   -0.725393  ...       True          4\n",
              " 14             CatBoost_FULL   -0.731979  ...       True         23\n",
              " 15                  CatBoost   -0.734646  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.774693  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.774864  ...       True          1\n",
              " 18       ExtraTreesEntr_FULL   -0.842544  ...       True         20\n",
              " 19       ExtraTreesGini_FULL   -0.846299  ...       True         19\n",
              " 20            ExtraTreesGini   -0.853920  ...       True          6\n",
              " 21            ExtraTreesEntr   -0.864722  ...       True          7\n",
              " 22            KNeighborsDist   -2.081018  ...       True          3\n",
              " 23       KNeighborsDist_FULL   -2.088705  ...       True         16\n",
              " 24            KNeighborsUnif   -2.103193  ...       True          2\n",
              " 25       KNeighborsUnif_FULL   -2.112019  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.711020  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.721966  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.730868  ...       True         25\n",
              " 3      RandomForestGini_FULL   -0.743278  ...       True         17\n",
              " 4      RandomForestEntr_FULL   -0.743657  ...       True         18\n",
              " 5             LightGBMCustom   -0.745714  ...       True         12\n",
              " 6               XGBoost_FULL   -0.750292  ...       True         24\n",
              " 7           RandomForestGini   -0.750819  ...       True          4\n",
              " 8           RandomForestEntr   -0.754999  ...       True          5\n",
              " 9              LightGBM_FULL   -0.758223  ...       True         21\n",
              " 10           LightGBMXT_FULL   -0.760828  ...       True         22\n",
              " 11                   XGBoost   -0.763584  ...       True         11\n",
              " 12                  LightGBM   -0.766004  ...       True          8\n",
              " 13                LightGBMXT   -0.766737  ...       True          9\n",
              " 14             CatBoost_FULL   -0.785818  ...       True         23\n",
              " 15                  CatBoost   -0.791636  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.822969  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.828219  ...       True          1\n",
              " 18            ExtraTreesGini   -0.852402  ...       True          6\n",
              " 19       ExtraTreesGini_FULL   -0.860605  ...       True         19\n",
              " 20       ExtraTreesEntr_FULL   -0.861743  ...       True         20\n",
              " 21            ExtraTreesEntr   -0.872245  ...       True          7\n",
              " 22       KNeighborsDist_FULL   -2.100893  ...       True         16\n",
              " 23       KNeighborsUnif_FULL   -2.142006  ...       True         15\n",
              " 24            KNeighborsDist   -2.185454  ...       True          3\n",
              " 25            KNeighborsUnif   -2.217238  ...       True          2\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.663660  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.671921  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.681771  ...       True         25\n",
              " 3      RandomForestEntr_FULL   -0.683866  ...       True         18\n",
              " 4           RandomForestEntr   -0.686534  ...       True          5\n",
              " 5      RandomForestGini_FULL   -0.690049  ...       True         17\n",
              " 6           RandomForestGini   -0.690728  ...       True          4\n",
              " 7             LightGBMCustom   -0.697022  ...       True         12\n",
              " 8              LightGBM_FULL   -0.704574  ...       True         21\n",
              " 9               XGBoost_FULL   -0.709879  ...       True         24\n",
              " 10                  LightGBM   -0.713876  ...       True          8\n",
              " 11                   XGBoost   -0.718159  ...       True         11\n",
              " 12           LightGBMXT_FULL   -0.725067  ...       True         22\n",
              " 13                LightGBMXT   -0.729154  ...       True          9\n",
              " 14             CatBoost_FULL   -0.740322  ...       True         23\n",
              " 15                  CatBoost   -0.745062  ...       True         10\n",
              " 16            NeuralNetMXNet   -0.778493  ...       True          1\n",
              " 17       NeuralNetMXNet_FULL   -0.788668  ...       True         14\n",
              " 18            ExtraTreesGini   -0.799400  ...       True          6\n",
              " 19       ExtraTreesEntr_FULL   -0.828768  ...       True         20\n",
              " 20            ExtraTreesEntr   -0.837045  ...       True          7\n",
              " 21       ExtraTreesGini_FULL   -0.849538  ...       True         19\n",
              " 22       KNeighborsDist_FULL   -1.962090  ...       True         16\n",
              " 23            KNeighborsDist   -1.980276  ...       True          3\n",
              " 24       KNeighborsUnif_FULL   -1.992494  ...       True         15\n",
              " 25            KNeighborsUnif   -2.006207  ...       True          2\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.705889  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.711538  ...       True         13\n",
              " 2           RandomForestEntr   -0.729428  ...       True          5\n",
              " 3      RandomForestGini_FULL   -0.730134  ...       True         17\n",
              " 4           RandomForestGini   -0.731939  ...       True          4\n",
              " 5      RandomForestEntr_FULL   -0.732749  ...       True         18\n",
              " 6        LightGBMCustom_FULL   -0.738942  ...       True         25\n",
              " 7             LightGBMCustom   -0.744318  ...       True         12\n",
              " 8               XGBoost_FULL   -0.754583  ...       True         24\n",
              " 9              LightGBM_FULL   -0.760918  ...       True         21\n",
              " 10                   XGBoost   -0.761871  ...       True         11\n",
              " 11                  LightGBM   -0.763279  ...       True          8\n",
              " 12           LightGBMXT_FULL   -0.773403  ...       True         22\n",
              " 13                LightGBMXT   -0.776740  ...       True          9\n",
              " 14             CatBoost_FULL   -0.781206  ...       True         23\n",
              " 15                  CatBoost   -0.784179  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.818172  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.819617  ...       True          1\n",
              " 18            ExtraTreesGini   -0.834876  ...       True          6\n",
              " 19            ExtraTreesEntr   -0.845904  ...       True          7\n",
              " 20       ExtraTreesGini_FULL   -0.850084  ...       True         19\n",
              " 21       ExtraTreesEntr_FULL   -0.853963  ...       True         20\n",
              " 22            KNeighborsDist   -2.193856  ...       True          3\n",
              " 23            KNeighborsUnif   -2.214029  ...       True          2\n",
              " 24       KNeighborsDist_FULL   -2.259989  ...       True         16\n",
              " 25       KNeighborsUnif_FULL   -2.285515  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.687986  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.691356  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.704468  ...       True         25\n",
              " 3      RandomForestGini_FULL   -0.712944  ...       True         17\n",
              " 4      RandomForestEntr_FULL   -0.715255  ...       True         18\n",
              " 5             LightGBMCustom   -0.716344  ...       True         12\n",
              " 6           RandomForestGini   -0.717590  ...       True          4\n",
              " 7           RandomForestEntr   -0.722697  ...       True          5\n",
              " 8                    XGBoost   -0.730404  ...       True         11\n",
              " 9              LightGBM_FULL   -0.732326  ...       True         21\n",
              " 10              XGBoost_FULL   -0.734163  ...       True         24\n",
              " 11                  LightGBM   -0.734189  ...       True          8\n",
              " 12           LightGBMXT_FULL   -0.740681  ...       True         22\n",
              " 13                LightGBMXT   -0.744347  ...       True          9\n",
              " 14                  CatBoost   -0.763767  ...       True         10\n",
              " 15             CatBoost_FULL   -0.766168  ...       True         23\n",
              " 16            NeuralNetMXNet   -0.790282  ...       True          1\n",
              " 17       NeuralNetMXNet_FULL   -0.800118  ...       True         14\n",
              " 18       ExtraTreesEntr_FULL   -0.826268  ...       True         20\n",
              " 19       ExtraTreesGini_FULL   -0.832522  ...       True         19\n",
              " 20            ExtraTreesGini   -0.833507  ...       True          6\n",
              " 21            ExtraTreesEntr   -0.839347  ...       True          7\n",
              " 22       KNeighborsDist_FULL   -1.943028  ...       True         16\n",
              " 23       KNeighborsUnif_FULL   -1.977388  ...       True         15\n",
              " 24            KNeighborsDist   -2.053883  ...       True          3\n",
              " 25            KNeighborsUnif   -2.086655  ...       True          2\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.694088  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.703110  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.710619  ...       True         25\n",
              " 3             LightGBMCustom   -0.716026  ...       True         12\n",
              " 4      RandomForestEntr_FULL   -0.726175  ...       True         18\n",
              " 5              LightGBM_FULL   -0.727533  ...       True         21\n",
              " 6               XGBoost_FULL   -0.729313  ...       True         24\n",
              " 7      RandomForestGini_FULL   -0.733000  ...       True         17\n",
              " 8           RandomForestEntr   -0.734282  ...       True          5\n",
              " 9           RandomForestGini   -0.734943  ...       True          4\n",
              " 10                   XGBoost   -0.739369  ...       True         11\n",
              " 11                  LightGBM   -0.739574  ...       True          8\n",
              " 12           LightGBMXT_FULL   -0.747003  ...       True         22\n",
              " 13             CatBoost_FULL   -0.751320  ...       True         23\n",
              " 14                LightGBMXT   -0.752092  ...       True          9\n",
              " 15                  CatBoost   -0.764332  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.805453  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.808810  ...       True          1\n",
              " 18            ExtraTreesEntr   -0.848421  ...       True          7\n",
              " 19       ExtraTreesEntr_FULL   -0.869105  ...       True         20\n",
              " 20            ExtraTreesGini   -0.869477  ...       True          6\n",
              " 21       ExtraTreesGini_FULL   -0.871936  ...       True         19\n",
              " 22            KNeighborsDist   -2.043868  ...       True          3\n",
              " 23            KNeighborsUnif   -2.064068  ...       True          2\n",
              " 24       KNeighborsDist_FULL   -2.071913  ...       True         16\n",
              " 25       KNeighborsUnif_FULL   -2.094188  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.695099  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.705612  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.711278  ...       True         25\n",
              " 3             LightGBMCustom   -0.722192  ...       True         12\n",
              " 4      RandomForestGini_FULL   -0.727943  ...       True         17\n",
              " 5      RandomForestEntr_FULL   -0.731605  ...       True         18\n",
              " 6               XGBoost_FULL   -0.731962  ...       True         24\n",
              " 7           RandomForestEntr   -0.737329  ...       True          5\n",
              " 8           RandomForestGini   -0.741656  ...       True          4\n",
              " 9              LightGBM_FULL   -0.747428  ...       True         21\n",
              " 10                  LightGBM   -0.749667  ...       True          8\n",
              " 11           LightGBMXT_FULL   -0.752315  ...       True         22\n",
              " 12                   XGBoost   -0.752522  ...       True         11\n",
              " 13                LightGBMXT   -0.763920  ...       True          9\n",
              " 14             CatBoost_FULL   -0.772194  ...       True         23\n",
              " 15                  CatBoost   -0.775088  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.797301  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.802403  ...       True          1\n",
              " 18            ExtraTreesEntr   -0.863363  ...       True          7\n",
              " 19       ExtraTreesGini_FULL   -0.864220  ...       True         19\n",
              " 20       ExtraTreesEntr_FULL   -0.866178  ...       True         20\n",
              " 21            ExtraTreesGini   -0.885925  ...       True          6\n",
              " 22       KNeighborsDist_FULL   -2.170122  ...       True         16\n",
              " 23            KNeighborsDist   -2.173992  ...       True          3\n",
              " 24            KNeighborsUnif   -2.195829  ...       True          2\n",
              " 25       KNeighborsUnif_FULL   -2.200315  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.678258  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.691318  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.699527  ...       True         25\n",
              " 3             LightGBMCustom   -0.711196  ...       True         12\n",
              " 4      RandomForestEntr_FULL   -0.712416  ...       True         18\n",
              " 5      RandomForestGini_FULL   -0.715694  ...       True         17\n",
              " 6              LightGBM_FULL   -0.720709  ...       True         21\n",
              " 7           RandomForestGini   -0.723135  ...       True          4\n",
              " 8               XGBoost_FULL   -0.723350  ...       True         24\n",
              " 9                    XGBoost   -0.725359  ...       True         11\n",
              " 10          RandomForestEntr   -0.726633  ...       True          5\n",
              " 11                  LightGBM   -0.727875  ...       True          8\n",
              " 12           LightGBMXT_FULL   -0.729025  ...       True         22\n",
              " 13                LightGBMXT   -0.742948  ...       True          9\n",
              " 14             CatBoost_FULL   -0.756257  ...       True         23\n",
              " 15                  CatBoost   -0.762199  ...       True         10\n",
              " 16       NeuralNetMXNet_FULL   -0.792582  ...       True         14\n",
              " 17            NeuralNetMXNet   -0.793713  ...       True          1\n",
              " 18       ExtraTreesGini_FULL   -0.835628  ...       True         19\n",
              " 19       ExtraTreesEntr_FULL   -0.850004  ...       True         20\n",
              " 20            ExtraTreesGini   -0.852083  ...       True          6\n",
              " 21            ExtraTreesEntr   -0.863166  ...       True          7\n",
              " 22            KNeighborsDist   -2.007546  ...       True          3\n",
              " 23       KNeighborsDist_FULL   -2.016127  ...       True         16\n",
              " 24            KNeighborsUnif   -2.031049  ...       True          2\n",
              " 25       KNeighborsUnif_FULL   -2.046826  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.690577  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.695248  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.710087  ...       True         25\n",
              " 3             LightGBMCustom   -0.711901  ...       True         12\n",
              " 4                    XGBoost   -0.732099  ...       True         11\n",
              " 5      RandomForestEntr_FULL   -0.732905  ...       True         18\n",
              " 6               XGBoost_FULL   -0.732972  ...       True         24\n",
              " 7                   LightGBM   -0.734480  ...       True          8\n",
              " 8           RandomForestGini   -0.735662  ...       True          4\n",
              " 9              LightGBM_FULL   -0.736545  ...       True         21\n",
              " 10           LightGBMXT_FULL   -0.736636  ...       True         22\n",
              " 11          RandomForestEntr   -0.737202  ...       True          5\n",
              " 12     RandomForestGini_FULL   -0.738201  ...       True         17\n",
              " 13                LightGBMXT   -0.742640  ...       True          9\n",
              " 14             CatBoost_FULL   -0.756601  ...       True         23\n",
              " 15                  CatBoost   -0.760603  ...       True         10\n",
              " 16            NeuralNetMXNet   -0.791946  ...       True          1\n",
              " 17       NeuralNetMXNet_FULL   -0.792110  ...       True         14\n",
              " 18            ExtraTreesEntr   -0.867293  ...       True          7\n",
              " 19            ExtraTreesGini   -0.872510  ...       True          6\n",
              " 20       ExtraTreesEntr_FULL   -0.885273  ...       True         20\n",
              " 21       ExtraTreesGini_FULL   -0.891970  ...       True         19\n",
              " 22            KNeighborsDist   -2.069480  ...       True          3\n",
              " 23       KNeighborsDist_FULL   -2.086314  ...       True         16\n",
              " 24            KNeighborsUnif   -2.087080  ...       True          2\n",
              " 25       KNeighborsUnif_FULL   -2.107779  ...       True         15\n",
              " \n",
              " [26 rows x 12 columns],\n",
              "                        model  score_test  ...  can_infer  fit_order\n",
              " 0   WeightedEnsemble_FULL_L1   -0.693291  ...       True         26\n",
              " 1        WeightedEnsemble_L1   -0.703029  ...       True         13\n",
              " 2        LightGBMCustom_FULL   -0.715367  ...       True         25\n",
              " 3             LightGBMCustom   -0.727152  ...       True         12\n",
              " 4           RandomForestEntr   -0.732582  ...       True          5\n",
              " 5           RandomForestGini   -0.733132  ...       True          4\n",
              " 6      RandomForestEntr_FULL   -0.739633  ...       True         18\n",
              " 7            LightGBMXT_FULL   -0.740451  ...       True         22\n",
              " 8              LightGBM_FULL   -0.740659  ...       True         21\n",
              " 9               XGBoost_FULL   -0.740821  ...       True         24\n",
              " 10     RandomForestGini_FULL   -0.742527  ...       True         17\n",
              " 11                  LightGBM   -0.744328  ...       True          8\n",
              " 12                   XGBoost   -0.747064  ...       True         11\n",
              " 13                LightGBMXT   -0.751898  ...       True          9\n",
              " 14             CatBoost_FULL   -0.759973  ...       True         23\n",
              " 15                  CatBoost   -0.767169  ...       True         10\n",
              " 16            NeuralNetMXNet   -0.789505  ...       True          1\n",
              " 17       NeuralNetMXNet_FULL   -0.793439  ...       True         14\n",
              " 18       ExtraTreesEntr_FULL   -0.851026  ...       True         20\n",
              " 19            ExtraTreesEntr   -0.858440  ...       True          7\n",
              " 20       ExtraTreesGini_FULL   -0.861652  ...       True         19\n",
              " 21            ExtraTreesGini   -0.861773  ...       True          6\n",
              " 22       KNeighborsDist_FULL   -2.245269  ...       True         16\n",
              " 23            KNeighborsDist   -2.276212  ...       True          3\n",
              " 24       KNeighborsUnif_FULL   -2.276870  ...       True         15\n",
              " 25            KNeighborsUnif   -2.312183  ...       True          2\n",
              " \n",
              " [26 rows x 12 columns]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKOCDVxd0Dag"
      },
      "source": [
        "## ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puXFps6A_e78",
        "outputId": "6a509094-c3a1-4f65-ac5e-0d95b3f0563d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AutogluonModels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouIOKIB8_naW",
        "outputId": "703fc1e7-113e-4fb8-9093-4275f5af2df3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mag-20210520_034147\u001b[0m/  \u001b[01;34mag-20210520_042546\u001b[0m/  \u001b[01;34mag-20210520_050345\u001b[0m/\n",
            "\u001b[01;34mag-20210520_035217\u001b[0m/  \u001b[01;34mag-20210520_043605\u001b[0m/  \u001b[01;34mag-20210520_051121\u001b[0m/\n",
            "\u001b[01;34mag-20210520_040246\u001b[0m/  \u001b[01;34mag-20210520_044500\u001b[0m/\n",
            "\u001b[01;34mag-20210520_041351\u001b[0m/  \u001b[01;34mag-20210520_045555\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPF0BE1mAbyY"
      },
      "source": [
        "awef = []\n",
        "for x in range(len(predictors)):\n",
        "  for y in range(len(ldbd[x])):\n",
        "    if ldbd[x]['model'][y] == \"WeightedEnsemble_FULL_L1\" or ldbd[x]['model'][y] == \"WeightedEnsemble_L1\" or ldbd[x]['model'][y] == \"LightGBMCustom_FULL\":\n",
        "      awef.append(y)\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDViPXqLBnK9",
        "outputId": "d11097fd-7579-4977-c8bb-ada3d9fc602b"
      },
      "source": [
        "awef"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAHLRoaA-2mj",
        "outputId": "0e553e84-2b0f-4be0-ef47-329562af7af8"
      },
      "source": [
        "kf = []\n",
        "ite = 0\n",
        "for x in range(len(predictors)):\n",
        "  print(ldbd[x]['model'][awef[x]])\n",
        "  if ldbd[x]['model'][awef[x]] == \"RandomForestGini_FULL\":\n",
        "    pass\n",
        "  else:\n",
        "    kf.append(predictors[x].predict_proba(test, model = ldbd[x]['model'][awef[x]], as_pandas=True, as_multiclass=True))\n",
        "    ite += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n",
            "WeightedEnsemble_FULL_L1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukVJGmrcMG4z"
      },
      "source": [
        "kf = []\n",
        "for x in range(len(predictors)):\n",
        "  kf.append(predictors[x].predict_proba(test, model = ldbd[x]['model'][0], as_pandas=True, as_multiclass=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxeOtg70193a",
        "outputId": "c812b579-c502-427b-c55c-b09dd903554f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([31375, 34703, 26701, 27141, 27273, 30423, 30486, 30562, 31647,\n",
              "            32065, 32462, 34224, 35699, 26680, 29157, 30180, 30211, 31211,\n",
              "            36021],\n",
              "           dtype='int64', name='index')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boor086mslgG"
      },
      "source": [
        "a = 0\n",
        "for x in range(ite):\n",
        "  a += kf[x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6HVU40qbf0n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "JPRGg2PSbfu8",
        "outputId": "591be890-2d17-436a-d050-f198cccb2263"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26457</th>\n",
              "      <td>0.423114</td>\n",
              "      <td>1.101500</td>\n",
              "      <td>8.475386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26458</th>\n",
              "      <td>3.966882</td>\n",
              "      <td>1.763964</td>\n",
              "      <td>4.269154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26459</th>\n",
              "      <td>0.467913</td>\n",
              "      <td>0.749952</td>\n",
              "      <td>8.782135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26460</th>\n",
              "      <td>1.198020</td>\n",
              "      <td>0.965532</td>\n",
              "      <td>7.836447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26461</th>\n",
              "      <td>0.749377</td>\n",
              "      <td>1.944211</td>\n",
              "      <td>7.306413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36452</th>\n",
              "      <td>0.944189</td>\n",
              "      <td>4.595446</td>\n",
              "      <td>4.460365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36453</th>\n",
              "      <td>1.917490</td>\n",
              "      <td>4.667751</td>\n",
              "      <td>3.414759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36454</th>\n",
              "      <td>0.176703</td>\n",
              "      <td>0.660081</td>\n",
              "      <td>9.163217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36455</th>\n",
              "      <td>3.422404</td>\n",
              "      <td>1.868900</td>\n",
              "      <td>4.708696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36456</th>\n",
              "      <td>0.832395</td>\n",
              "      <td>2.709521</td>\n",
              "      <td>6.458084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0.0       1.0       2.0\n",
              "index                              \n",
              "26457  0.423114  1.101500  8.475386\n",
              "26458  3.966882  1.763964  4.269154\n",
              "26459  0.467913  0.749952  8.782135\n",
              "26460  1.198020  0.965532  7.836447\n",
              "26461  0.749377  1.944211  7.306413\n",
              "...         ...       ...       ...\n",
              "36452  0.944189  4.595446  4.460365\n",
              "36453  1.917490  4.667751  3.414759\n",
              "36454  0.176703  0.660081  9.163217\n",
              "36455  3.422404  1.868900  4.708696\n",
              "36456  0.832395  2.709521  6.458084\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3ZqBgclM6ZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "d8e24be5-c07b-4580-9e62-59e597bbba16"
      },
      "source": [
        "k = a.sort_index()\n",
        "k.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26457</th>\n",
              "      <td>0.423114</td>\n",
              "      <td>1.101500</td>\n",
              "      <td>8.475386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26458</th>\n",
              "      <td>3.966882</td>\n",
              "      <td>1.763964</td>\n",
              "      <td>4.269154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26459</th>\n",
              "      <td>0.467913</td>\n",
              "      <td>0.749952</td>\n",
              "      <td>8.782135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26460</th>\n",
              "      <td>1.198020</td>\n",
              "      <td>0.965532</td>\n",
              "      <td>7.836447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26461</th>\n",
              "      <td>0.749377</td>\n",
              "      <td>1.944211</td>\n",
              "      <td>7.306413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26462</th>\n",
              "      <td>0.384085</td>\n",
              "      <td>0.740432</td>\n",
              "      <td>8.875484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26463</th>\n",
              "      <td>3.907071</td>\n",
              "      <td>5.938968</td>\n",
              "      <td>0.153960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26464</th>\n",
              "      <td>0.651161</td>\n",
              "      <td>0.869707</td>\n",
              "      <td>8.479134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26465</th>\n",
              "      <td>0.560777</td>\n",
              "      <td>1.032261</td>\n",
              "      <td>8.406962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26466</th>\n",
              "      <td>0.312622</td>\n",
              "      <td>2.723127</td>\n",
              "      <td>6.964252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0.0       1.0       2.0\n",
              "index                              \n",
              "26457  0.423114  1.101500  8.475386\n",
              "26458  3.966882  1.763964  4.269154\n",
              "26459  0.467913  0.749952  8.782135\n",
              "26460  1.198020  0.965532  7.836447\n",
              "26461  0.749377  1.944211  7.306413\n",
              "26462  0.384085  0.740432  8.875484\n",
              "26463  3.907071  5.938968  0.153960\n",
              "26464  0.651161  0.869707  8.479134\n",
              "26465  0.560777  1.032261  8.406962\n",
              "26466  0.312622  2.723127  6.964252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8TIUF2utbUi"
      },
      "source": [
        "# FINISHED!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54tCs3UUNAA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a3c75f-5a01-44a1-d84a-940ad314e18a"
      },
      "source": [
        "cd /content/drive/MyDrive/mtfk/results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/mtfk/results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnP1qBE1ubRS"
      },
      "source": [
        "a = sub.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6B9rfkiND_y"
      },
      "source": [
        "sub['0'] = k[0]\n",
        "sub['1'] = k[1]\n",
        "sub['2'] = k[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rnS_1RCbU0_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYEoDeeNuQME"
      },
      "source": [
        "k = (sub + a)/ite"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKPVR_7J11i9"
      },
      "source": [
        "test_t = abnorm_collec(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkZecvjM2L25"
      },
      "source": [
        "abn = k.loc[test_t.index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk2VCmV33Z_x",
        "outputId": "626327a0-4306-4f7d-eafe-6dbef4446625"
      },
      "source": [
        "for x in range(len(k.loc[test_t.index])):\n",
        "  print(x)\n",
        "  abn.iloc[x]['0'] = 0.00\n",
        "  abn.iloc[x]['1'] = 0.00\n",
        "  abn.iloc[x]['2'] = 1.00\n",
        "abn.iloc[x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "Name: 35063, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vOfpGJx2drY"
      },
      "source": [
        "k.loc[abn.index] = abn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "0UhFo9wo2T47",
        "outputId": "72008710-4710-4c18-f928-f27842c27e99"
      },
      "source": [
        "k.loc[test_t.index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31375</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34703</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26701</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27141</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27273</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30423</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30486</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30562</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31647</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32065</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32462</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34224</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35699</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27179</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27774</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32371</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32340</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33366</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33559</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35063</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0    1    2\n",
              "index               \n",
              "31375  0.0  0.0  1.0\n",
              "34703  0.0  0.0  1.0\n",
              "26701  0.0  0.0  1.0\n",
              "27141  0.0  0.0  1.0\n",
              "27273  0.0  0.0  1.0\n",
              "30423  0.0  0.0  1.0\n",
              "30486  0.0  0.0  1.0\n",
              "30562  0.0  0.0  1.0\n",
              "31647  0.0  0.0  1.0\n",
              "32065  0.0  0.0  1.0\n",
              "32462  0.0  0.0  1.0\n",
              "34224  0.0  0.0  1.0\n",
              "35699  0.0  0.0  1.0\n",
              "27179  0.0  0.0  1.0\n",
              "27774  0.0  0.0  1.0\n",
              "32371  0.0  0.0  1.0\n",
              "32340  0.0  0.0  1.0\n",
              "33366  0.0  0.0  1.0\n",
              "33559  0.0  0.0  1.0\n",
              "35063  0.0  0.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "9YtNQj2qdJ6q",
        "outputId": "7fade679-f3eb-4ff1-9eb3-bbba21a3849a"
      },
      "source": [
        "k.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26457</th>\n",
              "      <td>0.042311</td>\n",
              "      <td>0.110150</td>\n",
              "      <td>0.847539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26458</th>\n",
              "      <td>0.396688</td>\n",
              "      <td>0.176396</td>\n",
              "      <td>0.426915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26459</th>\n",
              "      <td>0.046791</td>\n",
              "      <td>0.074995</td>\n",
              "      <td>0.878214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26460</th>\n",
              "      <td>0.119802</td>\n",
              "      <td>0.096553</td>\n",
              "      <td>0.783645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26461</th>\n",
              "      <td>0.074938</td>\n",
              "      <td>0.194421</td>\n",
              "      <td>0.730641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26462</th>\n",
              "      <td>0.038409</td>\n",
              "      <td>0.074043</td>\n",
              "      <td>0.887548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26463</th>\n",
              "      <td>0.390707</td>\n",
              "      <td>0.593897</td>\n",
              "      <td>0.015396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26464</th>\n",
              "      <td>0.065116</td>\n",
              "      <td>0.086971</td>\n",
              "      <td>0.847913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26465</th>\n",
              "      <td>0.056078</td>\n",
              "      <td>0.103226</td>\n",
              "      <td>0.840696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26466</th>\n",
              "      <td>0.031262</td>\n",
              "      <td>0.272313</td>\n",
              "      <td>0.696425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2\n",
              "index                              \n",
              "26457  0.042311  0.110150  0.847539\n",
              "26458  0.396688  0.176396  0.426915\n",
              "26459  0.046791  0.074995  0.878214\n",
              "26460  0.119802  0.096553  0.783645\n",
              "26461  0.074938  0.194421  0.730641\n",
              "26462  0.038409  0.074043  0.887548\n",
              "26463  0.390707  0.593897  0.015396\n",
              "26464  0.065116  0.086971  0.847913\n",
              "26465  0.056078  0.103226  0.840696\n",
              "26466  0.031262  0.272313  0.696425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLJjPuRxvOJC"
      },
      "source": [
        "k.to_csv('K_fold_auto_10times_reshape_log_loss_abnremoved.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpvfuOS3Uezj",
        "outputId": "7cd28f84-0401-4c9d-c7e5-21823e21ebd5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "vlbOW9nx8HzP",
        "outputId": "1d8861e2-2544-4f7d-fb33-fadce310794b"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26457</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26458</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26459</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26460</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26461</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36452</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36453</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36454</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36455</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36456</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0  1  2\n",
              "index         \n",
              "26457  0  0  0\n",
              "26458  0  0  0\n",
              "26459  0  0  0\n",
              "26460  0  0  0\n",
              "26461  0  0  0\n",
              "...   .. .. ..\n",
              "36452  0  0  0\n",
              "36453  0  0  0\n",
              "36454  0  0  0\n",
              "36455  0  0  0\n",
              "36456  0  0  0\n",
              "\n",
              "[10000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T0aiHK8UwCj"
      },
      "source": [
        "a = pd.read_csv(output_directory+\"/K_fold_auto_13times.csv\",index_col=index)\n",
        "b = pd.read_csv(output_directory+\"/Old_beksu.csv\",index_col=index)\n",
        "d = pd.read_csv(output_directory+\"/Longest_iter.csv\",index_col=index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYXhVrrzWIoO"
      },
      "source": [
        "e = (a + b  + d )/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6NmIUKK5tI0",
        "outputId": "a254b4a7-f1fe-4c69-f60a-3b95c6f77279"
      },
      "source": [
        "for x in range(len(e.loc[test_t.index])):\n",
        "  print(x)\n",
        "  abn.iloc[x]['0'] = 0.00\n",
        "  abn.iloc[x]['1'] = 0.00\n",
        "  abn.iloc[x]['2'] = 1.00\n",
        "abn.iloc[x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.0\n",
              "1    0.0\n",
              "2    1.0\n",
              "Name: 35063, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmmWA35j5ydF"
      },
      "source": [
        "e.loc[abn.index] = abn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcNlGL5SWK4V"
      },
      "source": [
        "e.to_csv(\"This_is_my_last.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpPTzNJf5Yat"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}