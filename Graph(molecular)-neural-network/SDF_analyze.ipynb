{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDF_analyze.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1dqGUzaMZxBueIBnJWp6QUirrobKJKIZc",
      "authorship_tag": "ABX9TyNpyqCOwyezu41OlNs5CE2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkhy0106/HolyMoly/blob/master/Graph(molecular)-neural-network/SDF_analyze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfDXtzisJzw3",
        "outputId": "6440385d-cb5e-481d-feee-054cf871da18"
      },
      "source": [
        "!pip3 install pip install rdkit-pypi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.3.4-cp37-cp37m-manylinux2014_x86_64.whl (18.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2021.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhcLThSJLSiB"
      },
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5_3VO4REGAa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf9b26d-f391-4461-d9bc-e9bccaf8c69c"
      },
      "source": [
        "import os \n",
        "path = './drive/MyDrive/235789_Samsung AI Challenge for Scientific Discovery_data.zip (Unzipped Files)/dev_sdf' \n",
        "file_list = os.listdir(path) \n",
        "print (len(file_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxKBuPDZU4N7",
        "outputId": "fb3b6b42-812b-4e08-e9fc-90b6d0dc4111"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grltFNO40nmQ"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/235789_Samsung AI Challenge for Scientific Discovery_data.zip (Unzipped Files)' '/content/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ynoM4da05RB"
      },
      "source": [
        "!rm -r '/content/data/train_sdf'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkiA3cyXUkjs"
      },
      "source": [
        "!cp -r '/content/drive/MyDrive/235789_Samsung AI Challenge for Scientific Discovery_data.zip (Unzipped Files)/train_sdf' '/content/data/train_sdf'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv00WKb-mK11"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from rdkit.Chem.Draw import SimilarityMaps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxjIdD6SUbej"
      },
      "source": [
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "from matplotlib.figure import Figure\n",
        "from rdkit import DataStructs\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow as imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWpm4bHBmNgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77f6688-b843-49fc-e5b7-bff5e43d468c"
      },
      "source": [
        "print('numpy verison :', np.__version__)\n",
        "print('pandas version :', pd.__version__)\n",
        "print('opencv version :', cv2.__version__)\n",
        "print('rdkit version :', rdkit.__version__)\n",
        "print('torch version :', torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "numpy verison : 1.19.5\n",
            "pandas version : 1.1.5\n",
            "opencv version : 4.1.2\n",
            "rdkit version : 2021.03.4\n",
            "torch version : 1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYHHHToamRT1"
      },
      "source": [
        "train = pd.read_csv('./data/train.csv')\n",
        "dev = pd.read_csv('./data/dev.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6Lkhz6nIxR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "731ec6c5-ec73-4b44-9f5f-e444e54d2591"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>S1_energy(eV)</th>\n",
              "      <th>T1_energy(eV)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_0</td>\n",
              "      <td>CCC1CCCCN1C(=O)C(C)OC(=O)c1c(C)oc(-n2cccc2)c1C#N</td>\n",
              "      <td>4.6747</td>\n",
              "      <td>3.3809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_1</td>\n",
              "      <td>COc1ccc(Oc2ccc(N3C(=S)NC(c4ccccn4)C3c3cc(C)n(-...</td>\n",
              "      <td>3.6617</td>\n",
              "      <td>3.4585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2</td>\n",
              "      <td>CC(=O)Nc1ccc(C(=O)[C@H](C)Sc2nnc(C3CCCCC3)o2)cc1</td>\n",
              "      <td>3.6420</td>\n",
              "      <td>3.1787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3</td>\n",
              "      <td>OC(CNC1CC1)CN1CCc2sccc2C1</td>\n",
              "      <td>4.8901</td>\n",
              "      <td>3.7847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_4</td>\n",
              "      <td>CCNC(CCCC(F)(F)F)C1(OCC)CCOCC1</td>\n",
              "      <td>6.4967</td>\n",
              "      <td>6.2724</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       uid  ... T1_energy(eV)\n",
              "0  train_0  ...        3.3809\n",
              "1  train_1  ...        3.4585\n",
              "2  train_2  ...        3.1787\n",
              "3  train_3  ...        3.7847\n",
              "4  train_4  ...        6.2724\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv_W0ZWYnJ6Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b70cc390-9628-414d-fd7e-ea06b00f4296"
      },
      "source": [
        "dev.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>S1_energy(eV)</th>\n",
              "      <th>T1_energy(eV)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dev_0</td>\n",
              "      <td>O=C1c2ccccc2C2(c3ccccc31)c1ccccc1N(c1ccc(-c3nc...</td>\n",
              "      <td>2.7609</td>\n",
              "      <td>2.7540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dev_1</td>\n",
              "      <td>Cc1cccc2c3ccccc3n(-c3ccc(-c4c(-c5ccccc5)c(C#N)...</td>\n",
              "      <td>3.0495</td>\n",
              "      <td>3.0163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dev_2</td>\n",
              "      <td>CC1(C)c2ccccc2-c2ccc(-c3c(F)c(F)c(-c4ccc5c(c4)...</td>\n",
              "      <td>2.8314</td>\n",
              "      <td>2.1412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dev_3</td>\n",
              "      <td>CC(C)(C)c1ccc2c(c1)B1c3cc(C(C)(C)C)ccc3Oc3cc(-...</td>\n",
              "      <td>3.1813</td>\n",
              "      <td>2.9424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dev_4</td>\n",
              "      <td>O=C1c2cc(-c3ccc4c(c3)c3ccccc3n4-c3ccccc3)ccc2S...</td>\n",
              "      <td>2.9559</td>\n",
              "      <td>2.7362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     uid  ... T1_energy(eV)\n",
              "0  dev_0  ...        2.7540\n",
              "1  dev_1  ...        3.0163\n",
              "2  dev_2  ...        2.1412\n",
              "3  dev_3  ...        2.9424\n",
              "4  dev_4  ...        2.7362\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LyB-fGlnKsT"
      },
      "source": [
        "train = pd.concat([train, dev])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-1YrB4jnLk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f3a1b7fb-ee51-4a6b-843e-991d0c24d340"
      },
      "source": [
        "train['S1_energy(eV)'].hist(bins=100, alpha=0.5)\n",
        "train['T1_energy(eV)'].hist(bins=100, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSwuRMdiQYlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d239ba9b-4cff-4b1f-c513-ff899d2d0969"
      },
      "source": [
        "!rm -r '/content/data/train_imgs'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/data/train_imgs': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGCTUPBtdvj9"
      },
      "source": [
        "!mkdir '/content/data/train_imgs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyRMPdYw3bOc"
      },
      "source": [
        "import gc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joYIhjVgnPLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2040c1-b499-4fbb-e482-2dc6451f5d80"
      },
      "source": [
        "plt.ioff()\n",
        "for idx, row in tqdm(train.iterrows()):\n",
        "    if idx <= 29628:\n",
        "       continue\n",
        "    file = row['uid']\n",
        "    smiles = row['SMILES']\n",
        "    m = Chem.MolFromSmiles(smiles)\n",
        "    if m != None:\n",
        "        AllChem.ComputeGasteigerCharges(m)\n",
        "        mol = m\n",
        "        contribs = [mol.GetAtomWithIdx(i).GetDoubleProp('_GasteigerCharge') for i in range(mol.GetNumAtoms())]\n",
        "        fig = SimilarityMaps.GetSimilarityMapFromWeights(mol, contribs, colorMap='jet', contourLines=10,size=(300,300))\n",
        "        plt.close(fig)\n",
        "        fig.savefig(f'data/train_imgs/{file}.png',bbox_inches='tight',dpi=39) #dpi 39 = 300x300 pix 1dpi = 0.1299\n",
        "        del contribs, m, fig\n",
        "        gc.collect()\n",
        "plt.ion()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30345it [03:13, 156.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya13IrCqoQNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "c3680702-d54d-4ddc-a78c-72c89526c9c8"
      },
      "source": [
        "sample_img = cv2.imread('./data/train_imgs/dev_0.png')\n",
        "plt.imshow(sample_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9bc4b9d9e5d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/train_imgs/dev_0.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/patches/__init__.py\u001b[0m in \u001b[0;36mcv2_imshow\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \"\"\"\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0;31m# cv2 stores colors as BGR; convert to RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'clip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWdjiENRoRLa"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 25\n",
        "num_layers = 1\n",
        "dropout_rate = 0.1\n",
        "embedding_dim = 128\n",
        "learning_rate = 1e-4\n",
        "vision_pretrain = True\n",
        "save_path = f'./models/best_model.pt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4QFea2EoTx0"
      },
      "source": [
        "class SMILES_Tokenizer():\n",
        "    def __init__(self, max_length):\n",
        "        self.txt2idx = {}\n",
        "        self.idx2txt = {}\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def fit(self, SMILES_list):\n",
        "        unique_char = set()\n",
        "        for smiles in SMILES_list:\n",
        "            for char in smiles:\n",
        "                unique_char.add(char)\n",
        "        unique_char = sorted(list(unique_char))\n",
        "        for i, char in enumerate(unique_char):\n",
        "            self.txt2idx[char]=i+2\n",
        "            self.idx2txt[i+2]=char\n",
        "            \n",
        "    def txt2seq(self, texts):\n",
        "        seqs = []\n",
        "        for text in tqdm(texts):\n",
        "            seq = [0]*self.max_length\n",
        "            for i, t in enumerate(text):\n",
        "                if i == self.max_length:\n",
        "                    break\n",
        "                try:\n",
        "                    seq[i] = self.txt2idx[t]\n",
        "                except:\n",
        "                    seq[i] = 1\n",
        "            seqs.append(seq)\n",
        "        return np.array(seqs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99vmqYFoofVh"
      },
      "source": [
        "max_len = train.SMILES.str.len().max()\n",
        "max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgtnq8GKK1nO"
      },
      "source": [
        "tokenizer = SMILES_Tokenizer(max_len)\n",
        "tokenizer.fit(train.SMILES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO7w-AlJUJns"
      },
      "source": [
        "seqs = tokenizer.txt2seq(train.SMILES)\n",
        "labels = train[['S1_energy(eV)', 'T1_energy(eV)']].to_numpy()\n",
        "imgs = ('./data/train_imgs/'+train.uid+'.png').to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWesqOqAU8hi"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "imgs, seqs, labels = shuffle(imgs, seqs, labels, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UTqxH2A6NE6"
      },
      "source": [
        "train_imgs = imgs[:27000]\n",
        "train_seqs = seqs[:27000]\n",
        "train_labels = labels[:27000]\n",
        "val_imgs = imgs[27000:]\n",
        "val_seqs = seqs[27000:]\n",
        "val_labels = labels[27000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27VL_3Q16O9Y"
      },
      "source": [
        "train_imgs.shape, train_seqs.shape, train_labels.shape, val_imgs.shape, val_seqs.shape, val_labels.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK1pyEYL6P1Q"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, imgs, seqs, labels=None, mode='train'):\n",
        "        self.mode = mode\n",
        "        self.imgs = imgs\n",
        "        self.seqs = seqs\n",
        "        if self.mode=='train':\n",
        "            self.labels = labels\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        img = cv2.imread(self.imgs[i]).astype(np.float32)/255\n",
        "        img = np.transpose(img, (2,0,1))\n",
        "        if self.mode == 'train':\n",
        "            return {\n",
        "                'img' : torch.tensor(img, dtype=torch.float32),\n",
        "                'seq' : torch.tensor(self.seqs[i], dtype=torch.long),\n",
        "                'label' : torch.tensor(self.labels[i], dtype=torch.float32)\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'img' : torch.tensor(img, dtype=torch.float32),\n",
        "                'seq' : torch.tensor(self.seqs[i], dtype=torch.long),\n",
        "            }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvMHZ-zN6dKS"
      },
      "source": [
        "train_dataset = CustomDataset(train_imgs, train_seqs, train_labels)\n",
        "val_dataset = CustomDataset(val_imgs, val_seqs, val_labels)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EApdilJEAFgi"
      },
      "source": [
        "sample_batch['img'].size(), sample_batch['seq'].size(), sample_batch['label'].size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1f6dWySAuI1"
      },
      "source": [
        "sample_batch['img'].dtype, sample_batch['seq'].dtype, sample_batch['label'].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4NSHvei_gMr"
      },
      "source": [
        "class CNN_Encoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, rate):\n",
        "        super(CNN_Encoder, self).__init__()\n",
        "        model = models.resnet50(pretrained=vision_pretrain)\n",
        "        modules = list(model.children())[:-2]\n",
        "        self.feature_extract_model = nn.Sequential(*modules)\n",
        "        self.dropout1 = nn.Dropout(rate)\n",
        "        self.fc = nn.Linear(2048, embedding_dim)\n",
        "        self.dropout2 = nn.Dropout(rate)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.feature_extract_model(x)\n",
        "        x = x.permute(0,2,3,1)\n",
        "        x = x.view(x.size(0), -1, x.size(3))\n",
        "        x = self.dropout1(x)\n",
        "        x = nn.ReLU()(self.fc(x))\n",
        "        x = self.dropout2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY7lZftH_eYU"
      },
      "source": [
        "class RNN_Decoder(nn.Module):\n",
        "    def __init__(self, max_len, embedding_dim, num_layers, rate):\n",
        "        super(RNN_Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(max_len, embedding_dim)\n",
        "        self.dropout = nn.Dropout(rate)\n",
        "        self.lstm = nn.LSTM(embedding_dim, embedding_dim, num_layers)\n",
        "        self.final_layer = nn.Linear((max_len+100)*embedding_dim, 2)\n",
        "\n",
        "    def forward(self, enc_out, dec_inp):\n",
        "        embedded = self.embedding(dec_inp)\n",
        "        embedded = self.dropout(embedded)\n",
        "        embedded = torch.cat([enc_out, embedded], dim=1)\n",
        "        hidden, _ = self.lstm(embedded)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        output = nn.ReLU()(self.final_layer(hidden))\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL_H5ApeUbaz"
      },
      "source": [
        "class CNN2RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, max_len, num_layers, rate):\n",
        "        super(CNN2RNN, self).__init__()\n",
        "        self.cnn = CNN_Encoder(embedding_dim, rate)\n",
        "        self.rnn = RNN_Decoder(max_len, embedding_dim, num_layers, rate)\n",
        "        \n",
        "    def forward(self, img, seq):\n",
        "        cnn_output = self.cnn(img)\n",
        "        output = self.rnn(cnn_output, seq)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0DbaCLzpLwO"
      },
      "source": [
        "model = CNN2RNN(embedding_dim=embedding_dim, max_len=max_len, num_layers=num_layers, rate=dropout_rate)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNqz6PXwpM0U"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.L1Loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM26QcXKpOzi"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training):\n",
        "    img = batch_item['img'].to(device)\n",
        "    seq = batch_item['seq'].to(device)\n",
        "    label = batch_item['label'].to(device)\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(img, seq)\n",
        "            loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        return loss\n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(img, seq)\n",
        "            loss = criterion(output, label)\n",
        "            \n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t0rDb8HpQsD"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1))\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss = train_step(batch_item, epoch, batch, training)\n",
        "        total_val_loss += batch_loss\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1))\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    \n",
        "    if np.min(val_loss_plot) == val_loss_plot[-1]:\n",
        "        torch.save(model, save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8O5uq8lpSNP"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss(mae)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR9o3QyzpTlj"
      },
      "source": [
        "모델 복원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjAhhvtjpTJo"
      },
      "source": [
        "model = torch.load(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNezg8fvpVuO"
      },
      "source": [
        "테스트 데이터 및 제출 양식 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_gfox_spVQG"
      },
      "source": [
        "test = pd.read_csv('./data/test.csv')\n",
        "submission = pd.read_csv('./data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It8L0v-MpXE1"
      },
      "source": [
        "for idx, row in tqdm(test.iterrows()):\n",
        "    file = row['uid']\n",
        "    smiles = row['SMILES']\n",
        "    m = Chem.MolFromSmiles(smiles)\n",
        "    if m != None:\n",
        "        img = Draw.MolToImage(m, size=(300,300))\n",
        "        img.save(f'./data/test_imgs/{file}.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hziiRQAOpYvH"
      },
      "source": [
        "test_seqs = tokenizer.txt2seq(test.SMILES)\n",
        "test_imgs = ('./data/test_imgs/'+test.uid+'.png').to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ORS18YCpan_"
      },
      "source": [
        "test_dataset = CustomDataset(imgs=test_imgs, seqs=test_seqs, labels=None, mode='test')\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, num_workers=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmPrAlOJpbyH"
      },
      "source": [
        "추론 및 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOc9Tei0pbbB"
      },
      "source": [
        "def predict(dataset):\n",
        "    model.eval()\n",
        "    result = []\n",
        "    for batch_item in dataset:\n",
        "        img = batch_item['img'].to(device)\n",
        "        seq = batch_item['seq'].to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(img, seq)\n",
        "        output = output.cpu().numpy()\n",
        "        gap = output[:, 0] - output[:, 1]\n",
        "        gap = np.where(gap<0, 0, gap)\n",
        "        result.extend(list(gap))\n",
        "        \n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbjm2M-tpdj1"
      },
      "source": [
        "pred = predict(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKi4rxU3peiN"
      },
      "source": [
        "submission['ST1_GAP(eV)'] = pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wp_oXk3pfaN"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwvNXqrVpgod"
      },
      "source": [
        "submission.to_csv('/content/drive/MyDrive/235789_Samsung AI Challenge for Scientific Discovery_data.zip (Unzipped Files)/dacon_baseline.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}