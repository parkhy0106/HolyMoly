{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "OTGNN_custom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1OprT_uak_mmK1B9B1YLTd3c9wFXLzh5a",
      "authorship_tag": "ABX9TyMQOyi5p/Mafq9bQWVJaS0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkhy0106/HolyMoly/blob/master/Graph(molecular)-neural-network/OTGNN_custom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3S8wVOgjWN-",
        "outputId": "7bc8d6ea-cc7c-42a0-cef8-951a65a59753"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38FfQKeKjjol",
        "outputId": "a7d02ad6-9a3e-4c72-f826-653c7101d905"
      },
      "source": [
        "%env PYTHONPATH="
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca2BpyNZjnyq",
        "outputId": "6e54882d-bcfe-4460-e985-8349ce83512a"
      },
      "source": [
        "%%bash\n",
        "\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "--2021-09-08 11:27:58--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2021-09-08 11:27:58--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 6.81M 8s\n",
            "    50K .......... .......... .......... .......... ..........  0% 6.92M 8s\n",
            "   100K .......... .......... .......... .......... ..........  0% 20.7M 6s\n",
            "   150K .......... .......... .......... .......... ..........  0% 20.5M 5s\n",
            "   200K .......... .......... .......... .......... ..........  0% 12.8M 5s\n",
            "   250K .......... .......... .......... .......... ..........  0% 23.5M 5s\n",
            "   300K .......... .......... .......... .......... ..........  0% 31.1M 4s\n",
            "   350K .......... .......... .......... .......... ..........  0% 35.8M 4s\n",
            "   400K .......... .......... .......... .......... ..........  0% 28.8M 4s\n",
            "   450K .......... .......... .......... .......... ..........  0% 44.6M 3s\n",
            "   500K .......... .......... .......... .......... ..........  0% 54.1M 3s\n",
            "   550K .......... .......... .......... .......... ..........  1% 40.0M 3s\n",
            "   600K .......... .......... .......... .......... ..........  1% 47.2M 3s\n",
            "   650K .......... .......... .......... .......... ..........  1% 41.7M 3s\n",
            "   700K .......... .......... .......... .......... ..........  1%  233M 3s\n",
            "   750K .......... .......... .......... .......... ..........  1% 51.2M 3s\n",
            "   800K .......... .......... .......... .......... ..........  1% 59.1M 2s\n",
            "   850K .......... .......... .......... .......... ..........  1% 97.7M 2s\n",
            "   900K .......... .......... .......... .......... ..........  1%  119M 2s\n",
            "   950K .......... .......... .......... .......... ..........  1% 57.7M 2s\n",
            "  1000K .......... .......... .......... .......... ..........  1% 71.2M 2s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 46.4M 2s\n",
            "  1100K .......... .......... .......... .......... ..........  2%  129M 2s\n",
            "  1150K .......... .......... .......... .......... ..........  2% 59.6M 2s\n",
            "  1200K .......... .......... .......... .......... ..........  2%  230M 2s\n",
            "  1250K .......... .......... .......... .......... ..........  2% 84.9M 2s\n",
            "  1300K .......... .......... .......... .......... ..........  2%  111M 2s\n",
            "  1350K .......... .......... .......... .......... ..........  2% 88.7M 2s\n",
            "  1400K .......... .......... .......... .......... ..........  2%  260M 2s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  106M 2s\n",
            "  1500K .......... .......... .......... .......... ..........  2%  111M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2%  117M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2%  117M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2%  108M 1s\n",
            "  1700K .......... .......... .......... .......... ..........  3%  170M 1s\n",
            "  1750K .......... .......... .......... .......... ..........  3%  144M 1s\n",
            "  1800K .......... .......... .......... .......... ..........  3%  229M 1s\n",
            "  1850K .......... .......... .......... .......... ..........  3%  166M 1s\n",
            "  1900K .......... .......... .......... .......... ..........  3%  175M 1s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  130M 1s\n",
            "  2000K .......... .......... .......... .......... ..........  3%  166M 1s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  286M 1s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  173M 1s\n",
            "  2150K .......... .......... .......... .......... ..........  3% 98.5M 1s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  166M 1s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  145M 1s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  149M 1s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  131M 1s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  110M 1s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  155M 1s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  169M 1s\n",
            "  2550K .......... .......... .......... .......... ..........  4%  101M 1s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  155M 1s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  166M 1s\n",
            "  2700K .......... .......... .......... .......... ..........  4%  112M 1s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  137M 1s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  105M 1s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  115M 1s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  124M 1s\n",
            "  2950K .......... .......... .......... .......... ..........  5% 85.6M 1s\n",
            "  3000K .......... .......... .......... .......... ..........  5% 97.8M 1s\n",
            "  3050K .......... .......... .......... .......... ..........  5% 82.3M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5% 69.3M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5% 45.3M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5% 55.6M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5% 62.1M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5% 45.1M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  152M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  291M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  177M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  146M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  261M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  245M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  178M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  164M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  252M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  303M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  150M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  147M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  234M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  167M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  294M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  299M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  118M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  155M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  292M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  268M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  255M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  295M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  293M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  284M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  240M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8% 84.9M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  285M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  159M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  245M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  161M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  164M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  291M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  221M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  117M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  162M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  150M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  151M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  277M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  105M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  289M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  146M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  164M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  269M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  126M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9%  225M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  173M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  295M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  273M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  230M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  298M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  293M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  271M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  270M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10% 53.7M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  308M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  244M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10% 85.6M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  292M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  281M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  119M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  138M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  172M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  280M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  282M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11% 94.6M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  211M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  105M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  170M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  259M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  173M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  164M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  267M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  246M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  294M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  300M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  272M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  261M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  291M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  299M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  302M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12% 50.4M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13%  104M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  285M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  295M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  269M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  304M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13% 96.3M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  171M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  154M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  259M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  161M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  174M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  264M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  267M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  119M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  157M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  243M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  115M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  289M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  287M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  268M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14%  268M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  301M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  298M 0s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  244M 0s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  303M 0s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  291M 0s\n",
            "  8700K .......... .......... .......... .......... .......... 15% 56.5M 0s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  110M 0s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  299M 0s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  299M 0s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  305M 0s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  242M 0s\n",
            "  9000K .......... .......... .......... .......... .......... 15% 88.7M 0s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  177M 0s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  270M 0s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  149M 0s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  157M 0s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  256M 0s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  291M 0s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  235M 0s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  309M 0s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  299M 0s\n",
            "  9500K .......... .......... .......... .......... .......... 16% 64.0M 0s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  163M 0s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  302M 0s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  295M 0s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  276M 0s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  248M 0s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  297M 0s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  294M 0s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  303M 0s\n",
            "  9950K .......... .......... .......... .......... .......... 17%  269M 0s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  272M 0s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  300M 0s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  211M 0s\n",
            " 10150K .......... .......... .......... .......... .......... 17% 43.8M 0s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  296M 0s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  280M 0s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  282M 0s\n",
            " 10350K .......... .......... .......... .......... .......... 18% 76.0M 0s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  262M 0s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  142M 0s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  105M 0s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  228M 0s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  278M 0s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  302M 0s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  299M 0s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  262M 0s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  291M 0s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  212M 0s\n",
            " 10900K .......... .......... .......... .......... .......... 19% 82.7M 0s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  141M 0s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  288M 0s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  299M 0s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  303M 0s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  271M 0s\n",
            " 11200K .......... .......... .......... .......... .......... 19%  301M 0s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  265M 0s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  297M 0s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  252M 0s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  302M 0s\n",
            " 11450K .......... .......... .......... .......... .......... 20% 46.2M 0s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  117M 0s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  259M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  299M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  300M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  119M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  134M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  113M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  298M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  162M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  269M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  300M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  298M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  300M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  229M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  229M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 21% 76.0M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  159M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  260M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  299M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  297M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  292M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  233M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  298M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  280M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  262M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  257M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22% 50.1M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  105M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  296M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  251M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  300M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22% 93.5M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  300M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  278M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  269M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23% 82.9M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  295M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  251M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  287M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  283M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  302M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23% 72.1M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  261M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  171M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  299M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  252M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  288M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  278M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  300M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  261M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  283M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  294M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  285M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24%  223M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24% 62.1M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  110M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  121M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  171M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  104M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  168M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  274M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  139M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25%  120M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  234M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  297M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  270M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  299M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  291M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26% 70.3M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26% 97.3M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  173M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  197M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  176M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  159M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  196M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  191M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26% 39.0M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26% 49.0M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  112M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  193M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27% 72.6M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  133M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  228M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  218M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27% 64.8M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27% 93.1M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  236M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  240M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  243M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  200M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  214M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  229M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  245M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  192M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  228M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28% 47.6M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  230M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  131M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  202M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  138M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  237M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  117M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  147M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  235M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  241M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  203M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  239M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  105M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  118M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  118M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  241M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  241M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  230M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  217M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  241M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  243M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  234M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  196M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  244M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30% 98.1M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  226M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30%  213M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  244M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  243M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  226M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31% 54.6M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31% 51.2M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  218M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  243M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31%  218M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  242M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31% 67.5M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  137M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  194M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  245M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  252M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  254M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  194M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  228M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  238M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  241M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  200M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32% 80.6M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32% 56.2M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32% 98.6M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32% 57.7M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  140M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  196M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  241M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  197M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  245M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  227M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33% 83.1M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33% 71.4M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  236M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  245M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  234M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  174M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  237M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  237M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  247M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  202M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  242M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34% 81.8M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34% 51.8M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34% 90.8M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  135M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  235M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  116M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  209M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  239M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  242M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  221M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  204M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35% 72.6M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  222M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  249M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  218M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  117M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35% 88.1M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  238M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  180M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  233M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  242M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  103M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36% 75.1M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36% 71.8M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  168M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  131M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36% 80.3M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  229M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  222M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  241M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  221M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  241M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37% 70.0M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  127M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37%  183M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37% 79.4M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  199M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  223M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  227M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  249M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38%  257M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  244M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  101M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38% 84.1M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38% 93.6M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  241M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  217M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  133M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  133M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38%  124M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  200M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  247M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  249M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  241M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39% 65.4M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  110M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  221M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  105M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  153M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  208M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  252M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  228M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  184M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40%  239M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  243M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40% 77.9M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40% 70.5M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  126M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  228M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40% 94.6M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40% 87.9M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  242M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  244M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  218M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40% 85.5M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  234M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41% 66.9M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41% 83.6M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  169M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  186M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  195M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  141M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  188M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  247M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41% 81.0M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41% 80.1M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42% 62.8M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42% 83.7M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  194M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  200M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  158M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  197M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42% 72.1M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42% 83.7M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  110M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  199M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  193M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  202M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  156M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  201M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  189M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  203M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  171M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43% 49.4M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43% 76.9M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43%  183M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  105M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  111M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  185M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  188M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  138M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44% 56.2M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  169M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  112M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  159M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  194M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  176M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  189M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  173M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  190M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  194M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  184M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45% 51.1M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45% 79.3M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45% 57.0M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  184M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  170M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  195M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45% 82.3M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  116M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  155M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  188M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  186M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  191M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46% 62.6M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  190M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  186M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  177M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  162M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46% 81.1M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46%  124M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46% 82.8M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46% 58.8M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  115M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  195M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  185M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47% 87.9M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  118M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  190M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  190M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  172M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  184M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47% 68.2M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  105M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  154M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  195M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  185M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48% 81.6M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48% 66.5M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  118M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  182M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48%  115M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  102M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  195M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  191M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48% 64.7M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  168M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  199M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  184M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  197M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49% 83.7M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49% 66.1M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  181M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  194M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  180M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49% 74.8M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  112M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  191M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  104M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  123M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  177M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  106M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  169M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  182M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50% 95.9M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  115M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  157M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  187M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  192M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51% 61.5M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51% 81.7M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  193M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  196M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  190M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51% 49.6M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  171M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  119M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  189M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  100M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  120M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  183M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  196M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52% 57.1M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  203M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  272M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  292M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  263M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  279M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  289M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  113M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  107M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  187M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  284M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  299M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  271M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  163M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  117M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  176M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  216M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  285M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  294M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  289M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  271M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  263M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  131M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  143M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  104M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  291M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54%  286M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  302M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  113M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  244M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  288M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  301M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  251M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  230M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  296M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  292M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  218M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  110M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  137M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  159M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  127M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  174M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  165M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  166M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56%  149M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  154M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  299M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  300M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  239M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  299M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56% 91.3M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  115M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  133M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  129M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  169M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57%  155M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  121M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  293M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  301M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  271M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  259M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  123M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  201M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  131M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  147M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  195M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  115M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  160M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  152M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  167M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  171M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  161M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  248M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  308M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  301M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  138M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  142M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  159M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  140M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  168M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  117M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  159M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  301M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  285M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  273M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  290M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  284M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  215M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59% 92.0M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  162M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  148M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  168M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  107M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  133M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  179M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  303M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  237M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  116M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  296M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  299M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  254M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  290M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  119M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  105M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61%  149M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  115M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  152M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  272M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  255M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  299M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  301M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  283M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  245M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  288M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62% 94.8M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  153M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62% 93.2M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  154M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  171M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  114M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  239M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  300M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  300M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  116M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  154M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  269M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  283M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  287M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63% 84.8M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  135M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  117M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  193M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  181M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  304M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  298M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  281M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  249M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  302M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  284M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  296M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64% 84.7M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  156M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  148M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  136M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  107M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  159M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  173M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65%  285M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  256M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  104M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  195M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  248M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  251M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  294M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  111M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  117M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  235M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  145M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  105M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  281M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  243M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  253M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  247M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  289M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  262M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  274M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66% 40.2M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  193M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  250M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  296M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  278M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  304M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67% 95.0M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  103M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  164M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  147M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67% 86.2M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  161M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  161M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  154M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  116M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  270M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  293M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  300M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  239M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  283M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  292M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  279M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  265M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  301M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  273M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  298M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  251M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  285M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69% 88.2M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  122M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  133M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  150M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  101M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  160M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69%  100M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  169M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  285M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  115M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  243M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  169M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  152M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  285M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  147M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  297M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  286M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  302M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  267M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  282M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  293M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  288M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  249M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  304M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  303M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  285M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  263M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  298M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  119M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  134M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  108M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  112M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  166M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  163M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  112M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  163M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  114M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  150M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  110M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  161M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72% 99.4M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  166M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  269M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  282M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  299M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  293M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  249M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  312M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  296M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  284M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  257M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  283M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  303M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  298M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  112M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  119M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  167M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  125M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  111M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74%  138M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  198M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  112M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74% 96.1M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  162M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  146M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  114M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  125M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  196M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  297M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  299M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  241M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  297M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  300M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  261M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  270M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  300M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  290M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  299M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  253M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  279M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  114M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  155M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  111M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  147M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  114M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  163M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  101M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  123M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  140M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  164M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  102M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  137M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  293M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  282M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  252M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  303M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  286M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  288M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  269M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  280M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  300M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  294M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78% 93.9M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  165M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78%  302M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  118M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  124M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  207M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78% 92.6M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  237M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  109M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  118M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  150M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  109M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  102M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  143M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  128M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  294M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  251M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  298M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  305M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  305M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  242M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  304M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  304M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  290M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  108M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  155M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  146M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  106M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  116M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  165M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  113M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  143M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  110M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  159M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  160M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  169M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  231M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  155M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  181M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  285M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  143M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  290M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  323M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  309M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  270M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  278M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  294M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  293M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  245M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  183M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  126M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  116M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  108M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  121M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  159M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  113M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83%  106M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  295M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  287M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  163M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  142M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  302M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  283M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  296M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  241M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  299M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83%  287M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  110M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  125M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  119M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  164M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  289M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  247M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  300M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  147M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  116M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84% 96.9M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  118M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  168M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  160M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85% 98.1M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  167M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  284M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  300M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  262M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  117M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  174M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  296M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  236M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  299M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  297M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  282M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86% 98.3M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  140M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  124M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  125M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  151M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  287M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  174M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  120M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  110M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  166M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  272M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  171M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  214M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  139M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  194M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  172M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  288M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  250M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  294M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  118M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  149M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  283M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  303M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  301M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  229M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  296M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  282M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  120M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  240M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  303M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  297M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  292M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  273M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  297M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  275M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  254M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  250M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  300M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  306M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  303M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  250M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  302M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  292M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  286M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  249M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  291M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  125M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  134M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  185M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  280M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  311M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  300M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  260M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  311M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  282M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  100M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  136M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  107M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  117M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  159M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  103M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  122M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  111M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  161M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91% 99.7M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  112M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  168M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  283M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  248M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  286M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  165M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92% 98.2M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  127M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  165M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92% 91.2M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  118M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  134M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  111M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  119M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  160M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93%  107M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  137M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  118M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  186M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93% 84.3M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  113M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  113M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  262M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  263M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  116M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  163M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  287M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  253M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  300M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  283M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  301M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  258M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  204M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  193M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  178M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94% 44.5M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95% 54.9M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95% 64.3M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95% 85.5M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  132M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  138M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  119M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  178M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95% 89.1M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  186M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  184M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  186M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  199M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  298M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  292M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  248M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  247M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  296M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  262M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  294M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  259M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  263M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  303M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  286M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  244M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  319M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  277M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97% 88.8M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  250M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  299M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  253M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  301M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  241M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  292M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  263M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  268M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  238M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  304M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  282M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  298M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  246M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  256M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  295M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  290M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  267M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  297M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  303M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  267M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  245M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  287M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  289M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  296M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  238M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  299M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  299M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  241M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  229M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  279M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  260M=0.4s\n",
            "\n",
            "2021-09-08 11:27:59 (145 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsTzKKIPExmM",
        "outputId": "8bb2cc1c-dcf6-477b-f97c-f4c7e58da70b"
      },
      "source": [
        "# Without 파이썬 업데이트, 아나콘다 최신 버젼으로 업데이트\n",
        "# 즉 파이썬은 3.6버전으로 홀딩하고, 아나콘다 업데이트\n",
        "%%bash\n",
        "\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pycosat-0.6.3              |   py36h27cfd23_0         107 KB\n",
            "    brotlipy-0.7.0             |py36h27cfd23_1003         349 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    tqdm-4.62.1                |     pyhd3eb1b0_1          80 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    cryptography-3.4.7         |   py36hd23ed53_0         1.0 MB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    idna-3.2                   |     pyhd3eb1b0_0          54 KB\n",
            "    conda-package-handling-1.7.3|   py36h27cfd23_1         946 KB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         2.1 MB\n",
            "    urllib3-1.26.6             |     pyhd3eb1b0_1         106 KB\n",
            "    pyopenssl-20.0.1           |     pyhd3eb1b0_1          48 KB\n",
            "    requests-2.26.0            |     pyhd3eb1b0_0          59 KB\n",
            "    ld_impl_linux-64-2.35.1    |       h7274673_9         637 KB\n",
            "    charset-normalizer-2.0.4   |     pyhd3eb1b0_0          33 KB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    ruamel_yaml-0.15.100       |   py36h27cfd23_0         268 KB\n",
            "    setuptools-52.0.0          |   py36h06a4308_0         933 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    conda-4.10.3               |   py36h06a4308_0         3.1 MB\n",
            "    readline-8.1               |       h27cfd23_0         464 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    pysocks-1.7.1              |   py36h06a4308_0          30 KB\n",
            "    sqlite-3.36.0              |       hc218d9a_0         1.4 MB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    ca-certificates-2021.7.5   |       h06a4308_1         119 KB\n",
            "    cffi-1.14.6                |   py36h400218f_0         224 KB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    six-1.16.0                 |     pyhd3eb1b0_0          18 KB\n",
            "    openssl-1.1.1l             |       h7f8727e_0         3.8 MB\n",
            "    wheel-0.37.0               |     pyhd3eb1b0_1          31 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        65.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    brotlipy:               0.7.0-py36h27cfd23_1003\n",
            "    charset-normalizer:     2.0.4-pyhd3eb1b0_0     \n",
            "    conda-package-handling: 1.7.3-py36h27cfd23_1   \n",
            "    ld_impl_linux-64:       2.35.1-h7274673_9      \n",
            "    tqdm:                   4.62.1-pyhd3eb1b0_1    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2021.7.5-h06a4308_1     \n",
            "    certifi:                2018.4.16-py36_0        --> 2021.5.30-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.6-py36h400218f_0   \n",
            "    conda:                  4.5.4-py36_0            --> 4.10.3-py36h06a4308_0   \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 3.4.7-py36hd23ed53_0    \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 3.2-pyhd3eb1b0_0        \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1l-h7f8727e_0       \n",
            "    pip:                    10.0.1-py36_0           --> 21.2.2-py36h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2               \n",
            "    pyopenssl:              18.0.0-py36_0           --> 20.0.1-pyhd3eb1b0_1     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36h06a4308_0    \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.13-h12debd9_1       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.1-h27cfd23_0          \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.26.0-pyhd3eb1b0_0     \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.100-py36h27cfd23_0 \n",
            "    setuptools:             39.2.0-py36_0           --> 52.0.0-py36h06a4308_0   \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.16.0-pyhd3eb1b0_0     \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.36.0-hc218d9a_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.26.6-pyhd3eb1b0_1     \n",
            "    wheel:                  0.31.1-py36_0           --> 0.37.0-pyhd3eb1b0_1     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _openmp_mutex-4.5          |            1_gnu          22 KB\n",
            "    libgcc-ng-9.3.0            |      h5101ec6_17         4.8 MB\n",
            "    libgomp-9.3.0              |      h5101ec6_17         311 KB\n",
            "    libstdcxx-ng-9.3.0         |      hd4cf53a_17         3.1 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         8.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  chardet-3.0.4-py36h0f667ec_1\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "  libedit-3.1.20170329-h6b74fdf_2\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  libgcc-ng                                9.1.0-hdf63c60_0 --> 9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng                             9.1.0-hdf63c60_0 --> 9.3.0-hd4cf53a_17\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\rlibgcc-ng-9.3.0      | 4.8 MB    |            |   0% \rlibgcc-ng-9.3.0      | 4.8 MB    | ######     |  61% \rlibgcc-ng-9.3.0      | 4.8 MB    | ########## | 100% \n",
            "\r_openmp_mutex-4.5    | 22 KB     |            |   0% \r_openmp_mutex-4.5    | 22 KB     | ########## | 100% \n",
            "\rlibstdcxx-ng-9.3.0   | 3.1 MB    |            |   0% \rlibstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \rlibstdcxx-ng-9.3.0   | 3.1 MB    | ########## | 100% \n",
            "\rlibgomp-9.3.0        | 311 KB    |            |   0% \rlibgomp-9.3.0        | 311 KB    | ########## | 100% \n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  349 KB |            |   0% \rbrotlipy-0.7.0       |  349 KB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n",
            "\rcertifi-2021.5.30    |  141 KB |            |   0% \rcertifi-2021.5.30    |  141 KB | ########## | 100% \n",
            "\rtqdm-4.62.1          |   80 KB |            |   0% \rtqdm-4.62.1          |   80 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rcryptography-3.4.7   |  1.0 MB |            |   0% \rcryptography-3.4.7   |  1.0 MB | #######9   |  80% \rcryptography-3.4.7   |  1.0 MB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.1.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #######7   |  78% \rlibstdcxx-ng-9.1.0   |  4.0 MB | ########## | 100% \n",
            "\rpython-3.6.13        | 32.5 MB |            |   0% \rpython-3.6.13        | 32.5 MB | ##4        |  24% \rpython-3.6.13        | 32.5 MB | #####5     |  56% \rpython-3.6.13        | 32.5 MB | #######5   |  75% \rpython-3.6.13        | 32.5 MB | #########1 |  91% \rpython-3.6.13        | 32.5 MB | ########## | 100% \n",
            "\ridna-3.2             |   54 KB |            |   0% \ridna-3.2             |   54 KB | ########## | 100% \n",
            "\rconda-package-handli |  946 KB |            |   0% \rconda-package-handli |  946 KB | #########1 |  91% \rconda-package-handli |  946 KB | ########## | 100% \n",
            "\rpip-21.2.2           |  2.1 MB |            |   0% \rpip-21.2.2           |  2.1 MB | ########   |  81% \rpip-21.2.2           |  2.1 MB | #########5 |  96% \rpip-21.2.2           |  2.1 MB | ########## | 100% \n",
            "\rurllib3-1.26.6       |  106 KB |            |   0% \rurllib3-1.26.6       |  106 KB | ########## | 100% \n",
            "\rpyopenssl-20.0.1     |   48 KB |            |   0% \rpyopenssl-20.0.1     |   48 KB | ########## | 100% \n",
            "\rrequests-2.26.0      |   59 KB |            |   0% \rrequests-2.26.0      |   59 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  637 KB |            |   0% \rld_impl_linux-64-2.3 |  637 KB | #########5 |  95% \rld_impl_linux-64-2.3 |  637 KB | ########## | 100% \n",
            "\rcharset-normalizer-2 |   33 KB |            |   0% \rcharset-normalizer-2 |   33 KB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.1.0      |  8.1 MB |            |   0% \rlibgcc-ng-9.1.0      |  8.1 MB | #######5   |  76% \rlibgcc-ng-9.1.0      |  8.1 MB | #########4 |  95% \rlibgcc-ng-9.1.0      |  8.1 MB | ########## | 100% \n",
            "\rruamel_yaml-0.15.100 |  268 KB |            |   0% \rruamel_yaml-0.15.100 |  268 KB | ########## | 100% \n",
            "\rsetuptools-52.0.0    |  933 KB |            |   0% \rsetuptools-52.0.0    |  933 KB | ########1  |  81% \rsetuptools-52.0.0    |  933 KB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rconda-4.10.3         |  3.1 MB |            |   0% \rconda-4.10.3         |  3.1 MB | ########1  |  81% \rconda-4.10.3         |  3.1 MB | ########## | 100% \n",
            "\rreadline-8.1         |  464 KB |            |   0% \rreadline-8.1         |  464 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rsqlite-3.36.0        |  1.4 MB |            |   0% \rsqlite-3.36.0        |  1.4 MB | ########6  |  87% \rsqlite-3.36.0        |  1.4 MB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######9   |  79% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | ########   |  80% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rca-certificates-2021 |  119 KB |            |   0% \rca-certificates-2021 |  119 KB | ########## | 100% \n",
            "\rcffi-1.14.6          |  224 KB |            |   0% \rcffi-1.14.6          |  224 KB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rsix-1.16.0           |   18 KB |            |   0% \rsix-1.16.0           |   18 KB | ########## | 100% \n",
            "\ropenssl-1.1.1l       |  3.8 MB |            |   0% \ropenssl-1.1.1l       |  3.8 MB | #######6   |  77% \ropenssl-1.1.1l       |  3.8 MB | ########## | 100% \n",
            "\rwheel-0.37.0         |   31 KB |            |   0% \rwheel-0.37.0         |   31 KB | ########## | 100% \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLhNx_88E5F7",
        "outputId": "057b311a-a9b4-4801-a96f-a0aa5d7dfdb8"
      },
      "source": [
        "import sys\n",
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYpMVLXNE8hz"
      },
      "source": [
        "!ls /usr/local/lib/python3.6/dist-packages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDkPWpo0FC8D"
      },
      "source": [
        "# Any package that you install with Conda will be installed into the directory\n",
        "import sys\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.6/site-packages\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psIblhEoFlse",
        "outputId": "6c39f689-1ab9-4cc3-a7c7-49c193a4e74a"
      },
      "source": [
        "sys.path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/content',\n",
              " '/env/python',\n",
              " '/usr/lib/python37.zip',\n",
              " '/usr/lib/python3.7',\n",
              " '/usr/lib/python3.7/lib-dynload',\n",
              " '/usr/local/lib/python3.7/dist-packages',\n",
              " '/usr/lib/python3/dist-packages',\n",
              " '/usr/local/lib/python3.7/dist-packages/IPython/extensions',\n",
              " '/root/.ipython',\n",
              " '/usr/local/lib/python3.6/site-packages']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRyzIZ7-Fu7v"
      },
      "source": [
        "#site-packages 가 제일 아래 붙었다.\n",
        "#구글 코랩에 디폴트로 인스톨 된 패키지인 dist-packages가 먼저 나타난다. \n",
        "#그래서 구글 코랩에 의해 가능한 패키지 버젼이 콘다를 통해 깔린 같은 패키지의 어떤 버젼보다 우선할 수 있다. 선점할 수 있다.\n",
        "#코랩 패키지 버젼이 우위를 가진다\n",
        "#그렇기 때문에 shell이 아닌 일반 colab에서 실행한 코드는 일반 colab과 동일하게 돌아가게 된다.\n",
        "#모든 코드를 !python으로 돌려야 하는 아찔한 상황."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVaptDiBj3cl",
        "outputId": "a31d857a-67c0-43b3-9ed4-e7dc21119abe"
      },
      "source": [
        "!conda create -n mol_ot python=3.6.8 -y\n",
        "!conda activate mol_ot -y\n",
        "!sudo apt-get install libxrender1\n",
        "\n",
        "!conda install pytorch torchvision -c pytorch -y\n",
        "!conda install -c rdkit rdkit -y\n",
        "!conda install -c conda-forge pot -y\n",
        "!conda install -c anaconda scikit-learn -y\n",
        "!conda install -c conda-forge matplotlib -y\n",
        "!conda install -c conda-forge tqdm -y\n",
        "!conda install -c conda-forge tensorboardx -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/mol_ot\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.6.8\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    libedit-3.1.20210714       |       h7f8727e_0         165 KB\n",
            "    libffi-3.2.1               |    hf484d3e_1007          48 KB\n",
            "    python-3.6.8               |       h0371630_0        30.1 MB\n",
            "    readline-7.0               |       h7b6447c_5         324 KB\n",
            "    sqlite-3.33.0              |       h62c20be_0         1.1 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        31.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-4.5-1_gnu\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2021.7.5-h06a4308_1\n",
            "  certifi            pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20210714-h7f8727e_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hf484d3e_1007\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.3.0-h5101ec6_17\n",
            "  libgomp            pkgs/main/linux-64::libgomp-9.3.0-h5101ec6_17\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.3.0-hd4cf53a_17\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1l-h7f8727e_0\n",
            "  pip                pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0\n",
            "  python             pkgs/main/linux-64::python-3.6.8-h0371630_0\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  setuptools         pkgs/main/linux-64::setuptools-52.0.0-py36h06a4308_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.33.0-h62c20be_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.10-hbc83047_0\n",
            "  wheel              pkgs/main/noarch::wheel-0.37.0-pyhd3eb1b0_1\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.5-h7b6447c_0\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "sqlite-3.33.0        | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  7.59it/s]\n",
            "readline-7.0         | 324 KB    | : 100% 1.0/1 [00:00<00:00, 19.89it/s]\n",
            "python-3.6.8         | 30.1 MB   | : 100% 1.0/1 [00:00<00:00,  1.45it/s]               \n",
            "libedit-3.1.20210714 | 165 KB    | : 100% 1.0/1 [00:00<00:00, 14.48it/s]\n",
            "libffi-3.2.1         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 21.80it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate mol_ot\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "\n",
            "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\n",
            "To initialize your shell, run\n",
            "\n",
            "    $ conda init <SHELL_NAME>\n",
            "\n",
            "Currently supported shells are:\n",
            "  - bash\n",
            "  - fish\n",
            "  - tcsh\n",
            "  - xonsh\n",
            "  - zsh\n",
            "  - powershell\n",
            "\n",
            "See 'conda init --help' for more information and options.\n",
            "\n",
            "IMPORTANT: You may need to close and restart your shell after running 'conda init'.\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libxrender1 is already the newest version (1:0.9.10-1).\n",
            "libxrender1 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pytorch\n",
            "    - torchvision\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    blas-1.0                   |              mkl           6 KB\n",
            "    bzip2-1.0.8                |       h7b6447c_0          78 KB\n",
            "    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n",
            "    dataclasses-0.8            |     pyh4f3eec9_6          22 KB\n",
            "    ffmpeg-4.3                 |       hf484d3e_0         9.9 MB  pytorch\n",
            "    freetype-2.10.4            |       h5ab3b9f_0         596 KB\n",
            "    gmp-6.2.1                  |       h2531618_2         539 KB\n",
            "    gnutls-3.6.15              |       he1e5248_0         1.0 MB\n",
            "    intel-openmp-2021.3.0      |    h06a4308_3350         1.4 MB\n",
            "    jpeg-9b                    |       h024ee3a_2         214 KB\n",
            "    lame-3.100                 |       h7b6447c_0         323 KB\n",
            "    lcms2-2.12                 |       h3be6417_0         312 KB\n",
            "    libiconv-1.15              |       h63c8f33_5         721 KB\n",
            "    libidn2-2.3.2              |       h7f8727e_0          81 KB\n",
            "    libpng-1.6.37              |       hbc83047_0         278 KB\n",
            "    libtasn1-4.16.0            |       h27cfd23_0          58 KB\n",
            "    libtiff-4.2.0              |       h85742a9_0         502 KB\n",
            "    libunistring-0.9.10        |       h27cfd23_0         536 KB\n",
            "    libuv-1.40.0               |       h7b6447c_0         736 KB\n",
            "    libwebp-base-1.2.0         |       h27cfd23_0         437 KB\n",
            "    lz4-c-1.9.3                |       h295c915_1         185 KB\n",
            "    mkl-2021.3.0               |     h06a4308_520       141.2 MB\n",
            "    nettle-3.7.3               |       hbbd107a_1         809 KB\n",
            "    ninja-1.10.2               |       hff7bd54_1         1.4 MB\n",
            "    olefile-0.46               |           py36_0          48 KB\n",
            "    openh264-2.1.0             |       hd408876_0         722 KB\n",
            "    openjpeg-2.4.0             |       h3ad879b_0         331 KB\n",
            "    pillow-8.3.1               |   py36h2c7a002_0         637 KB\n",
            "    pytorch-1.9.0              |py3.6_cuda10.2_cudnn7.6.5_0       705.1 MB  pytorch\n",
            "    torchvision-0.10.0         |       py36_cu102        28.7 MB  pytorch\n",
            "    typing_extensions-3.10.0.0 |     pyhca03da5_0          27 KB\n",
            "    zstd-1.4.9                 |       haebb681_0         480 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        1.23 GB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  blas               pkgs/main/linux-64::blas-1.0-mkl\n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h7b6447c_0\n",
            "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1\n",
            "  dataclasses        pkgs/main/noarch::dataclasses-0.8-pyh4f3eec9_6\n",
            "  ffmpeg             pytorch/linux-64::ffmpeg-4.3-hf484d3e_0\n",
            "  freetype           pkgs/main/linux-64::freetype-2.10.4-h5ab3b9f_0\n",
            "  gmp                pkgs/main/linux-64::gmp-6.2.1-h2531618_2\n",
            "  gnutls             pkgs/main/linux-64::gnutls-3.6.15-he1e5248_0\n",
            "  intel-openmp       pkgs/main/linux-64::intel-openmp-2021.3.0-h06a4308_3350\n",
            "  jpeg               pkgs/main/linux-64::jpeg-9b-h024ee3a_2\n",
            "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0\n",
            "  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0\n",
            "  libiconv           pkgs/main/linux-64::libiconv-1.15-h63c8f33_5\n",
            "  libidn2            pkgs/main/linux-64::libidn2-2.3.2-h7f8727e_0\n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.37-hbc83047_0\n",
            "  libtasn1           pkgs/main/linux-64::libtasn1-4.16.0-h27cfd23_0\n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.2.0-h85742a9_0\n",
            "  libunistring       pkgs/main/linux-64::libunistring-0.9.10-h27cfd23_0\n",
            "  libuv              pkgs/main/linux-64::libuv-1.40.0-h7b6447c_0\n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.2.0-h27cfd23_0\n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.3-h295c915_1\n",
            "  mkl                pkgs/main/linux-64::mkl-2021.3.0-h06a4308_520\n",
            "  nettle             pkgs/main/linux-64::nettle-3.7.3-hbbd107a_1\n",
            "  ninja              pkgs/main/linux-64::ninja-1.10.2-hff7bd54_1\n",
            "  olefile            pkgs/main/linux-64::olefile-0.46-py36_0\n",
            "  openh264           pkgs/main/linux-64::openh264-2.1.0-hd408876_0\n",
            "  openjpeg           pkgs/main/linux-64::openjpeg-2.4.0-h3ad879b_0\n",
            "  pillow             pkgs/main/linux-64::pillow-8.3.1-py36h2c7a002_0\n",
            "  pytorch            pytorch/linux-64::pytorch-1.9.0-py3.6_cuda10.2_cudnn7.6.5_0\n",
            "  torchvision        pytorch/linux-64::torchvision-0.10.0-py36_cu102\n",
            "  typing_extensions  pkgs/main/noarch::typing_extensions-3.10.0.0-pyhca03da5_0\n",
            "  zstd               pkgs/main/linux-64::zstd-1.4.9-haebb681_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "lame-3.100           | 323 KB    | : 100% 1.0/1 [00:00<00:00,  9.61it/s]\n",
            "libidn2-2.3.2        | 81 KB     | : 100% 1.0/1 [00:00<00:00, 22.23it/s]\n",
            "nettle-3.7.3         | 809 KB    | : 100% 1.0/1 [00:00<00:00, 13.01it/s]\n",
            "zstd-1.4.9           | 480 KB    | : 100% 1.0/1 [00:00<00:00, 16.21it/s]\n",
            "pytorch-1.9.0        | 705.1 MB  | : 100% 1.0/1 [01:48<00:00, 108.12s/it]             \n",
            "blas-1.0             | 6 KB      | : 100% 1.0/1 [00:00<00:00, 24.71it/s]\n",
            "libtiff-4.2.0        | 502 KB    | : 100% 1.0/1 [00:00<00:00, 17.24it/s]\n",
            "cudatoolkit-10.2.89  | 365.1 MB  | : 100% 1.0/1 [00:07<00:00,  7.70s/it]               \n",
            "bzip2-1.0.8          | 78 KB     | : 100% 1.0/1 [00:00<00:00, 15.01it/s]\n",
            "intel-openmp-2021.3. | 1.4 MB    | : 100% 1.0/1 [00:00<00:00, 10.33it/s]\n",
            "gmp-6.2.1            | 539 KB    | : 100% 1.0/1 [00:00<00:00, 15.98it/s]\n",
            "lz4-c-1.9.3          | 185 KB    | : 100% 1.0/1 [00:00<00:00, 21.01it/s]\n",
            "libuv-1.40.0         | 736 KB    | : 100% 1.0/1 [00:00<00:00, 19.21it/s]\n",
            "openjpeg-2.4.0       | 331 KB    | : 100% 1.0/1 [00:00<00:00, 20.98it/s]\n",
            "ffmpeg-4.3           | 9.9 MB    | : 100% 1.0/1 [00:02<00:00,  2.61s/it]               \n",
            "libwebp-base-1.2.0   | 437 KB    | : 100% 1.0/1 [00:00<00:00, 18.20it/s]\n",
            "typing_extensions-3. | 27 KB     | : 100% 1.0/1 [00:00<00:00, 21.46it/s]\n",
            "libunistring-0.9.10  | 536 KB    | : 100% 1.0/1 [00:00<00:00, 20.27it/s]\n",
            "openh264-2.1.0       | 722 KB    | : 100% 1.0/1 [00:00<00:00, 15.52it/s]\n",
            "freetype-2.10.4      | 596 KB    | : 100% 1.0/1 [00:00<00:00, 17.07it/s]\n",
            "olefile-0.46         | 48 KB     | : 100% 1.0/1 [00:00<00:00, 23.42it/s]\n",
            "libpng-1.6.37        | 278 KB    | : 100% 1.0/1 [00:00<00:00, 20.92it/s]\n",
            "libiconv-1.15        | 721 KB    | : 100% 1.0/1 [00:00<00:00, 18.02it/s]\n",
            "gnutls-3.6.15        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00, 16.22it/s]\n",
            "pillow-8.3.1         | 637 KB    | : 100% 1.0/1 [00:00<00:00, 15.50it/s]\n",
            "libtasn1-4.16.0      | 58 KB     | : 100% 1.0/1 [00:00<00:00, 22.40it/s]\n",
            "dataclasses-0.8      | 22 KB     | : 100% 1.0/1 [00:00<00:00, 21.51it/s]\n",
            "mkl-2021.3.0         | 141.2 MB  | : 100% 1.0/1 [00:14<00:00, 14.06s/it]               \n",
            "ninja-1.10.2         | 1.4 MB    | : 100% 1.0/1 [00:01<00:00,  1.71s/it]\n",
            "torchvision-0.10.0   | 28.7 MB   | : 100% 1.0/1 [00:05<00:00,  5.10s/it]\n",
            "lcms2-2.12           | 312 KB    | : 100% 1.0/1 [00:00<00:00, 18.94it/s]\n",
            "jpeg-9b              | 214 KB    | : 100% 1.0/1 [00:00<00:00, 21.59it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cairo-1.16.0               |       hf32fb01_1         1.0 MB\n",
            "    fontconfig-2.13.1          |       h6c09931_0         250 KB\n",
            "    glib-2.69.1                |       h5202010_0         1.7 MB\n",
            "    icu-58.2                   |       he6710b0_3        10.5 MB\n",
            "    libboost-1.73.0            |      h3ff78a5_11        13.9 MB\n",
            "    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB\n",
            "    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB\n",
            "    libuuid-1.0.3              |       h1bed415_2          15 KB\n",
            "    libxcb-1.14                |       h7b6447c_0         505 KB\n",
            "    libxml2-2.9.12             |       h03d6c58_0         1.2 MB\n",
            "    mkl-service-2.4.0          |   py36h7f8727e_0          56 KB\n",
            "    mkl_fft-1.3.0              |   py36h42c9631_2         171 KB\n",
            "    mkl_random-1.2.2           |   py36h51133e4_0         292 KB\n",
            "    numpy-1.16.6               |   py36h2d18471_3          50 KB\n",
            "    numpy-base-1.16.6          |   py36hdc34a94_3         3.5 MB\n",
            "    pandas-1.1.5               |   py36ha9443f7_0         8.2 MB\n",
            "    pcre-8.45                  |       h295c915_0         207 KB\n",
            "    pixman-0.40.0              |       h7b6447c_0         370 KB\n",
            "    py-boost-1.73.0            |  py36ha9443f7_11         204 KB\n",
            "    python-dateutil-2.8.2      |     pyhd3eb1b0_0         233 KB\n",
            "    pytz-2021.1                |     pyhd3eb1b0_0         181 KB\n",
            "    rdkit-2020.09.1.0          |   py36hd50e099_1        26.0 MB  rdkit\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        69.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cairo              pkgs/main/linux-64::cairo-1.16.0-hf32fb01_1\n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.13.1-h6c09931_0\n",
            "  glib               pkgs/main/linux-64::glib-2.69.1-h5202010_0\n",
            "  icu                pkgs/main/linux-64::icu-58.2-he6710b0_3\n",
            "  libboost           pkgs/main/linux-64::libboost-1.73.0-h3ff78a5_11\n",
            "  libgfortran-ng     pkgs/main/linux-64::libgfortran-ng-7.5.0-ha8ba4b0_17\n",
            "  libgfortran4       pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17\n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.0.3-h1bed415_2\n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.14-h7b6447c_0\n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.9.12-h03d6c58_0\n",
            "  mkl-service        pkgs/main/linux-64::mkl-service-2.4.0-py36h7f8727e_0\n",
            "  mkl_fft            pkgs/main/linux-64::mkl_fft-1.3.0-py36h42c9631_2\n",
            "  mkl_random         pkgs/main/linux-64::mkl_random-1.2.2-py36h51133e4_0\n",
            "  numpy              pkgs/main/linux-64::numpy-1.16.6-py36h2d18471_3\n",
            "  numpy-base         pkgs/main/linux-64::numpy-base-1.16.6-py36hdc34a94_3\n",
            "  pandas             pkgs/main/linux-64::pandas-1.1.5-py36ha9443f7_0\n",
            "  pcre               pkgs/main/linux-64::pcre-8.45-h295c915_0\n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7b6447c_0\n",
            "  py-boost           pkgs/main/linux-64::py-boost-1.73.0-py36ha9443f7_11\n",
            "  python-dateutil    pkgs/main/noarch::python-dateutil-2.8.2-pyhd3eb1b0_0\n",
            "  pytz               pkgs/main/noarch::pytz-2021.1-pyhd3eb1b0_0\n",
            "  rdkit              rdkit/linux-64::rdkit-2020.09.1.0-py36hd50e099_1\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "py-boost-1.73.0      | 204 KB    | : 100% 1.0/1 [00:00<00:00,  8.80it/s]\n",
            "fontconfig-2.13.1    | 250 KB    | : 100% 1.0/1 [00:00<00:00, 13.26it/s]\n",
            "libxcb-1.14          | 505 KB    | : 100% 1.0/1 [00:00<00:00, 13.58it/s]\n",
            "numpy-1.16.6         | 50 KB     | : 100% 1.0/1 [00:00<00:00, 21.91it/s]\n",
            "pytz-2021.1          | 181 KB    | : 100% 1.0/1 [00:00<00:00, 11.12it/s]\n",
            "pandas-1.1.5         | 8.2 MB    | : 100% 1.0/1 [00:00<00:00,  2.28it/s]\n",
            "libuuid-1.0.3        | 15 KB     | : 100% 1.0/1 [00:00<00:00, 21.75it/s]\n",
            "mkl_fft-1.3.0        | 171 KB    | : 100% 1.0/1 [00:00<00:00, 21.91it/s]\n",
            "pixman-0.40.0        | 370 KB    | : 100% 1.0/1 [00:00<00:00, 19.75it/s]\n",
            "libgfortran4-7.5.0   | 995 KB    | : 100% 1.0/1 [00:00<00:00, 14.16it/s]\n",
            "rdkit-2020.09.1.0    | 26.0 MB   | : 100% 1.0/1 [00:05<00:00,  5.61s/it]\n",
            "python-dateutil-2.8. | 233 KB    | : 100% 1.0/1 [00:00<00:00, 19.55it/s]\n",
            "cairo-1.16.0         | 1.0 MB    | : 100% 1.0/1 [00:00<00:00, 12.60it/s]\n",
            "numpy-base-1.16.6    | 3.5 MB    | : 100% 1.0/1 [00:00<00:00,  4.84it/s]\n",
            "libxml2-2.9.12       | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  8.05it/s]\n",
            "glib-2.69.1          | 1.7 MB    | : 100% 1.0/1 [00:00<00:00,  8.88it/s]\n",
            "libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 19.88it/s]\n",
            "mkl_random-1.2.2     | 292 KB    | : 100% 1.0/1 [00:00<00:00, 20.63it/s]\n",
            "libboost-1.73.0      | 13.9 MB   | : 100% 1.0/1 [00:01<00:00,  1.59s/it]               \n",
            "pcre-8.45            | 207 KB    | : 100% 1.0/1 [00:00<00:00, 18.52it/s]\n",
            "mkl-service-2.4.0    | 56 KB     | : 100% 1.0/1 [00:00<00:00, 21.17it/s]\n",
            "icu-58.2             | 10.5 MB   | : 100% 1.0/1 [00:00<00:00,  2.98it/s]\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pot\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
            "    certifi-2021.5.30          |   py36h5fab9bb_0         141 KB  conda-forge\n",
            "    conda-4.10.3               |   py36h5fab9bb_0         3.1 MB  conda-forge\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    kiwisolver-1.3.1           |   py36h2531618_0          80 KB\n",
            "    libblas-3.9.0              |   11_linux64_mkl          12 KB  conda-forge\n",
            "    libcblas-3.9.0             |   11_linux64_mkl          11 KB  conda-forge\n",
            "    liblapack-3.9.0            |   11_linux64_mkl          11 KB  conda-forge\n",
            "    matplotlib-base-3.3.4      |   py36hd391965_0         6.8 MB  conda-forge\n",
            "    pot-0.7.0                  |   py36h831f99a_0         194 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python_abi-3.6             |          2_cp36m           4 KB  conda-forge\n",
            "    scipy-1.5.3                |   py36h976291a_0        18.6 MB  conda-forge\n",
            "    tornado-6.1                |   py36h8f6f2f9_1         643 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        29.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  kiwisolver         pkgs/main/linux-64::kiwisolver-1.3.1-py36h2531618_0\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-11_linux64_mkl\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-11_linux64_mkl\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-11_linux64_mkl\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.3.4-py36hd391965_0\n",
            "  pot                conda-forge/linux-64::pot-0.7.0-py36h831f99a_0\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.6-2_cp36m\n",
            "  scipy              conda-forge/linux-64::scipy-1.5.3-py36h976291a_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py36h8f6f2f9_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
            "  certifi            pkgs/main::certifi-2021.5.30-py36h06a~ --> conda-forge::certifi-2021.5.30-py36h5fab9bb_0\n",
            "  conda              pkgs/main::conda-4.10.3-py36h06a4308_0 --> conda-forge::conda-4.10.3-py36h5fab9bb_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00,  8.33it/s]\n",
            "libblas-3.9.0        | 12 KB     | : 100% 1.0/1 [00:00<00:00, 30.65it/s]\n",
            "pyparsing-2.4.7      | 60 KB     | : 100% 1.0/1 [00:00<00:00, 25.30it/s]\n",
            "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 34.04it/s]\n",
            "certifi-2021.5.30    | 141 KB    | : 100% 1.0/1 [00:00<00:00, 18.21it/s]\n",
            "matplotlib-base-3.3. | 6.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\n",
            "scipy-1.5.3          | 18.6 MB   | : 100% 1.0/1 [00:02<00:00,  2.79s/it]\n",
            "conda-4.10.3         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.79it/s]\n",
            "pot-0.7.0            | 194 KB    | : 100% 1.0/1 [00:00<00:00, 14.02it/s]\n",
            "cycler-0.10.0        | 9 KB      | : 100% 1.0/1 [00:00<00:00, 28.86it/s]\n",
            "tornado-6.1          | 643 KB    | : 100% 1.0/1 [00:00<00:00,  6.18it/s]\n",
            "kiwisolver-1.3.1     | 80 KB     | : 100% 1.0/1 [00:00<00:00, 11.40it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 28.52it/s]\n",
            "ca-certificates-2021 | 136 KB    | : 100% 1.0/1 [00:00<00:00, 22.31it/s]\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - scikit-learn\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2020.10.14 |                0         128 KB  anaconda\n",
            "    certifi-2020.6.20          |           py36_0         160 KB  anaconda\n",
            "    joblib-0.17.0              |             py_0         205 KB  anaconda\n",
            "    scikit-learn-0.23.2        |   py36h0573a6f_0         6.9 MB  anaconda\n",
            "    threadpoolctl-2.1.0        |     pyh5ca1d4c_0          16 KB  anaconda\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         7.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  joblib             anaconda/noarch::joblib-0.17.0-py_0\n",
            "  scikit-learn       anaconda/linux-64::scikit-learn-0.23.2-py36h0573a6f_0\n",
            "  threadpoolctl      anaconda/noarch::threadpoolctl-2.1.0-pyh5ca1d4c_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2021.5.3~ --> anaconda::ca-certificates-2020.10.14-0\n",
            "  certifi            conda-forge::certifi-2021.5.30-py36h5~ --> anaconda::certifi-2020.6.20-py36_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "joblib-0.17.0        | 205 KB    | : 100% 1.0/1 [00:00<00:00,  7.03it/s]\n",
            "ca-certificates-2020 | 128 KB    | : 100% 1.0/1 [00:00<00:00, 20.22it/s]\n",
            "certifi-2020.6.20    | 160 KB    | : 100% 1.0/1 [00:00<00:00, 18.51it/s]\n",
            "threadpoolctl-2.1.0  | 16 KB     | : 100% 1.0/1 [00:00<00:00, 23.84it/s]\n",
            "scikit-learn-0.23.2  | 6.9 MB    | : 100% 1.0/1 [00:01<00:00,  1.27s/it]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - matplotlib\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    dbus-1.13.6                |       he372182_0         602 KB  conda-forge\n",
            "    expat-2.4.1                |       h9c3ff4c_0         182 KB  conda-forge\n",
            "    gst-plugins-base-1.14.0    |       h8213a91_2         4.9 MB\n",
            "    gstreamer-1.14.0           |       h28cd5cc_2         3.2 MB\n",
            "    matplotlib-3.3.4           |   py36h06a4308_0          26 KB\n",
            "    pyqt-5.9.2                 |   py36hcca6a23_4         5.7 MB  conda-forge\n",
            "    qt-5.9.7                   |       h5867ecd_1        68.5 MB\n",
            "    sip-4.19.8                 |   py36hf484d3e_0         274 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        83.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  dbus               conda-forge/linux-64::dbus-1.13.6-he372182_0\n",
            "  expat              conda-forge/linux-64::expat-2.4.1-h9c3ff4c_0\n",
            "  gst-plugins-base   pkgs/main/linux-64::gst-plugins-base-1.14.0-h8213a91_2\n",
            "  gstreamer          pkgs/main/linux-64::gstreamer-1.14.0-h28cd5cc_2\n",
            "  matplotlib         pkgs/main/linux-64::matplotlib-3.3.4-py36h06a4308_0\n",
            "  pyqt               conda-forge/linux-64::pyqt-5.9.2-py36hcca6a23_4\n",
            "  qt                 pkgs/main/linux-64::qt-5.9.7-h5867ecd_1\n",
            "  sip                pkgs/main/linux-64::sip-4.19.8-py36hf484d3e_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    anaconda::ca-certificates-2020.10.14-0 --> conda-forge::ca-certificates-2021.5.30-ha878542_0\n",
            "  certifi                anaconda::certifi-2020.6.20-py36_0 --> conda-forge::certifi-2021.5.30-py36h5fab9bb_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "dbus-1.13.6          | 602 KB    | : 100% 1.0/1 [00:00<00:00,  4.82it/s]\n",
            "expat-2.4.1          | 182 KB    | : 100% 1.0/1 [00:00<00:00, 14.40it/s]\n",
            "qt-5.9.7             | 68.5 MB   | : 100% 1.0/1 [00:02<00:00,  2.24s/it]               \n",
            "pyqt-5.9.2           | 5.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.16s/it]\n",
            "gst-plugins-base-1.1 | 4.9 MB    | : 100% 1.0/1 [00:00<00:00,  5.92it/s]\n",
            "sip-4.19.8           | 274 KB    | : 100% 1.0/1 [00:00<00:00, 16.60it/s]\n",
            "gstreamer-1.14.0     | 3.2 MB    | : 100% 1.0/1 [00:00<00:00,  8.23it/s]\n",
            "matplotlib-3.3.4     | 26 KB     | : 100% 1.0/1 [00:00<00:00, 20.47it/s]\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - tqdm\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    colorama-0.4.4             |     pyh9f0ad1d_0          18 KB  conda-forge\n",
            "    tqdm-4.62.2                |     pyhd8ed1ab_0          80 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:          97 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  tqdm                  pkgs/main::tqdm-4.62.1-pyhd3eb1b0_1 --> conda-forge::tqdm-4.62.2-pyhd8ed1ab_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "colorama-0.4.4       | 18 KB     | : 100% 1.0/1 [00:00<00:00, 10.65it/s]\n",
            "tqdm-4.62.2          | 80 KB     | : 100% 1.0/1 [00:00<00:00, 14.46it/s]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - tensorboardx\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    libprotobuf-3.17.2         |       h780b84a_1         2.5 MB  conda-forge\n",
            "    protobuf-3.17.2            |   py36hc4f0c31_0         334 KB  conda-forge\n",
            "    tensorboardx-2.4           |     pyhd8ed1ab_0          83 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         2.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-3.17.2-h780b84a_1\n",
            "  protobuf           conda-forge/linux-64::protobuf-3.17.2-py36hc4f0c31_0\n",
            "  tensorboardx       conda-forge/noarch::tensorboardx-2.4-pyhd8ed1ab_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "libprotobuf-3.17.2   | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.94it/s]\n",
            "tensorboardx-2.4     | 83 KB     | : 100% 1.0/1 [00:00<00:00, 20.03it/s]\n",
            "protobuf-3.17.2      | 334 KB    | : 100% 1.0/1 [00:00<00:00, 10.29it/s]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onMhomb8o0Dc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug3jH21IWO3Z",
        "outputId": "41964ee2-9a01-4e12-d8f9-f6b495d2af8e"
      },
      "source": [
        "!git clone https://github.com/benatorc/OTGNN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OTGNN'...\n",
            "remote: Enumerating objects: 66, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 66 (delta 8), reused 65 (delta 7), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cTRBn-8lJij"
      },
      "source": [
        "import pandas as pd\n",
        "directory = '/content/drive/MyDrive/235789_Samsung AI Challenge for Scientific Discovery_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFNuWoBAlksK"
      },
      "source": [
        "data = pd.concat([pd.read_csv(directory +'train.csv'), pd.read_csv(directory+'dev.csv')])\n",
        "test_data = pd.read_csv(directory +'test.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-H2rwXjcxNG"
      },
      "source": [
        "!cp /content/OTGNN/data/lipo/raw.csv /content/OTGNN/data/lipo/raw1.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDiO3mnjWWPd"
      },
      "source": [
        "example = pd.read_csv('/content/OTGNN/data/lipo/raw.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9fIOrYOpyAK"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "3ObF7Bn0WdSl",
        "outputId": "84ae9a44-8216-4ee6-b51b-a1ec357a4b17"
      },
      "source": [
        "example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14</th>\n",
              "      <th>3.54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...</td>\n",
              "      <td>-1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl</td>\n",
              "      <td>3.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...</td>\n",
              "      <td>3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OC1(CN2CCC1CC2)C#Cc3ccc(cc3)c4ccccc4</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4194</th>\n",
              "      <td>OCCc1ccc(NC(=O)c2cc3cc(Cl)ccc3[nH]2)cc1</td>\n",
              "      <td>3.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>CCN(C1CCN(CCC(c2ccc(F)cc2)c3ccc(F)cc3)CC1)C(=O...</td>\n",
              "      <td>3.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>COc1cccc2[nH]ncc12</td>\n",
              "      <td>2.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>Clc1ccc2ncccc2c1C(=O)NCC3CCCCC3</td>\n",
              "      <td>2.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>CN1C(=O)C=C(CCc2ccc3ccccc3c2)N=C1N</td>\n",
              "      <td>2.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4199 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14  3.54\n",
              "0     COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)... -1.18\n",
              "1                COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl  3.69\n",
              "2     OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...  3.37\n",
              "3     Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...  3.10\n",
              "4                  OC1(CN2CCC1CC2)C#Cc3ccc(cc3)c4ccccc4  3.14\n",
              "...                                                 ...   ...\n",
              "4194            OCCc1ccc(NC(=O)c2cc3cc(Cl)ccc3[nH]2)cc1  3.85\n",
              "4195  CCN(C1CCN(CCC(c2ccc(F)cc2)c3ccc(F)cc3)CC1)C(=O...  3.21\n",
              "4196                                 COc1cccc2[nH]ncc12  2.10\n",
              "4197                    Clc1ccc2ncccc2c1C(=O)NCC3CCCCC3  2.65\n",
              "4198                 CN1C(=O)C=C(CCc2ccc3ccccc3c2)N=C1N  2.70\n",
              "\n",
              "[4199 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weflFy23pW9N"
      },
      "source": [
        "data['s1_t1_gap']= data['S1_energy(eV)'] - data['T1_energy(eV)']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "739_IGviawPq"
      },
      "source": [
        "df = data.reset_index().drop(['uid','S1_energy(eV)','T1_energy(eV)','index'],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrOrQ_kGbcHx"
      },
      "source": [
        "df.to_csv('/content/OTGNN/data/lipo/raw.csv', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHPreitcc_sX"
      },
      "source": [
        "example2 = pd.read_csv('/content/OTGNN/data/lipo/raw.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "cRgmCk4vdDy3",
        "outputId": "3b67c871-f48b-45f1-f958-362948b70f54"
      },
      "source": [
        "example2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CCC1CCCCN1C(=O)C(C)OC(=O)c1c(C)oc(-n2cccc2)c1C#N</th>\n",
              "      <th>1.2937999999999996</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COc1ccc(Oc2ccc(N3C(=S)NC(c4ccccn4)C3c3cc(C)n(-...</td>\n",
              "      <td>0.2032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CC(=O)Nc1ccc(C(=O)[C@H](C)Sc2nnc(C3CCCCC3)o2)cc1</td>\n",
              "      <td>0.4633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OC(CNC1CC1)CN1CCc2sccc2C1</td>\n",
              "      <td>1.1054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCNC(CCCC(F)(F)F)C1(OCC)CCOCC1</td>\n",
              "      <td>0.2243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N#CCCNC(=O)C1(O)CCSC1</td>\n",
              "      <td>0.4264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30339</th>\n",
              "      <td>N#Cc1cc(-c2ccc(N3c4ccccc4Oc4ccccc43)cc2)c(-c2c...</td>\n",
              "      <td>0.0093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30340</th>\n",
              "      <td>CC1(C)c2ccccc2N(c2ccc(-c3nc4ccc(N5c6ccccc6C(C)...</td>\n",
              "      <td>0.0166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30341</th>\n",
              "      <td>Cc1cc(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32...</td>\n",
              "      <td>0.0104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30342</th>\n",
              "      <td>Cc1cc(-n2c3ccccc3c3ccccc32)cc(C)c1B1c2ccccc2B(...</td>\n",
              "      <td>0.0139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30343</th>\n",
              "      <td>CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1c(Cl...</td>\n",
              "      <td>0.1293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30344 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        CCC1CCCCN1C(=O)C(C)OC(=O)c1c(C)oc(-n2cccc2)c1C#N  1.2937999999999996\n",
              "0      COc1ccc(Oc2ccc(N3C(=S)NC(c4ccccn4)C3c3cc(C)n(-...              0.2032\n",
              "1       CC(=O)Nc1ccc(C(=O)[C@H](C)Sc2nnc(C3CCCCC3)o2)cc1              0.4633\n",
              "2                              OC(CNC1CC1)CN1CCc2sccc2C1              1.1054\n",
              "3                         CCNC(CCCC(F)(F)F)C1(OCC)CCOCC1              0.2243\n",
              "4                                  N#CCCNC(=O)C1(O)CCSC1              0.4264\n",
              "...                                                  ...                 ...\n",
              "30339  N#Cc1cc(-c2ccc(N3c4ccccc4Oc4ccccc43)cc2)c(-c2c...              0.0093\n",
              "30340  CC1(C)c2ccccc2N(c2ccc(-c3nc4ccc(N5c6ccccc6C(C)...              0.0166\n",
              "30341  Cc1cc(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32...              0.0104\n",
              "30342  Cc1cc(-n2c3ccccc3c3ccccc32)cc(C)c1B1c2ccccc2B(...              0.0139\n",
              "30343  CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1c(Cl...              0.1293\n",
              "\n",
              "[30344 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "DI6k_se8bZ_6",
        "outputId": "166c21a1-f66f-4458-df4b-f1ed5355813e"
      },
      "source": [
        "example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14</th>\n",
              "      <th>3.54</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...</td>\n",
              "      <td>-1.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl</td>\n",
              "      <td>3.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...</td>\n",
              "      <td>3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...</td>\n",
              "      <td>3.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OC1(CN2CCC1CC2)C#Cc3ccc(cc3)c4ccccc4</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4194</th>\n",
              "      <td>OCCc1ccc(NC(=O)c2cc3cc(Cl)ccc3[nH]2)cc1</td>\n",
              "      <td>3.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4195</th>\n",
              "      <td>CCN(C1CCN(CCC(c2ccc(F)cc2)c3ccc(F)cc3)CC1)C(=O...</td>\n",
              "      <td>3.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>COc1cccc2[nH]ncc12</td>\n",
              "      <td>2.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4197</th>\n",
              "      <td>Clc1ccc2ncccc2c1C(=O)NCC3CCCCC3</td>\n",
              "      <td>2.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4198</th>\n",
              "      <td>CN1C(=O)C=C(CCc2ccc3ccccc3c2)N=C1N</td>\n",
              "      <td>2.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4199 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14  3.54\n",
              "0     COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)... -1.18\n",
              "1                COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl  3.69\n",
              "2     OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...  3.37\n",
              "3     Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...  3.10\n",
              "4                  OC1(CN2CCC1CC2)C#Cc3ccc(cc3)c4ccccc4  3.14\n",
              "...                                                 ...   ...\n",
              "4194            OCCc1ccc(NC(=O)c2cc3cc(Cl)ccc3[nH]2)cc1  3.85\n",
              "4195  CCN(C1CCN(CCC(c2ccc(F)cc2)c3ccc(F)cc3)CC1)C(=O...  3.21\n",
              "4196                                 COc1cccc2[nH]ncc12  2.10\n",
              "4197                    Clc1ccc2ncccc2c1C(=O)NCC3CCCCC3  2.65\n",
              "4198                 CN1C(=O)C=C(CCc2ccc3ccccc3c2)N=C1N  2.70\n",
              "\n",
              "[4199 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gnkTNldidVNi",
        "outputId": "a1d70721-d659-4e00-bdd3-79709023e622"
      },
      "source": [
        "!pip install ipykernel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-5.5.5-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting ipython>=5.0.0\n",
            "  Downloading ipython-7.16.1-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 81.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.6/site-packages (from ipykernel) (6.1)\n",
            "Collecting traitlets>=4.1.0\n",
            "  Downloading traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting jupyter-client\n",
            "  Downloading jupyter_client-7.0.2-py3-none-any.whl (122 kB)\n",
            "\u001b[K     |████████████████████████████████| 122 kB 97.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/site-packages (from ipython>=5.0.0->ipykernel) (52.0.0.post20210125)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.0.9-py3-none-any.whl (8.9 kB)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.20-py3-none-any.whl (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting pexpect\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.7 MB/s \n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.10.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 54.5 MB/s \n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting ipython-genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from traitlets>=4.1.0->ipykernel) (1.16.0)\n",
            "Collecting nest-asyncio>=1.5\n",
            "  Downloading nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from jupyter-client->ipykernel) (2.8.2)\n",
            "Collecting jupyter-core>=4.6.0\n",
            "  Downloading jupyter_core-4.7.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting pyzmq>=13\n",
            "  Downloading pyzmq-22.2.1-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 73.9 MB/s \n",
            "\u001b[?25hCollecting entrypoints\n",
            "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
            "Collecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ipython-genutils, decorator, wcwidth, traitlets, ptyprocess, parso, pyzmq, pygments, prompt-toolkit, pickleshare, pexpect, nest-asyncio, jupyter-core, jedi, entrypoints, backcall, jupyter-client, ipython, ipykernel\n",
            "Successfully installed backcall-0.2.0 decorator-5.0.9 entrypoints-0.3 ipykernel-5.5.5 ipython-7.16.1 ipython-genutils-0.2.0 jedi-0.18.0 jupyter-client-7.0.2 jupyter-core-4.7.1 nest-asyncio-1.5.1 parso-0.8.2 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.20 ptyprocess-0.7.0 pygments-2.10.0 pyzmq-22.2.1 traitlets-4.3.3 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "ipython_genutils",
                  "jupyter_core",
                  "pexpect",
                  "pickleshare",
                  "wcwidth",
                  "zmq"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZbIpDi2dPAe",
        "outputId": "8d36932a-2239-488a-a8a2-e09c4bf48d66"
      },
      "source": [
        "cd OTGNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OTGNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbs2BWBWcBdU"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXR_0shRzNMw"
      },
      "source": [
        "with open(\"/content/OTGNN/data/lipo/split_0.json\", \"r+\") as st_json:\n",
        "\n",
        "    split_0 = json.load(st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_1.json\", \"r+\") as st_json:\n",
        "\n",
        "    split_1 = json.load(st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_2.json\", \"r+\") as st_json:\n",
        "\n",
        "    split_2 = json.load(st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_3.json\", \"r+\") as st_json:\n",
        "\n",
        "    split_3 = json.load(st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_4.json\", \"r+\") as st_json:\n",
        "\n",
        "    split_4 = json.load(st_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uj-ndtdo7Ng"
      },
      "source": [
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpHBzeLFmwR1"
      },
      "source": [
        "a = example2.index.to_list()\n",
        "spt = []\n",
        "num = 5\n",
        "size = int(len(a)/num)\n",
        "for x in range(num-1):\n",
        "  spt.append(random.sample(a,size))\n",
        "  a = list(set(a) - set(spt[x]))\n",
        "spt.append(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_XRLAbpsM9L",
        "outputId": "fc0633fa-3e9c-41db-f698-78ccb9a8db22"
      },
      "source": [
        "len(split_0['train'])/(len(split_0['test'])+len(split_0['train']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Ism5AYrnSW"
      },
      "source": [
        "def arr_splt(arr,perc):\n",
        "  train = random.sample(arr,int(len(arr)*perc))\n",
        "  test = list(set(arr) - set(train))\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxieUziqrQ3"
      },
      "source": [
        "split_0['train'], split_0['test'] = arr_splt(spt[0],0.88)\n",
        "split_1['train'], split_1['test'] = arr_splt(spt[1],0.88)\n",
        "split_2['train'], split_2['test'] = arr_splt(spt[2],0.88)\n",
        "split_3['train'], split_3['test'] = arr_splt(spt[3],0.88)\n",
        "split_4['train'], split_4['test'] = arr_splt(spt[4],0.88)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzidd-sCsnS6"
      },
      "source": [
        "with open(\"/content/OTGNN/data/lipo/split_0.json\", \"r+\") as st_json:\n",
        "\n",
        "    json.dump(split_0,st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_1.json\", \"r+\") as st_json:\n",
        "\n",
        "    json.dump(split_1,st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_2.json\", \"r+\") as st_json:\n",
        "\n",
        "    json.dump(split_2,st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_3.json\", \"r+\") as st_json:\n",
        "\n",
        "    json.dump(split_3,st_json)\n",
        "\n",
        "with open(\"/content/OTGNN/data/lipo/split_4.json\", \"r+\") as st_json:\n",
        "\n",
        "    json.dump(split_4,st_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eDH9od9P-fw"
      },
      "source": [
        "load model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jd_g931OgKpf"
      },
      "source": [
        "#test이후 실행하여 학습 준비"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZcOixi_gU5K"
      },
      "source": [
        "#!mv /content/OTGNN/data/lipo /content/OTGNN/data/ST_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "425BjyYmgZms",
        "outputId": "0d5bc0f7-69cd-42b3-8fb8-d32c22a58acb"
      },
      "source": [
        "#!mv /content/OTGNN/data/lipo_train /content/OTGNN/data/lipo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/OTGNN/data/lipo_train': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSZf8GWeTG6t"
      },
      "source": [
        "#!mv /content/OTGNN/data/ST_test /content/OTGNN/data/lipo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITOU1dVWdMA6",
        "outputId": "9ff7653f-9757-4e2b-8bdf-910fa25467a2"
      },
      "source": [
        "!python train_proto.py -data lipo -output_dir output/test -lr 5e-4 \\\n",
        "  -n_epochs 450 -n_hidden 60 -n_ffn_hidden 110 -batch_size 32 -n_pc 10 \\\n",
        "  -pc_size 10 -pc_hidden 10 -distance_metric wasserstein -separate_lr \\\n",
        "  -lr_pc 5e-3 -opt_method emd -mult_num_atoms -nce_coef 0.01 -pretrain_gcn '/content/drive/MyDrive/model_best_210904'\n",
        "  #n_hidden=50,n_ffn_hidden=100,batch_size=16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized model with 13572 params\n",
            "  0% 0/167 [00:00<?, ?it/s]/content/OTGNN/models/ot_modules.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 0:  mse: 0.2091 nce_reg: -2.3638 loss: 0.2328 prediction_mean: 0.7326 prediction_std: 0.2393 rmse: 0.4573\n",
            "Val   0:  mse: 0.1769 nce_reg: -2.3541 loss: 0.2004 prediction_mean: 0.7795 prediction_std: 0.0786 rmse: 0.4206\n",
            "Model saved to: output/test/run_0/models/model_0\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 1:  mse: 0.1363 nce_reg: -2.3391 loss: 0.1597 prediction_mean: 0.8181 prediction_std: 0.0664 rmse: 0.3692\n",
            "Val   1:  mse: 0.1594 nce_reg: -2.3181 loss: 0.1825 prediction_mean: 0.8612 prediction_std: 0.0368 rmse: 0.3992\n",
            "Model saved to: output/test/run_0/models/model_1\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.48it/s]\n",
            "Train 2:  mse: 0.1254 nce_reg: -2.2965 loss: 0.1484 prediction_mean: 0.8339 prediction_std: 0.0782 rmse: 0.3542\n",
            "Val   2:  mse: 0.1494 nce_reg: -2.2648 loss: 0.1721 prediction_mean: 0.8536 prediction_std: 0.0871 rmse: 0.3865\n",
            "Model saved to: output/test/run_0/models/model_2\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 3:  mse: 0.1167 nce_reg: -2.2516 loss: 0.1392 prediction_mean: 0.8389 prediction_std: 0.1076 rmse: 0.3416\n",
            "Val   3:  mse: 0.1394 nce_reg: -2.2244 loss: 0.1616 prediction_mean: 0.8427 prediction_std: 0.0993 rmse: 0.3733\n",
            "Model saved to: output/test/run_0/models/model_3\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 4:  mse: 0.1089 nce_reg: -2.2073 loss: 0.1310 prediction_mean: 0.8418 prediction_std: 0.1303 rmse: 0.3301\n",
            "Val   4:  mse: 0.1314 nce_reg: -2.1661 loss: 0.1531 prediction_mean: 0.8806 prediction_std: 0.1455 rmse: 0.3625\n",
            "Model saved to: output/test/run_0/models/model_4\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 5:  mse: 0.1026 nce_reg: -2.1504 loss: 0.1241 prediction_mean: 0.8439 prediction_std: 0.1574 rmse: 0.3203\n",
            "Val   5:  mse: 0.1233 nce_reg: -2.1178 loss: 0.1444 prediction_mean: 0.7991 prediction_std: 0.1573 rmse: 0.3511\n",
            "Model saved to: output/test/run_0/models/model_5\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 6:  mse: 0.0967 nce_reg: -2.0999 loss: 0.1177 prediction_mean: 0.8409 prediction_std: 0.1736 rmse: 0.3110\n",
            "Val   6:  mse: 0.1249 nce_reg: -2.0603 loss: 0.1455 prediction_mean: 0.7422 prediction_std: 0.1807 rmse: 0.3535\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 7:  mse: 0.0919 nce_reg: -2.0570 loss: 0.1124 prediction_mean: 0.8434 prediction_std: 0.1877 rmse: 0.3031\n",
            "Val   7:  mse: 0.1085 nce_reg: -2.0236 loss: 0.1287 prediction_mean: 0.8260 prediction_std: 0.1919 rmse: 0.3293\n",
            "Model saved to: output/test/run_0/models/model_7\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 8:  mse: 0.0895 nce_reg: -2.0076 loss: 0.1096 prediction_mean: 0.8442 prediction_std: 0.2003 rmse: 0.2992\n",
            "Val   8:  mse: 0.1105 nce_reg: -1.9879 loss: 0.1304 prediction_mean: 0.8641 prediction_std: 0.1932 rmse: 0.3325\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 9:  mse: 0.0845 nce_reg: -1.9631 loss: 0.1041 prediction_mean: 0.8432 prediction_std: 0.2083 rmse: 0.2907\n",
            "Val   9:  mse: 0.1067 nce_reg: -1.9302 loss: 0.1260 prediction_mean: 0.8016 prediction_std: 0.2110 rmse: 0.3267\n",
            "Model saved to: output/test/run_0/models/model_9\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 10:  mse: 0.0820 nce_reg: -1.9173 loss: 0.1012 prediction_mean: 0.8452 prediction_std: 0.2163 rmse: 0.2864\n",
            "Val   10:  mse: 0.1058 nce_reg: -1.8901 loss: 0.1247 prediction_mean: 0.8014 prediction_std: 0.2153 rmse: 0.3253\n",
            "Model saved to: output/test/run_0/models/model_10\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 11:  mse: 0.0801 nce_reg: -1.8830 loss: 0.0989 prediction_mean: 0.8445 prediction_std: 0.2216 rmse: 0.2830\n",
            "Val   11:  mse: 0.1102 nce_reg: -1.8609 loss: 0.1288 prediction_mean: 0.7474 prediction_std: 0.2325 rmse: 0.3320\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 12:  mse: 0.0757 nce_reg: -1.8447 loss: 0.0941 prediction_mean: 0.8455 prediction_std: 0.2290 rmse: 0.2751\n",
            "Val   12:  mse: 0.1036 nce_reg: -1.8140 loss: 0.1218 prediction_mean: 0.9125 prediction_std: 0.2257 rmse: 0.3219\n",
            "Model saved to: output/test/run_0/models/model_12\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 13:  mse: 0.0740 nce_reg: -1.8007 loss: 0.0920 prediction_mean: 0.8449 prediction_std: 0.2362 rmse: 0.2720\n",
            "Val   13:  mse: 0.1050 nce_reg: -1.7756 loss: 0.1227 prediction_mean: 0.7894 prediction_std: 0.2388 rmse: 0.3240\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 14:  mse: 0.0727 nce_reg: -1.7662 loss: 0.0904 prediction_mean: 0.8449 prediction_std: 0.2404 rmse: 0.2697\n",
            "Val   14:  mse: 0.0963 nce_reg: -1.7328 loss: 0.1136 prediction_mean: 0.8333 prediction_std: 0.2329 rmse: 0.3102\n",
            "Model saved to: output/test/run_0/models/model_14\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 15:  mse: 0.0721 nce_reg: -1.7296 loss: 0.0894 prediction_mean: 0.8444 prediction_std: 0.2417 rmse: 0.2684\n",
            "Val   15:  mse: 0.0941 nce_reg: -1.7048 loss: 0.1112 prediction_mean: 0.8658 prediction_std: 0.2404 rmse: 0.3068\n",
            "Model saved to: output/test/run_0/models/model_15\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 16:  mse: 0.0692 nce_reg: -1.6968 loss: 0.0862 prediction_mean: 0.8450 prediction_std: 0.2456 rmse: 0.2630\n",
            "Val   16:  mse: 0.0994 nce_reg: -1.6536 loss: 0.1159 prediction_mean: 0.7714 prediction_std: 0.2442 rmse: 0.3153\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 17:  mse: 0.0684 nce_reg: -1.6550 loss: 0.0850 prediction_mean: 0.8440 prediction_std: 0.2516 rmse: 0.2616\n",
            "Val   17:  mse: 0.0958 nce_reg: -1.6383 loss: 0.1122 prediction_mean: 0.8869 prediction_std: 0.2359 rmse: 0.3095\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 18:  mse: 0.0659 nce_reg: -1.6237 loss: 0.0822 prediction_mean: 0.8444 prediction_std: 0.2520 rmse: 0.2568\n",
            "Val   18:  mse: 0.0937 nce_reg: -1.5880 loss: 0.1096 prediction_mean: 0.8290 prediction_std: 0.2614 rmse: 0.3061\n",
            "Model saved to: output/test/run_0/models/model_18\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 19:  mse: 0.0629 nce_reg: -1.5830 loss: 0.0788 prediction_mean: 0.8465 prediction_std: 0.2547 rmse: 0.2508\n",
            "Val   19:  mse: 0.0923 nce_reg: -1.5364 loss: 0.1077 prediction_mean: 0.8436 prediction_std: 0.2703 rmse: 0.3038\n",
            "Model saved to: output/test/run_0/models/model_19\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 20:  mse: 0.0636 nce_reg: -1.5395 loss: 0.0790 prediction_mean: 0.8448 prediction_std: 0.2612 rmse: 0.2523\n",
            "Val   20:  mse: 0.1029 nce_reg: -1.4922 loss: 0.1178 prediction_mean: 0.7346 prediction_std: 0.2816 rmse: 0.3207\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 21:  mse: 0.0623 nce_reg: -1.4969 loss: 0.0773 prediction_mean: 0.8447 prediction_std: 0.2621 rmse: 0.2496\n",
            "Val   21:  mse: 0.0919 nce_reg: -1.4639 loss: 0.1065 prediction_mean: 0.8148 prediction_std: 0.2698 rmse: 0.3031\n",
            "Model saved to: output/test/run_0/models/model_21\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 22:  mse: 0.0624 nce_reg: -1.4579 loss: 0.0770 prediction_mean: 0.8446 prediction_std: 0.2665 rmse: 0.2498\n",
            "Val   22:  mse: 0.0951 nce_reg: -1.4416 loss: 0.1095 prediction_mean: 0.7793 prediction_std: 0.2591 rmse: 0.3083\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 23:  mse: 0.0612 nce_reg: -1.4260 loss: 0.0754 prediction_mean: 0.8453 prediction_std: 0.2652 rmse: 0.2473\n",
            "Val   23:  mse: 0.0958 nce_reg: -1.3958 loss: 0.1098 prediction_mean: 0.7795 prediction_std: 0.2702 rmse: 0.3095\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 24:  mse: 0.0596 nce_reg: -1.3870 loss: 0.0735 prediction_mean: 0.8437 prediction_std: 0.2694 rmse: 0.2442\n",
            "Val   24:  mse: 0.0980 nce_reg: -1.3531 loss: 0.1115 prediction_mean: 0.9519 prediction_std: 0.2672 rmse: 0.3131\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 25:  mse: 0.0582 nce_reg: -1.3496 loss: 0.0717 prediction_mean: 0.8454 prediction_std: 0.2690 rmse: 0.2412\n",
            "Val   25:  mse: 0.0925 nce_reg: -1.3137 loss: 0.1056 prediction_mean: 0.7823 prediction_std: 0.2874 rmse: 0.3041\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 26:  mse: 0.0573 nce_reg: -1.3103 loss: 0.0704 prediction_mean: 0.8448 prediction_std: 0.2720 rmse: 0.2394\n",
            "Val   26:  mse: 0.0891 nce_reg: -1.2856 loss: 0.1019 prediction_mean: 0.8599 prediction_std: 0.2864 rmse: 0.2984\n",
            "Model saved to: output/test/run_0/models/model_26\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 27:  mse: 0.0557 nce_reg: -1.2698 loss: 0.0684 prediction_mean: 0.8452 prediction_std: 0.2770 rmse: 0.2360\n",
            "Val   27:  mse: 0.0888 nce_reg: -1.2324 loss: 0.1011 prediction_mean: 0.8521 prediction_std: 0.2748 rmse: 0.2979\n",
            "Model saved to: output/test/run_0/models/model_27\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 28:  mse: 0.0556 nce_reg: -1.2316 loss: 0.0679 prediction_mean: 0.8447 prediction_std: 0.2759 rmse: 0.2359\n",
            "Val   28:  mse: 0.0921 nce_reg: -1.1883 loss: 0.1040 prediction_mean: 0.9104 prediction_std: 0.2793 rmse: 0.3035\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 29:  mse: 0.0546 nce_reg: -1.1889 loss: 0.0665 prediction_mean: 0.8443 prediction_std: 0.2772 rmse: 0.2337\n",
            "Val   29:  mse: 0.0898 nce_reg: -1.1491 loss: 0.1013 prediction_mean: 0.7959 prediction_std: 0.2732 rmse: 0.2997\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 30:  mse: 0.0581 nce_reg: -1.1588 loss: 0.0696 prediction_mean: 0.8441 prediction_std: 0.2812 rmse: 0.2409\n",
            "Val   30:  mse: 0.0887 nce_reg: -1.1276 loss: 0.0999 prediction_mean: 0.8937 prediction_std: 0.2980 rmse: 0.2978\n",
            "Model saved to: output/test/run_0/models/model_30\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 31:  mse: 0.0526 nce_reg: -1.1232 loss: 0.0638 prediction_mean: 0.8447 prediction_std: 0.2779 rmse: 0.2293\n",
            "Val   31:  mse: 0.0899 nce_reg: -1.0918 loss: 0.1008 prediction_mean: 0.8502 prediction_std: 0.2857 rmse: 0.2999\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 32:  mse: 0.0503 nce_reg: -1.0806 loss: 0.0611 prediction_mean: 0.8456 prediction_std: 0.2849 rmse: 0.2242\n",
            "Val   32:  mse: 0.0915 nce_reg: -1.0427 loss: 0.1019 prediction_mean: 0.7873 prediction_std: 0.2872 rmse: 0.3024\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 33:  mse: 0.0500 nce_reg: -1.0439 loss: 0.0604 prediction_mean: 0.8438 prediction_std: 0.2865 rmse: 0.2236\n",
            "Val   33:  mse: 0.0902 nce_reg: -1.0158 loss: 0.1003 prediction_mean: 0.8808 prediction_std: 0.2934 rmse: 0.3003\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 34:  mse: 0.0482 nce_reg: -1.0020 loss: 0.0582 prediction_mean: 0.8451 prediction_std: 0.2859 rmse: 0.2195\n",
            "Val   34:  mse: 0.0863 nce_reg: -0.9637 loss: 0.0959 prediction_mean: 0.8317 prediction_std: 0.2906 rmse: 0.2938\n",
            "Model saved to: output/test/run_0/models/model_34\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 35:  mse: 0.0477 nce_reg: -0.9558 loss: 0.0573 prediction_mean: 0.8436 prediction_std: 0.2881 rmse: 0.2185\n",
            "Val   35:  mse: 0.0889 nce_reg: -0.9304 loss: 0.0982 prediction_mean: 0.8992 prediction_std: 0.2924 rmse: 0.2982\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 36:  mse: 0.0487 nce_reg: -0.9269 loss: 0.0580 prediction_mean: 0.8461 prediction_std: 0.2900 rmse: 0.2207\n",
            "Val   36:  mse: 0.0883 nce_reg: -0.8986 loss: 0.0973 prediction_mean: 0.8280 prediction_std: 0.3251 rmse: 0.2971\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 37:  mse: 0.0485 nce_reg: -0.8956 loss: 0.0574 prediction_mean: 0.8444 prediction_std: 0.2949 rmse: 0.2202\n",
            "Val   37:  mse: 0.0943 nce_reg: -0.8600 loss: 0.1029 prediction_mean: 0.7799 prediction_std: 0.2943 rmse: 0.3070\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 38:  mse: 0.0466 nce_reg: -0.8738 loss: 0.0554 prediction_mean: 0.8443 prediction_std: 0.2921 rmse: 0.2159\n",
            "Val   38:  mse: 0.0855 nce_reg: -0.8357 loss: 0.0939 prediction_mean: 0.8369 prediction_std: 0.3136 rmse: 0.2924\n",
            "Model saved to: output/test/run_0/models/model_38\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 39:  mse: 0.0480 nce_reg: -0.8389 loss: 0.0564 prediction_mean: 0.8452 prediction_std: 0.2970 rmse: 0.2190\n",
            "Val   39:  mse: 0.0905 nce_reg: -0.8238 loss: 0.0987 prediction_mean: 0.7911 prediction_std: 0.3017 rmse: 0.3008\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 40:  mse: 0.0451 nce_reg: -0.8176 loss: 0.0533 prediction_mean: 0.8443 prediction_std: 0.2958 rmse: 0.2124\n",
            "Val   40:  mse: 0.0861 nce_reg: -0.7797 loss: 0.0939 prediction_mean: 0.8547 prediction_std: 0.2819 rmse: 0.2935\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 41:  mse: 0.0434 nce_reg: -0.7833 loss: 0.0512 prediction_mean: 0.8452 prediction_std: 0.2958 rmse: 0.2082\n",
            "Val   41:  mse: 0.0899 nce_reg: -0.7411 loss: 0.0973 prediction_mean: 0.9099 prediction_std: 0.3094 rmse: 0.2999\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 42:  mse: 0.0455 nce_reg: -0.7577 loss: 0.0531 prediction_mean: 0.8444 prediction_std: 0.2996 rmse: 0.2133\n",
            "Val   42:  mse: 0.0902 nce_reg: -0.7431 loss: 0.0977 prediction_mean: 0.7966 prediction_std: 0.3215 rmse: 0.3004\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 43:  mse: 0.0416 nce_reg: -0.7315 loss: 0.0489 prediction_mean: 0.8445 prediction_std: 0.3014 rmse: 0.2038\n",
            "Val   43:  mse: 0.0883 nce_reg: -0.7021 loss: 0.0954 prediction_mean: 0.8697 prediction_std: 0.2983 rmse: 0.2972\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 44:  mse: 0.0411 nce_reg: -0.6971 loss: 0.0481 prediction_mean: 0.8446 prediction_std: 0.2995 rmse: 0.2028\n",
            "Val   44:  mse: 0.0939 nce_reg: -0.6713 loss: 0.1006 prediction_mean: 0.9307 prediction_std: 0.3177 rmse: 0.3064\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 45:  mse: 0.0454 nce_reg: -0.6873 loss: 0.0523 prediction_mean: 0.8461 prediction_std: 0.3072 rmse: 0.2131\n",
            "Val   45:  mse: 0.0929 nce_reg: -0.6586 loss: 0.0995 prediction_mean: 0.7660 prediction_std: 0.2977 rmse: 0.3048\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 46:  mse: 0.0409 nce_reg: -0.6706 loss: 0.0476 prediction_mean: 0.8440 prediction_std: 0.3018 rmse: 0.2021\n",
            "Val   46:  mse: 0.0856 nce_reg: -0.6330 loss: 0.0920 prediction_mean: 0.8556 prediction_std: 0.3102 rmse: 0.2926\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 47:  mse: 0.0400 nce_reg: -0.6383 loss: 0.0464 prediction_mean: 0.8443 prediction_std: 0.3049 rmse: 0.2000\n",
            "Val   47:  mse: 0.0866 nce_reg: -0.6131 loss: 0.0927 prediction_mean: 0.8405 prediction_std: 0.3224 rmse: 0.2942\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 48:  mse: 0.0398 nce_reg: -0.6156 loss: 0.0459 prediction_mean: 0.8448 prediction_std: 0.3041 rmse: 0.1994\n",
            "Val   48:  mse: 0.0849 nce_reg: -0.5815 loss: 0.0907 prediction_mean: 0.8366 prediction_std: 0.3146 rmse: 0.2913\n",
            "Model saved to: output/test/run_0/models/model_48\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 49:  mse: 0.0401 nce_reg: -0.5969 loss: 0.0461 prediction_mean: 0.8448 prediction_std: 0.3082 rmse: 0.2003\n",
            "Val   49:  mse: 0.0875 nce_reg: -0.5684 loss: 0.0932 prediction_mean: 0.7849 prediction_std: 0.3210 rmse: 0.2958\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 50:  mse: 0.0402 nce_reg: -0.5756 loss: 0.0459 prediction_mean: 0.8433 prediction_std: 0.3072 rmse: 0.2004\n",
            "Val   50:  mse: 0.0863 nce_reg: -0.5574 loss: 0.0919 prediction_mean: 0.8245 prediction_std: 0.3273 rmse: 0.2938\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 51:  mse: 0.0381 nce_reg: -0.5609 loss: 0.0437 prediction_mean: 0.8451 prediction_std: 0.3089 rmse: 0.1952\n",
            "Val   51:  mse: 0.0870 nce_reg: -0.5300 loss: 0.0923 prediction_mean: 0.8364 prediction_std: 0.3353 rmse: 0.2949\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 52:  mse: 0.0371 nce_reg: -0.5376 loss: 0.0425 prediction_mean: 0.8445 prediction_std: 0.3100 rmse: 0.1927\n",
            "Val   52:  mse: 0.0888 nce_reg: -0.5087 loss: 0.0939 prediction_mean: 0.8093 prediction_std: 0.3136 rmse: 0.2980\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 53:  mse: 0.0355 nce_reg: -0.5179 loss: 0.0407 prediction_mean: 0.8433 prediction_std: 0.3095 rmse: 0.1884\n",
            "Val   53:  mse: 0.0847 nce_reg: -0.4999 loss: 0.0897 prediction_mean: 0.8375 prediction_std: 0.2981 rmse: 0.2911\n",
            "Model saved to: output/test/run_0/models/model_53\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 54:  mse: 0.0375 nce_reg: -0.5051 loss: 0.0426 prediction_mean: 0.8458 prediction_std: 0.3109 rmse: 0.1937\n",
            "Val   54:  mse: 0.0854 nce_reg: -0.4788 loss: 0.0902 prediction_mean: 0.8651 prediction_std: 0.3256 rmse: 0.2923\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 55:  mse: 0.0358 nce_reg: -0.4872 loss: 0.0407 prediction_mean: 0.8444 prediction_std: 0.3108 rmse: 0.1893\n",
            "Val   55:  mse: 0.0906 nce_reg: -0.4689 loss: 0.0953 prediction_mean: 0.7894 prediction_std: 0.3355 rmse: 0.3010\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 56:  mse: 0.0352 nce_reg: -0.4693 loss: 0.0399 prediction_mean: 0.8448 prediction_std: 0.3127 rmse: 0.1876\n",
            "Val   56:  mse: 0.0904 nce_reg: -0.4562 loss: 0.0950 prediction_mean: 0.8132 prediction_std: 0.3181 rmse: 0.3007\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 57:  mse: 0.0348 nce_reg: -0.4521 loss: 0.0393 prediction_mean: 0.8450 prediction_std: 0.3136 rmse: 0.1866\n",
            "Val   57:  mse: 0.0886 nce_reg: -0.4423 loss: 0.0930 prediction_mean: 0.7821 prediction_std: 0.3343 rmse: 0.2976\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 58:  mse: 0.0344 nce_reg: -0.4418 loss: 0.0388 prediction_mean: 0.8448 prediction_std: 0.3159 rmse: 0.1855\n",
            "Val   58:  mse: 0.0867 nce_reg: -0.4340 loss: 0.0911 prediction_mean: 0.7997 prediction_std: 0.3106 rmse: 0.2945\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 59:  mse: 0.0351 nce_reg: -0.4277 loss: 0.0393 prediction_mean: 0.8452 prediction_std: 0.3153 rmse: 0.1872\n",
            "Val   59:  mse: 0.1063 nce_reg: -0.4222 loss: 0.1105 prediction_mean: 0.7094 prediction_std: 0.3312 rmse: 0.3260\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 60:  mse: 0.0335 nce_reg: -0.4195 loss: 0.0377 prediction_mean: 0.8433 prediction_std: 0.3163 rmse: 0.1832\n",
            "Val   60:  mse: 0.0858 nce_reg: -0.3940 loss: 0.0897 prediction_mean: 0.8205 prediction_std: 0.3333 rmse: 0.2928\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 61:  mse: 0.0327 nce_reg: -0.4052 loss: 0.0367 prediction_mean: 0.8431 prediction_std: 0.3166 rmse: 0.1808\n",
            "Val   61:  mse: 0.0921 nce_reg: -0.3907 loss: 0.0960 prediction_mean: 0.7679 prediction_std: 0.3267 rmse: 0.3035\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.32it/s]\n",
            "Train 62:  mse: 0.0325 nce_reg: -0.3886 loss: 0.0364 prediction_mean: 0.8449 prediction_std: 0.3163 rmse: 0.1803\n",
            "Val   62:  mse: 0.0888 nce_reg: -0.3679 loss: 0.0925 prediction_mean: 0.8567 prediction_std: 0.3459 rmse: 0.2980\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 63:  mse: 0.0370 nce_reg: -0.3860 loss: 0.0409 prediction_mean: 0.8459 prediction_std: 0.3219 rmse: 0.1924\n",
            "Val   63:  mse: 0.0891 nce_reg: -0.3775 loss: 0.0929 prediction_mean: 0.8953 prediction_std: 0.3401 rmse: 0.2985\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 64:  mse: 0.0338 nce_reg: -0.3847 loss: 0.0376 prediction_mean: 0.8457 prediction_std: 0.3190 rmse: 0.1837\n",
            "Val   64:  mse: 0.0843 nce_reg: -0.3646 loss: 0.0879 prediction_mean: 0.8552 prediction_std: 0.3235 rmse: 0.2903\n",
            "Model saved to: output/test/run_0/models/model_64\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 65:  mse: 0.0305 nce_reg: -0.3699 loss: 0.0342 prediction_mean: 0.8446 prediction_std: 0.3179 rmse: 0.1747\n",
            "Val   65:  mse: 0.0909 nce_reg: -0.3476 loss: 0.0944 prediction_mean: 0.7777 prediction_std: 0.3469 rmse: 0.3015\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 66:  mse: 0.0322 nce_reg: -0.3584 loss: 0.0358 prediction_mean: 0.8453 prediction_std: 0.3211 rmse: 0.1795\n",
            "Val   66:  mse: 0.0848 nce_reg: -0.3551 loss: 0.0883 prediction_mean: 0.8451 prediction_std: 0.3257 rmse: 0.2911\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 67:  mse: 0.0303 nce_reg: -0.3470 loss: 0.0337 prediction_mean: 0.8453 prediction_std: 0.3198 rmse: 0.1740\n",
            "Val   67:  mse: 0.0925 nce_reg: -0.3347 loss: 0.0959 prediction_mean: 0.7602 prediction_std: 0.3067 rmse: 0.3042\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 68:  mse: 0.0318 nce_reg: -0.3396 loss: 0.0352 prediction_mean: 0.8426 prediction_std: 0.3222 rmse: 0.1784\n",
            "Val   68:  mse: 0.0870 nce_reg: -0.3285 loss: 0.0903 prediction_mean: 0.8746 prediction_std: 0.3382 rmse: 0.2949\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 69:  mse: 0.0307 nce_reg: -0.3359 loss: 0.0340 prediction_mean: 0.8431 prediction_std: 0.3222 rmse: 0.1751\n",
            "Val   69:  mse: 0.0918 nce_reg: -0.3141 loss: 0.0949 prediction_mean: 0.9230 prediction_std: 0.3181 rmse: 0.3030\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 70:  mse: 0.0291 nce_reg: -0.3224 loss: 0.0323 prediction_mean: 0.8457 prediction_std: 0.3220 rmse: 0.1706\n",
            "Val   70:  mse: 0.0886 nce_reg: -0.3062 loss: 0.0917 prediction_mean: 0.8801 prediction_std: 0.3421 rmse: 0.2977\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 71:  mse: 0.0303 nce_reg: -0.3141 loss: 0.0335 prediction_mean: 0.8451 prediction_std: 0.3247 rmse: 0.1741\n",
            "Val   71:  mse: 0.0912 nce_reg: -0.3038 loss: 0.0942 prediction_mean: 0.7774 prediction_std: 0.3177 rmse: 0.3019\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 72:  mse: 0.0297 nce_reg: -0.3110 loss: 0.0329 prediction_mean: 0.8436 prediction_std: 0.3234 rmse: 0.1725\n",
            "Val   72:  mse: 0.0939 nce_reg: -0.2949 loss: 0.0969 prediction_mean: 0.9313 prediction_std: 0.3223 rmse: 0.3064\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 73:  mse: 0.0287 nce_reg: -0.3020 loss: 0.0317 prediction_mean: 0.8451 prediction_std: 0.3230 rmse: 0.1693\n",
            "Val   73:  mse: 0.0919 nce_reg: -0.2855 loss: 0.0947 prediction_mean: 0.8051 prediction_std: 0.3316 rmse: 0.3031\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 74:  mse: 0.0288 nce_reg: -0.2985 loss: 0.0317 prediction_mean: 0.8438 prediction_std: 0.3246 rmse: 0.1696\n",
            "Val   74:  mse: 0.0873 nce_reg: -0.2829 loss: 0.0901 prediction_mean: 0.8823 prediction_std: 0.3214 rmse: 0.2954\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 75:  mse: 0.0262 nce_reg: -0.2881 loss: 0.0291 prediction_mean: 0.8457 prediction_std: 0.3239 rmse: 0.1619\n",
            "Val   75:  mse: 0.0881 nce_reg: -0.2743 loss: 0.0908 prediction_mean: 0.8640 prediction_std: 0.3267 rmse: 0.2967\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 76:  mse: 0.0272 nce_reg: -0.2768 loss: 0.0300 prediction_mean: 0.8442 prediction_std: 0.3254 rmse: 0.1650\n",
            "Val   76:  mse: 0.0863 nce_reg: -0.2726 loss: 0.0890 prediction_mean: 0.8320 prediction_std: 0.3183 rmse: 0.2937\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 77:  mse: 0.0287 nce_reg: -0.2745 loss: 0.0314 prediction_mean: 0.8447 prediction_std: 0.3246 rmse: 0.1694\n",
            "Val   77:  mse: 0.0875 nce_reg: -0.2561 loss: 0.0900 prediction_mean: 0.7883 prediction_std: 0.3264 rmse: 0.2957\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 78:  mse: 0.0250 nce_reg: -0.2640 loss: 0.0277 prediction_mean: 0.8461 prediction_std: 0.3255 rmse: 0.1583\n",
            "Val   78:  mse: 0.0942 nce_reg: -0.2443 loss: 0.0967 prediction_mean: 0.7734 prediction_std: 0.3199 rmse: 0.3069\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 79:  mse: 0.0275 nce_reg: -0.2578 loss: 0.0301 prediction_mean: 0.8442 prediction_std: 0.3264 rmse: 0.1659\n",
            "Val   79:  mse: 0.0994 nce_reg: -0.2566 loss: 0.1019 prediction_mean: 0.7367 prediction_std: 0.3426 rmse: 0.3152\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 80:  mse: 0.0263 nce_reg: -0.2538 loss: 0.0288 prediction_mean: 0.8438 prediction_std: 0.3270 rmse: 0.1621\n",
            "Val   80:  mse: 0.0910 nce_reg: -0.2408 loss: 0.0934 prediction_mean: 0.7754 prediction_std: 0.3061 rmse: 0.3016\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 81:  mse: 0.0258 nce_reg: -0.2460 loss: 0.0283 prediction_mean: 0.8446 prediction_std: 0.3267 rmse: 0.1606\n",
            "Val   81:  mse: 0.0921 nce_reg: -0.2251 loss: 0.0944 prediction_mean: 0.7843 prediction_std: 0.3413 rmse: 0.3035\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 82:  mse: 0.0256 nce_reg: -0.2402 loss: 0.0280 prediction_mean: 0.8443 prediction_std: 0.3278 rmse: 0.1601\n",
            "Val   82:  mse: 0.0883 nce_reg: -0.2196 loss: 0.0905 prediction_mean: 0.8183 prediction_std: 0.3318 rmse: 0.2972\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 83:  mse: 0.0272 nce_reg: -0.2332 loss: 0.0295 prediction_mean: 0.8441 prediction_std: 0.3300 rmse: 0.1648\n",
            "Val   83:  mse: 0.0942 nce_reg: -0.2237 loss: 0.0965 prediction_mean: 0.9342 prediction_std: 0.3337 rmse: 0.3069\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 84:  mse: 0.0266 nce_reg: -0.2317 loss: 0.0289 prediction_mean: 0.8443 prediction_std: 0.3279 rmse: 0.1631\n",
            "Val   84:  mse: 0.0918 nce_reg: -0.2279 loss: 0.0941 prediction_mean: 0.7846 prediction_std: 0.3512 rmse: 0.3030\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 85:  mse: 0.0258 nce_reg: -0.2311 loss: 0.0281 prediction_mean: 0.8454 prediction_std: 0.3290 rmse: 0.1605\n",
            "Val   85:  mse: 0.0885 nce_reg: -0.2183 loss: 0.0907 prediction_mean: 0.8423 prediction_std: 0.3174 rmse: 0.2975\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 86:  mse: 0.0246 nce_reg: -0.2228 loss: 0.0268 prediction_mean: 0.8445 prediction_std: 0.3281 rmse: 0.1569\n",
            "Val   86:  mse: 0.0864 nce_reg: -0.2102 loss: 0.0885 prediction_mean: 0.8521 prediction_std: 0.3328 rmse: 0.2939\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 87:  mse: 0.0237 nce_reg: -0.2184 loss: 0.0259 prediction_mean: 0.8441 prediction_std: 0.3289 rmse: 0.1539\n",
            "Val   87:  mse: 0.0892 nce_reg: -0.2070 loss: 0.0912 prediction_mean: 0.7918 prediction_std: 0.3417 rmse: 0.2986\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 88:  mse: 0.0257 nce_reg: -0.2158 loss: 0.0279 prediction_mean: 0.8446 prediction_std: 0.3310 rmse: 0.1603\n",
            "Val   88:  mse: 0.0950 nce_reg: -0.2067 loss: 0.0971 prediction_mean: 0.7877 prediction_std: 0.3331 rmse: 0.3082\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 89:  mse: 0.0248 nce_reg: -0.2136 loss: 0.0269 prediction_mean: 0.8436 prediction_std: 0.3303 rmse: 0.1573\n",
            "Val   89:  mse: 0.0920 nce_reg: -0.2013 loss: 0.0940 prediction_mean: 0.9146 prediction_std: 0.3423 rmse: 0.3034\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 90:  mse: 0.0252 nce_reg: -0.2109 loss: 0.0273 prediction_mean: 0.8452 prediction_std: 0.3312 rmse: 0.1588\n",
            "Val   90:  mse: 0.0880 nce_reg: -0.1948 loss: 0.0900 prediction_mean: 0.8284 prediction_std: 0.3289 rmse: 0.2967\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 91:  mse: 0.0226 nce_reg: -0.2054 loss: 0.0247 prediction_mean: 0.8451 prediction_std: 0.3305 rmse: 0.1504\n",
            "Val   91:  mse: 0.0928 nce_reg: -0.1884 loss: 0.0947 prediction_mean: 0.8478 prediction_std: 0.3506 rmse: 0.3046\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 92:  mse: 0.0225 nce_reg: -0.2008 loss: 0.0245 prediction_mean: 0.8439 prediction_std: 0.3300 rmse: 0.1500\n",
            "Val   92:  mse: 0.0890 nce_reg: -0.1847 loss: 0.0909 prediction_mean: 0.8219 prediction_std: 0.3318 rmse: 0.2983\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 93:  mse: 0.0254 nce_reg: -0.1962 loss: 0.0274 prediction_mean: 0.8441 prediction_std: 0.3339 rmse: 0.1594\n",
            "Val   93:  mse: 0.0957 nce_reg: -0.1932 loss: 0.0976 prediction_mean: 0.9469 prediction_std: 0.3244 rmse: 0.3093\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 94:  mse: 0.0225 nce_reg: -0.1955 loss: 0.0245 prediction_mean: 0.8454 prediction_std: 0.3301 rmse: 0.1500\n",
            "Val   94:  mse: 0.0862 nce_reg: -0.1825 loss: 0.0880 prediction_mean: 0.8630 prediction_std: 0.3192 rmse: 0.2936\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 95:  mse: 0.0229 nce_reg: -0.1894 loss: 0.0248 prediction_mean: 0.8443 prediction_std: 0.3309 rmse: 0.1513\n",
            "Val   95:  mse: 0.0867 nce_reg: -0.1813 loss: 0.0885 prediction_mean: 0.8439 prediction_std: 0.3253 rmse: 0.2944\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 96:  mse: 0.0249 nce_reg: -0.1856 loss: 0.0268 prediction_mean: 0.8461 prediction_std: 0.3319 rmse: 0.1578\n",
            "Val   96:  mse: 0.0890 nce_reg: -0.1807 loss: 0.0908 prediction_mean: 0.8863 prediction_std: 0.3292 rmse: 0.2983\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 97:  mse: 0.0223 nce_reg: -0.1850 loss: 0.0241 prediction_mean: 0.8440 prediction_std: 0.3323 rmse: 0.1492\n",
            "Val   97:  mse: 0.0880 nce_reg: -0.1738 loss: 0.0897 prediction_mean: 0.8771 prediction_std: 0.3228 rmse: 0.2966\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 98:  mse: 0.0224 nce_reg: -0.1789 loss: 0.0241 prediction_mean: 0.8442 prediction_std: 0.3320 rmse: 0.1495\n",
            "Val   98:  mse: 0.0887 nce_reg: -0.1684 loss: 0.0904 prediction_mean: 0.8694 prediction_std: 0.3603 rmse: 0.2978\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.34it/s]\n",
            "Train 99:  mse: 0.0235 nce_reg: -0.1780 loss: 0.0253 prediction_mean: 0.8445 prediction_std: 0.3340 rmse: 0.1535\n",
            "Val   99:  mse: 0.0915 nce_reg: -0.1690 loss: 0.0932 prediction_mean: 0.7916 prediction_std: 0.3434 rmse: 0.3025\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 100:  mse: 0.0211 nce_reg: -0.1745 loss: 0.0228 prediction_mean: 0.8445 prediction_std: 0.3312 rmse: 0.1452\n",
            "Val   100:  mse: 0.0881 nce_reg: -0.1656 loss: 0.0897 prediction_mean: 0.7974 prediction_std: 0.3468 rmse: 0.2967\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 101:  mse: 0.0206 nce_reg: -0.1699 loss: 0.0223 prediction_mean: 0.8443 prediction_std: 0.3343 rmse: 0.1435\n",
            "Val   101:  mse: 0.0904 nce_reg: -0.1575 loss: 0.0920 prediction_mean: 0.8590 prediction_std: 0.3333 rmse: 0.3007\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 102:  mse: 0.0214 nce_reg: -0.1653 loss: 0.0231 prediction_mean: 0.8451 prediction_std: 0.3335 rmse: 0.1464\n",
            "Val   102:  mse: 0.0911 nce_reg: -0.1618 loss: 0.0927 prediction_mean: 0.7941 prediction_std: 0.3338 rmse: 0.3018\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 103:  mse: 0.0214 nce_reg: -0.1636 loss: 0.0231 prediction_mean: 0.8439 prediction_std: 0.3351 rmse: 0.1464\n",
            "Val   103:  mse: 0.0899 nce_reg: -0.1552 loss: 0.0915 prediction_mean: 0.9174 prediction_std: 0.3438 rmse: 0.2999\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 104:  mse: 0.0201 nce_reg: -0.1603 loss: 0.0217 prediction_mean: 0.8457 prediction_std: 0.3329 rmse: 0.1419\n",
            "Val   104:  mse: 0.0941 nce_reg: -0.1490 loss: 0.0955 prediction_mean: 0.7694 prediction_std: 0.3362 rmse: 0.3067\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 105:  mse: 0.0242 nce_reg: -0.1588 loss: 0.0258 prediction_mean: 0.8448 prediction_std: 0.3380 rmse: 0.1557\n",
            "Val   105:  mse: 0.0897 nce_reg: -0.1537 loss: 0.0913 prediction_mean: 0.7634 prediction_std: 0.3206 rmse: 0.2995\n",
            "100% 167/167 [02:29<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 106:  mse: 0.0205 nce_reg: -0.1577 loss: 0.0221 prediction_mean: 0.8448 prediction_std: 0.3326 rmse: 0.1431\n",
            "Val   106:  mse: 0.0912 nce_reg: -0.1461 loss: 0.0926 prediction_mean: 0.8215 prediction_std: 0.3515 rmse: 0.3019\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 107:  mse: 0.0201 nce_reg: -0.1538 loss: 0.0216 prediction_mean: 0.8441 prediction_std: 0.3372 rmse: 0.1416\n",
            "Val   107:  mse: 0.0951 nce_reg: -0.1459 loss: 0.0966 prediction_mean: 0.9116 prediction_std: 0.3501 rmse: 0.3084\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 108:  mse: 0.0215 nce_reg: -0.1522 loss: 0.0231 prediction_mean: 0.8457 prediction_std: 0.3358 rmse: 0.1468\n",
            "Val   108:  mse: 0.0872 nce_reg: -0.1432 loss: 0.0886 prediction_mean: 0.8061 prediction_std: 0.3374 rmse: 0.2952\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 109:  mse: 0.0197 nce_reg: -0.1502 loss: 0.0212 prediction_mean: 0.8439 prediction_std: 0.3349 rmse: 0.1402\n",
            "Val   109:  mse: 0.0897 nce_reg: -0.1381 loss: 0.0911 prediction_mean: 0.8333 prediction_std: 0.3393 rmse: 0.2995\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 110:  mse: 0.0234 nce_reg: -0.1522 loss: 0.0249 prediction_mean: 0.8422 prediction_std: 0.3385 rmse: 0.1528\n",
            "Val   110:  mse: 0.0882 nce_reg: -0.1486 loss: 0.0897 prediction_mean: 0.8016 prediction_std: 0.3439 rmse: 0.2970\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 111:  mse: 0.0192 nce_reg: -0.1482 loss: 0.0207 prediction_mean: 0.8439 prediction_std: 0.3353 rmse: 0.1387\n",
            "Val   111:  mse: 0.0911 nce_reg: -0.1432 loss: 0.0925 prediction_mean: 0.8799 prediction_std: 0.3480 rmse: 0.3018\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 112:  mse: 0.0206 nce_reg: -0.1479 loss: 0.0220 prediction_mean: 0.8453 prediction_std: 0.3372 rmse: 0.1434\n",
            "Val   112:  mse: 0.0865 nce_reg: -0.1397 loss: 0.0879 prediction_mean: 0.8305 prediction_std: 0.3294 rmse: 0.2940\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 113:  mse: 0.0188 nce_reg: -0.1462 loss: 0.0202 prediction_mean: 0.8444 prediction_std: 0.3362 rmse: 0.1370\n",
            "Val   113:  mse: 0.0895 nce_reg: -0.1320 loss: 0.0908 prediction_mean: 0.8233 prediction_std: 0.3460 rmse: 0.2992\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 114:  mse: 0.0188 nce_reg: -0.1420 loss: 0.0202 prediction_mean: 0.8441 prediction_std: 0.3366 rmse: 0.1370\n",
            "Val   114:  mse: 0.0897 nce_reg: -0.1349 loss: 0.0911 prediction_mean: 0.7839 prediction_std: 0.3436 rmse: 0.2996\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 115:  mse: 0.0187 nce_reg: -0.1386 loss: 0.0200 prediction_mean: 0.8448 prediction_std: 0.3366 rmse: 0.1366\n",
            "Val   115:  mse: 0.0930 nce_reg: -0.1289 loss: 0.0943 prediction_mean: 0.7873 prediction_std: 0.3556 rmse: 0.3050\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 116:  mse: 0.0215 nce_reg: -0.1378 loss: 0.0228 prediction_mean: 0.8447 prediction_std: 0.3377 rmse: 0.1465\n",
            "Val   116:  mse: 0.0885 nce_reg: -0.1292 loss: 0.0898 prediction_mean: 0.8737 prediction_std: 0.3615 rmse: 0.2975\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 117:  mse: 0.0207 nce_reg: -0.1392 loss: 0.0221 prediction_mean: 0.8460 prediction_std: 0.3373 rmse: 0.1439\n",
            "Val   117:  mse: 0.0906 nce_reg: -0.1247 loss: 0.0918 prediction_mean: 0.8226 prediction_std: 0.3365 rmse: 0.3009\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 118:  mse: 0.0190 nce_reg: -0.1364 loss: 0.0204 prediction_mean: 0.8433 prediction_std: 0.3377 rmse: 0.1379\n",
            "Val   118:  mse: 0.0894 nce_reg: -0.1253 loss: 0.0907 prediction_mean: 0.7908 prediction_std: 0.3399 rmse: 0.2990\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.28it/s]\n",
            "Train 119:  mse: 0.0182 nce_reg: -0.1334 loss: 0.0196 prediction_mean: 0.8453 prediction_std: 0.3371 rmse: 0.1350\n",
            "Val   119:  mse: 0.0916 nce_reg: -0.1267 loss: 0.0928 prediction_mean: 0.7639 prediction_std: 0.3301 rmse: 0.3026\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 120:  mse: 0.0186 nce_reg: -0.1324 loss: 0.0200 prediction_mean: 0.8438 prediction_std: 0.3390 rmse: 0.1365\n",
            "Val   120:  mse: 0.0867 nce_reg: -0.1241 loss: 0.0879 prediction_mean: 0.8496 prediction_std: 0.3393 rmse: 0.2944\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 121:  mse: 0.0196 nce_reg: -0.1288 loss: 0.0209 prediction_mean: 0.8442 prediction_std: 0.3392 rmse: 0.1399\n",
            "Val   121:  mse: 0.1010 nce_reg: -0.1218 loss: 0.1022 prediction_mean: 0.7475 prediction_std: 0.3470 rmse: 0.3178\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 122:  mse: 0.0204 nce_reg: -0.1276 loss: 0.0217 prediction_mean: 0.8451 prediction_std: 0.3408 rmse: 0.1429\n",
            "Val   122:  mse: 0.0881 nce_reg: -0.1275 loss: 0.0894 prediction_mean: 0.8490 prediction_std: 0.3188 rmse: 0.2968\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 123:  mse: 0.0218 nce_reg: -0.1324 loss: 0.0231 prediction_mean: 0.8450 prediction_std: 0.3379 rmse: 0.1475\n",
            "Val   123:  mse: 0.0942 nce_reg: -0.1256 loss: 0.0955 prediction_mean: 0.7766 prediction_std: 0.3477 rmse: 0.3069\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 124:  mse: 0.0179 nce_reg: -0.1280 loss: 0.0192 prediction_mean: 0.8436 prediction_std: 0.3386 rmse: 0.1339\n",
            "Val   124:  mse: 0.0875 nce_reg: -0.1231 loss: 0.0887 prediction_mean: 0.8129 prediction_std: 0.3355 rmse: 0.2958\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 125:  mse: 0.0169 nce_reg: -0.1242 loss: 0.0182 prediction_mean: 0.8446 prediction_std: 0.3378 rmse: 0.1301\n",
            "Val   125:  mse: 0.0907 nce_reg: -0.1118 loss: 0.0919 prediction_mean: 0.8925 prediction_std: 0.3539 rmse: 0.3012\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 126:  mse: 0.0163 nce_reg: -0.1222 loss: 0.0175 prediction_mean: 0.8447 prediction_std: 0.3397 rmse: 0.1278\n",
            "Val   126:  mse: 0.0918 nce_reg: -0.1147 loss: 0.0929 prediction_mean: 0.9083 prediction_std: 0.3470 rmse: 0.3029\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 127:  mse: 0.0199 nce_reg: -0.1225 loss: 0.0211 prediction_mean: 0.8454 prediction_std: 0.3384 rmse: 0.1411\n",
            "Val   127:  mse: 0.0936 nce_reg: -0.1120 loss: 0.0947 prediction_mean: 0.7929 prediction_std: 0.3661 rmse: 0.3059\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 128:  mse: 0.0174 nce_reg: -0.1195 loss: 0.0186 prediction_mean: 0.8442 prediction_std: 0.3391 rmse: 0.1317\n",
            "Val   128:  mse: 0.0904 nce_reg: -0.1106 loss: 0.0915 prediction_mean: 0.8262 prediction_std: 0.3549 rmse: 0.3007\n",
            "100% 167/167 [02:29<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.33it/s]\n",
            "Train 129:  mse: 0.0182 nce_reg: -0.1165 loss: 0.0193 prediction_mean: 0.8457 prediction_std: 0.3408 rmse: 0.1348\n",
            "Val   129:  mse: 0.0962 nce_reg: -0.1135 loss: 0.0974 prediction_mean: 0.7577 prediction_std: 0.3329 rmse: 0.3102\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 130:  mse: 0.0170 nce_reg: -0.1164 loss: 0.0182 prediction_mean: 0.8442 prediction_std: 0.3387 rmse: 0.1304\n",
            "Val   130:  mse: 0.0883 nce_reg: -0.1078 loss: 0.0894 prediction_mean: 0.7998 prediction_std: 0.3521 rmse: 0.2972\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 131:  mse: 0.0173 nce_reg: -0.1135 loss: 0.0184 prediction_mean: 0.8430 prediction_std: 0.3407 rmse: 0.1315\n",
            "Val   131:  mse: 0.0915 nce_reg: -0.1119 loss: 0.0926 prediction_mean: 0.8936 prediction_std: 0.3394 rmse: 0.3025\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 132:  mse: 0.0174 nce_reg: -0.1157 loss: 0.0186 prediction_mean: 0.8455 prediction_std: 0.3399 rmse: 0.1319\n",
            "Val   132:  mse: 0.0886 nce_reg: -0.1070 loss: 0.0897 prediction_mean: 0.8836 prediction_std: 0.3445 rmse: 0.2977\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 133:  mse: 0.0169 nce_reg: -0.1134 loss: 0.0181 prediction_mean: 0.8464 prediction_std: 0.3407 rmse: 0.1301\n",
            "Val   133:  mse: 0.1052 nce_reg: -0.1075 loss: 0.1062 prediction_mean: 0.7188 prediction_std: 0.3553 rmse: 0.3243\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 134:  mse: 0.0180 nce_reg: -0.1125 loss: 0.0192 prediction_mean: 0.8444 prediction_std: 0.3400 rmse: 0.1343\n",
            "Val   134:  mse: 0.0955 nce_reg: -0.1067 loss: 0.0965 prediction_mean: 0.7727 prediction_std: 0.3534 rmse: 0.3090\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 135:  mse: 0.0164 nce_reg: -0.1103 loss: 0.0175 prediction_mean: 0.8448 prediction_std: 0.3407 rmse: 0.1281\n",
            "Val   135:  mse: 0.0880 nce_reg: -0.1064 loss: 0.0891 prediction_mean: 0.8018 prediction_std: 0.3464 rmse: 0.2966\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 136:  mse: 0.0167 nce_reg: -0.1091 loss: 0.0178 prediction_mean: 0.8438 prediction_std: 0.3418 rmse: 0.1292\n",
            "Val   136:  mse: 0.0914 nce_reg: -0.0984 loss: 0.0924 prediction_mean: 0.8921 prediction_std: 0.3353 rmse: 0.3024\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 137:  mse: 0.0171 nce_reg: -0.1081 loss: 0.0182 prediction_mean: 0.8451 prediction_std: 0.3410 rmse: 0.1308\n",
            "Val   137:  mse: 0.0908 nce_reg: -0.1063 loss: 0.0919 prediction_mean: 0.7724 prediction_std: 0.3328 rmse: 0.3014\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 138:  mse: 0.0160 nce_reg: -0.1071 loss: 0.0171 prediction_mean: 0.8436 prediction_std: 0.3429 rmse: 0.1265\n",
            "Val   138:  mse: 0.0829 nce_reg: -0.1015 loss: 0.0839 prediction_mean: 0.8607 prediction_std: 0.3436 rmse: 0.2879\n",
            "Model saved to: output/test/run_0/models/model_138\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 139:  mse: 0.0158 nce_reg: -0.1059 loss: 0.0169 prediction_mean: 0.8447 prediction_std: 0.3412 rmse: 0.1257\n",
            "Val   139:  mse: 0.0954 nce_reg: -0.0990 loss: 0.0964 prediction_mean: 0.7769 prediction_std: 0.3472 rmse: 0.3089\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 140:  mse: 0.0173 nce_reg: -0.1048 loss: 0.0183 prediction_mean: 0.8437 prediction_std: 0.3406 rmse: 0.1314\n",
            "Val   140:  mse: 0.0858 nce_reg: -0.0998 loss: 0.0868 prediction_mean: 0.8519 prediction_std: 0.3552 rmse: 0.2929\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 141:  mse: 0.0145 nce_reg: -0.1035 loss: 0.0155 prediction_mean: 0.8449 prediction_std: 0.3418 rmse: 0.1202\n",
            "Val   141:  mse: 0.0879 nce_reg: -0.0953 loss: 0.0889 prediction_mean: 0.8084 prediction_std: 0.3432 rmse: 0.2966\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 142:  mse: 0.0157 nce_reg: -0.1003 loss: 0.0167 prediction_mean: 0.8448 prediction_std: 0.3420 rmse: 0.1253\n",
            "Val   142:  mse: 0.0879 nce_reg: -0.0920 loss: 0.0888 prediction_mean: 0.8134 prediction_std: 0.3408 rmse: 0.2965\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 143:  mse: 0.0171 nce_reg: -0.1012 loss: 0.0181 prediction_mean: 0.8439 prediction_std: 0.3429 rmse: 0.1306\n",
            "Val   143:  mse: 0.0868 nce_reg: -0.0955 loss: 0.0878 prediction_mean: 0.8369 prediction_std: 0.3490 rmse: 0.2946\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 144:  mse: 0.0162 nce_reg: -0.1006 loss: 0.0172 prediction_mean: 0.8455 prediction_std: 0.3425 rmse: 0.1274\n",
            "Val   144:  mse: 0.1039 nce_reg: -0.1008 loss: 0.1049 prediction_mean: 0.7250 prediction_std: 0.3366 rmse: 0.3224\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 145:  mse: 0.0165 nce_reg: -0.0997 loss: 0.0175 prediction_mean: 0.8441 prediction_std: 0.3418 rmse: 0.1283\n",
            "Val   145:  mse: 0.0879 nce_reg: -0.0947 loss: 0.0888 prediction_mean: 0.8991 prediction_std: 0.3449 rmse: 0.2964\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 146:  mse: 0.0161 nce_reg: -0.0995 loss: 0.0171 prediction_mean: 0.8447 prediction_std: 0.3433 rmse: 0.1270\n",
            "Val   146:  mse: 0.0858 nce_reg: -0.0970 loss: 0.0867 prediction_mean: 0.8409 prediction_std: 0.3491 rmse: 0.2929\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 147:  mse: 0.0149 nce_reg: -0.0980 loss: 0.0159 prediction_mean: 0.8452 prediction_std: 0.3417 rmse: 0.1222\n",
            "Val   147:  mse: 0.0880 nce_reg: -0.0940 loss: 0.0890 prediction_mean: 0.8280 prediction_std: 0.3518 rmse: 0.2967\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 148:  mse: 0.0151 nce_reg: -0.0977 loss: 0.0161 prediction_mean: 0.8442 prediction_std: 0.3415 rmse: 0.1229\n",
            "Val   148:  mse: 0.0864 nce_reg: -0.0900 loss: 0.0873 prediction_mean: 0.8514 prediction_std: 0.3447 rmse: 0.2940\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 149:  mse: 0.0144 nce_reg: -0.0960 loss: 0.0153 prediction_mean: 0.8448 prediction_std: 0.3436 rmse: 0.1199\n",
            "Val   149:  mse: 0.0895 nce_reg: -0.0879 loss: 0.0904 prediction_mean: 0.7901 prediction_std: 0.3590 rmse: 0.2991\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 150:  mse: 0.0142 nce_reg: -0.0947 loss: 0.0151 prediction_mean: 0.8444 prediction_std: 0.3434 rmse: 0.1190\n",
            "Val   150:  mse: 0.0850 nce_reg: -0.0882 loss: 0.0858 prediction_mean: 0.8507 prediction_std: 0.3448 rmse: 0.2915\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 151:  mse: 0.0136 nce_reg: -0.0917 loss: 0.0145 prediction_mean: 0.8445 prediction_std: 0.3425 rmse: 0.1166\n",
            "Val   151:  mse: 0.0903 nce_reg: -0.0871 loss: 0.0912 prediction_mean: 0.8114 prediction_std: 0.3418 rmse: 0.3005\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 152:  mse: 0.0144 nce_reg: -0.0911 loss: 0.0153 prediction_mean: 0.8443 prediction_std: 0.3433 rmse: 0.1201\n",
            "Val   152:  mse: 0.0909 nce_reg: -0.0841 loss: 0.0917 prediction_mean: 0.8317 prediction_std: 0.3498 rmse: 0.3015\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 153:  mse: 0.0131 nce_reg: -0.0891 loss: 0.0140 prediction_mean: 0.8442 prediction_std: 0.3429 rmse: 0.1143\n",
            "Val   153:  mse: 0.0895 nce_reg: -0.0825 loss: 0.0903 prediction_mean: 0.8286 prediction_std: 0.3644 rmse: 0.2992\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 154:  mse: 0.0153 nce_reg: -0.0879 loss: 0.0162 prediction_mean: 0.8452 prediction_std: 0.3444 rmse: 0.1236\n",
            "Val   154:  mse: 0.0891 nce_reg: -0.0848 loss: 0.0900 prediction_mean: 0.8300 prediction_std: 0.3589 rmse: 0.2985\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 155:  mse: 0.0152 nce_reg: -0.0874 loss: 0.0160 prediction_mean: 0.8453 prediction_std: 0.3442 rmse: 0.1231\n",
            "Val   155:  mse: 0.0941 nce_reg: -0.0813 loss: 0.0949 prediction_mean: 0.7851 prediction_std: 0.3619 rmse: 0.3067\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 156:  mse: 0.0159 nce_reg: -0.0876 loss: 0.0168 prediction_mean: 0.8429 prediction_std: 0.3429 rmse: 0.1263\n",
            "Val   156:  mse: 0.0905 nce_reg: -0.0825 loss: 0.0914 prediction_mean: 0.7851 prediction_std: 0.3662 rmse: 0.3009\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 157:  mse: 0.0141 nce_reg: -0.0880 loss: 0.0150 prediction_mean: 0.8452 prediction_std: 0.3453 rmse: 0.1188\n",
            "Val   157:  mse: 0.0886 nce_reg: -0.0831 loss: 0.0895 prediction_mean: 0.8190 prediction_std: 0.3493 rmse: 0.2977\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 158:  mse: 0.0149 nce_reg: -0.0863 loss: 0.0158 prediction_mean: 0.8444 prediction_std: 0.3442 rmse: 0.1221\n",
            "Val   158:  mse: 0.0928 nce_reg: -0.0840 loss: 0.0937 prediction_mean: 0.7717 prediction_std: 0.3439 rmse: 0.3047\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 159:  mse: 0.0150 nce_reg: -0.0866 loss: 0.0158 prediction_mean: 0.8453 prediction_std: 0.3438 rmse: 0.1223\n",
            "Val   159:  mse: 0.0844 nce_reg: -0.0817 loss: 0.0852 prediction_mean: 0.8309 prediction_std: 0.3445 rmse: 0.2904\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 160:  mse: 0.0135 nce_reg: -0.0853 loss: 0.0144 prediction_mean: 0.8443 prediction_std: 0.3429 rmse: 0.1162\n",
            "Val   160:  mse: 0.0959 nce_reg: -0.0810 loss: 0.0967 prediction_mean: 0.7562 prediction_std: 0.3559 rmse: 0.3096\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 161:  mse: 0.0170 nce_reg: -0.0859 loss: 0.0179 prediction_mean: 0.8417 prediction_std: 0.3463 rmse: 0.1304\n",
            "Val   161:  mse: 0.0890 nce_reg: -0.0815 loss: 0.0898 prediction_mean: 0.9155 prediction_std: 0.3360 rmse: 0.2983\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 162:  mse: 0.0173 nce_reg: -0.0883 loss: 0.0182 prediction_mean: 0.8441 prediction_std: 0.3442 rmse: 0.1317\n",
            "Val   162:  mse: 0.0858 nce_reg: -0.0828 loss: 0.0866 prediction_mean: 0.8210 prediction_std: 0.3560 rmse: 0.2929\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 163:  mse: 0.0149 nce_reg: -0.0868 loss: 0.0158 prediction_mean: 0.8439 prediction_std: 0.3448 rmse: 0.1222\n",
            "Val   163:  mse: 0.0943 nce_reg: -0.0802 loss: 0.0952 prediction_mean: 0.7709 prediction_std: 0.3543 rmse: 0.3072\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 164:  mse: 0.0131 nce_reg: -0.0852 loss: 0.0139 prediction_mean: 0.8442 prediction_std: 0.3438 rmse: 0.1144\n",
            "Val   164:  mse: 0.0841 nce_reg: -0.0787 loss: 0.0849 prediction_mean: 0.8283 prediction_std: 0.3400 rmse: 0.2900\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 165:  mse: 0.0124 nce_reg: -0.0834 loss: 0.0132 prediction_mean: 0.8442 prediction_std: 0.3442 rmse: 0.1111\n",
            "Val   165:  mse: 0.0894 nce_reg: -0.0805 loss: 0.0902 prediction_mean: 0.7983 prediction_std: 0.3573 rmse: 0.2990\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 166:  mse: 0.0146 nce_reg: -0.0831 loss: 0.0154 prediction_mean: 0.8453 prediction_std: 0.3467 rmse: 0.1209\n",
            "Val   166:  mse: 0.0994 nce_reg: -0.0784 loss: 0.1002 prediction_mean: 0.7552 prediction_std: 0.3692 rmse: 0.3153\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 167:  mse: 0.0142 nce_reg: -0.0820 loss: 0.0150 prediction_mean: 0.8430 prediction_std: 0.3452 rmse: 0.1193\n",
            "Val   167:  mse: 0.0923 nce_reg: -0.0794 loss: 0.0931 prediction_mean: 0.9047 prediction_std: 0.3680 rmse: 0.3039\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 168:  mse: 0.0140 nce_reg: -0.0830 loss: 0.0148 prediction_mean: 0.8454 prediction_std: 0.3441 rmse: 0.1182\n",
            "Val   168:  mse: 0.0861 nce_reg: -0.0763 loss: 0.0869 prediction_mean: 0.8138 prediction_std: 0.3463 rmse: 0.2935\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 169:  mse: 0.0130 nce_reg: -0.0804 loss: 0.0138 prediction_mean: 0.8441 prediction_std: 0.3440 rmse: 0.1139\n",
            "Val   169:  mse: 0.0859 nce_reg: -0.0759 loss: 0.0867 prediction_mean: 0.8065 prediction_std: 0.3448 rmse: 0.2931\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 170:  mse: 0.0123 nce_reg: -0.0787 loss: 0.0131 prediction_mean: 0.8442 prediction_std: 0.3452 rmse: 0.1109\n",
            "Val   170:  mse: 0.0860 nce_reg: -0.0722 loss: 0.0867 prediction_mean: 0.8732 prediction_std: 0.3472 rmse: 0.2932\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 171:  mse: 0.0134 nce_reg: -0.0783 loss: 0.0142 prediction_mean: 0.8448 prediction_std: 0.3437 rmse: 0.1157\n",
            "Val   171:  mse: 0.0894 nce_reg: -0.0737 loss: 0.0901 prediction_mean: 0.8265 prediction_std: 0.3629 rmse: 0.2989\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 172:  mse: 0.0135 nce_reg: -0.0777 loss: 0.0143 prediction_mean: 0.8447 prediction_std: 0.3469 rmse: 0.1161\n",
            "Val   172:  mse: 0.0892 nce_reg: -0.0738 loss: 0.0899 prediction_mean: 0.8517 prediction_std: 0.3593 rmse: 0.2987\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 173:  mse: 0.0134 nce_reg: -0.0763 loss: 0.0142 prediction_mean: 0.8439 prediction_std: 0.3453 rmse: 0.1159\n",
            "Val   173:  mse: 0.0870 nce_reg: -0.0730 loss: 0.0878 prediction_mean: 0.8630 prediction_std: 0.3440 rmse: 0.2950\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 174:  mse: 0.0127 nce_reg: -0.0756 loss: 0.0134 prediction_mean: 0.8463 prediction_std: 0.3449 rmse: 0.1126\n",
            "Val   174:  mse: 0.0881 nce_reg: -0.0710 loss: 0.0888 prediction_mean: 0.7889 prediction_std: 0.3621 rmse: 0.2968\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 175:  mse: 0.0128 nce_reg: -0.0751 loss: 0.0135 prediction_mean: 0.8438 prediction_std: 0.3476 rmse: 0.1129\n",
            "Val   175:  mse: 0.0856 nce_reg: -0.0708 loss: 0.0863 prediction_mean: 0.8556 prediction_std: 0.3532 rmse: 0.2926\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 176:  mse: 0.0128 nce_reg: -0.0750 loss: 0.0136 prediction_mean: 0.8444 prediction_std: 0.3457 rmse: 0.1133\n",
            "Val   176:  mse: 0.0887 nce_reg: -0.0701 loss: 0.0894 prediction_mean: 0.8411 prediction_std: 0.3612 rmse: 0.2978\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 177:  mse: 0.0132 nce_reg: -0.0748 loss: 0.0140 prediction_mean: 0.8436 prediction_std: 0.3466 rmse: 0.1150\n",
            "Val   177:  mse: 0.0858 nce_reg: -0.0712 loss: 0.0865 prediction_mean: 0.8190 prediction_std: 0.3493 rmse: 0.2929\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 178:  mse: 0.0131 nce_reg: -0.0747 loss: 0.0139 prediction_mean: 0.8451 prediction_std: 0.3463 rmse: 0.1145\n",
            "Val   178:  mse: 0.1028 nce_reg: -0.0698 loss: 0.1035 prediction_mean: 0.7349 prediction_std: 0.3577 rmse: 0.3206\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 179:  mse: 0.0123 nce_reg: -0.0735 loss: 0.0131 prediction_mean: 0.8443 prediction_std: 0.3464 rmse: 0.1110\n",
            "Val   179:  mse: 0.0941 nce_reg: -0.0681 loss: 0.0948 prediction_mean: 0.7719 prediction_std: 0.3545 rmse: 0.3068\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 180:  mse: 0.0122 nce_reg: -0.0720 loss: 0.0129 prediction_mean: 0.8447 prediction_std: 0.3471 rmse: 0.1105\n",
            "Val   180:  mse: 0.0892 nce_reg: -0.0692 loss: 0.0899 prediction_mean: 0.8160 prediction_std: 0.3435 rmse: 0.2987\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 181:  mse: 0.0131 nce_reg: -0.0739 loss: 0.0138 prediction_mean: 0.8444 prediction_std: 0.3458 rmse: 0.1143\n",
            "Val   181:  mse: 0.0892 nce_reg: -0.0685 loss: 0.0899 prediction_mean: 0.7980 prediction_std: 0.3548 rmse: 0.2986\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 182:  mse: 0.0117 nce_reg: -0.0719 loss: 0.0124 prediction_mean: 0.8446 prediction_std: 0.3461 rmse: 0.1081\n",
            "Val   182:  mse: 0.0860 nce_reg: -0.0673 loss: 0.0867 prediction_mean: 0.8197 prediction_std: 0.3490 rmse: 0.2933\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 183:  mse: 0.0127 nce_reg: -0.0710 loss: 0.0135 prediction_mean: 0.8449 prediction_std: 0.3471 rmse: 0.1129\n",
            "Val   183:  mse: 0.0881 nce_reg: -0.0684 loss: 0.0888 prediction_mean: 0.7978 prediction_std: 0.3490 rmse: 0.2969\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 184:  mse: 0.0118 nce_reg: -0.0701 loss: 0.0125 prediction_mean: 0.8436 prediction_std: 0.3470 rmse: 0.1087\n",
            "Val   184:  mse: 0.0872 nce_reg: -0.0669 loss: 0.0879 prediction_mean: 0.8673 prediction_std: 0.3585 rmse: 0.2954\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 185:  mse: 0.0131 nce_reg: -0.0698 loss: 0.0138 prediction_mean: 0.8457 prediction_std: 0.3456 rmse: 0.1146\n",
            "Val   185:  mse: 0.0940 nce_reg: -0.0639 loss: 0.0947 prediction_mean: 0.7815 prediction_std: 0.3634 rmse: 0.3067\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 186:  mse: 0.0133 nce_reg: -0.0700 loss: 0.0140 prediction_mean: 0.8441 prediction_std: 0.3459 rmse: 0.1153\n",
            "Val   186:  mse: 0.0887 nce_reg: -0.0657 loss: 0.0893 prediction_mean: 0.8678 prediction_std: 0.3558 rmse: 0.2978\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 187:  mse: 0.0135 nce_reg: -0.0695 loss: 0.0142 prediction_mean: 0.8439 prediction_std: 0.3466 rmse: 0.1163\n",
            "Val   187:  mse: 0.0901 nce_reg: -0.0660 loss: 0.0907 prediction_mean: 0.9104 prediction_std: 0.3569 rmse: 0.3001\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 188:  mse: 0.0117 nce_reg: -0.0698 loss: 0.0124 prediction_mean: 0.8447 prediction_std: 0.3464 rmse: 0.1084\n",
            "Val   188:  mse: 0.0855 nce_reg: -0.0649 loss: 0.0862 prediction_mean: 0.8452 prediction_std: 0.3469 rmse: 0.2925\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 189:  mse: 0.0103 nce_reg: -0.0675 loss: 0.0110 prediction_mean: 0.8448 prediction_std: 0.3483 rmse: 0.1017\n",
            "Val   189:  mse: 0.0899 nce_reg: -0.0626 loss: 0.0905 prediction_mean: 0.7899 prediction_std: 0.3432 rmse: 0.2998\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.34it/s]\n",
            "Train 190:  mse: 0.0111 nce_reg: -0.0672 loss: 0.0117 prediction_mean: 0.8443 prediction_std: 0.3467 rmse: 0.1052\n",
            "Val   190:  mse: 0.0881 nce_reg: -0.0640 loss: 0.0887 prediction_mean: 0.8210 prediction_std: 0.3476 rmse: 0.2967\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 191:  mse: 0.0105 nce_reg: -0.0663 loss: 0.0112 prediction_mean: 0.8444 prediction_std: 0.3478 rmse: 0.1026\n",
            "Val   191:  mse: 0.0885 nce_reg: -0.0631 loss: 0.0891 prediction_mean: 0.8891 prediction_std: 0.3413 rmse: 0.2975\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 192:  mse: 0.0123 nce_reg: -0.0664 loss: 0.0130 prediction_mean: 0.8457 prediction_std: 0.3466 rmse: 0.1109\n",
            "Val   192:  mse: 0.0938 nce_reg: -0.0627 loss: 0.0945 prediction_mean: 0.7803 prediction_std: 0.3627 rmse: 0.3063\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 193:  mse: 0.0116 nce_reg: -0.0663 loss: 0.0123 prediction_mean: 0.8442 prediction_std: 0.3481 rmse: 0.1077\n",
            "Val   193:  mse: 0.0890 nce_reg: -0.0626 loss: 0.0896 prediction_mean: 0.8079 prediction_std: 0.3597 rmse: 0.2984\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 194:  mse: 0.0116 nce_reg: -0.0650 loss: 0.0122 prediction_mean: 0.8443 prediction_std: 0.3483 rmse: 0.1077\n",
            "Val   194:  mse: 0.0904 nce_reg: -0.0626 loss: 0.0910 prediction_mean: 0.8493 prediction_std: 0.3579 rmse: 0.3006\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 195:  mse: 0.0151 nce_reg: -0.0667 loss: 0.0158 prediction_mean: 0.8451 prediction_std: 0.3484 rmse: 0.1228\n",
            "Val   195:  mse: 0.0888 nce_reg: -0.0630 loss: 0.0894 prediction_mean: 0.8266 prediction_std: 0.3536 rmse: 0.2980\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 196:  mse: 0.0119 nce_reg: -0.0660 loss: 0.0126 prediction_mean: 0.8438 prediction_std: 0.3456 rmse: 0.1092\n",
            "Val   196:  mse: 0.0886 nce_reg: -0.0610 loss: 0.0892 prediction_mean: 0.8646 prediction_std: 0.3600 rmse: 0.2976\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 197:  mse: 0.0127 nce_reg: -0.0651 loss: 0.0134 prediction_mean: 0.8452 prediction_std: 0.3476 rmse: 0.1128\n",
            "Val   197:  mse: 0.0892 nce_reg: -0.0611 loss: 0.0898 prediction_mean: 0.8611 prediction_std: 0.3493 rmse: 0.2987\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.34it/s]\n",
            "Train 198:  mse: 0.0112 nce_reg: -0.0637 loss: 0.0118 prediction_mean: 0.8438 prediction_std: 0.3473 rmse: 0.1056\n",
            "Val   198:  mse: 0.0939 nce_reg: -0.0619 loss: 0.0945 prediction_mean: 0.9041 prediction_std: 0.3656 rmse: 0.3064\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.34it/s]\n",
            "Train 199:  mse: 0.0111 nce_reg: -0.0645 loss: 0.0118 prediction_mean: 0.8439 prediction_std: 0.3475 rmse: 0.1055\n",
            "Val   199:  mse: 0.0915 nce_reg: -0.0610 loss: 0.0921 prediction_mean: 0.8562 prediction_std: 0.3654 rmse: 0.3025\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 200:  mse: 0.0115 nce_reg: -0.0634 loss: 0.0121 prediction_mean: 0.8449 prediction_std: 0.3478 rmse: 0.1070\n",
            "Val   200:  mse: 0.0858 nce_reg: -0.0592 loss: 0.0864 prediction_mean: 0.8754 prediction_std: 0.3454 rmse: 0.2929\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 201:  mse: 0.0136 nce_reg: -0.0638 loss: 0.0143 prediction_mean: 0.8446 prediction_std: 0.3491 rmse: 0.1168\n",
            "Val   201:  mse: 0.0876 nce_reg: -0.0589 loss: 0.0882 prediction_mean: 0.8201 prediction_std: 0.3460 rmse: 0.2960\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 202:  mse: 0.0115 nce_reg: -0.0643 loss: 0.0122 prediction_mean: 0.8441 prediction_std: 0.3477 rmse: 0.1073\n",
            "Val   202:  mse: 0.0879 nce_reg: -0.0611 loss: 0.0885 prediction_mean: 0.8203 prediction_std: 0.3564 rmse: 0.2964\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 203:  mse: 0.0094 nce_reg: -0.0619 loss: 0.0101 prediction_mean: 0.8450 prediction_std: 0.3472 rmse: 0.0971\n",
            "Val   203:  mse: 0.0913 nce_reg: -0.0574 loss: 0.0919 prediction_mean: 0.7715 prediction_std: 0.3549 rmse: 0.3021\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 204:  mse: 0.0114 nce_reg: -0.0617 loss: 0.0120 prediction_mean: 0.8440 prediction_std: 0.3491 rmse: 0.1066\n",
            "Val   204:  mse: 0.0854 nce_reg: -0.0599 loss: 0.0860 prediction_mean: 0.8408 prediction_std: 0.3449 rmse: 0.2922\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 205:  mse: 0.0097 nce_reg: -0.0615 loss: 0.0103 prediction_mean: 0.8448 prediction_std: 0.3469 rmse: 0.0984\n",
            "Val   205:  mse: 0.0879 nce_reg: -0.0564 loss: 0.0884 prediction_mean: 0.8710 prediction_std: 0.3509 rmse: 0.2964\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 206:  mse: 0.0094 nce_reg: -0.0595 loss: 0.0100 prediction_mean: 0.8452 prediction_std: 0.3487 rmse: 0.0967\n",
            "Val   206:  mse: 0.0876 nce_reg: -0.0566 loss: 0.0882 prediction_mean: 0.8209 prediction_std: 0.3564 rmse: 0.2960\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 207:  mse: 0.0119 nce_reg: -0.0601 loss: 0.0125 prediction_mean: 0.8444 prediction_std: 0.3483 rmse: 0.1090\n",
            "Val   207:  mse: 0.0873 nce_reg: -0.0562 loss: 0.0878 prediction_mean: 0.8445 prediction_std: 0.3600 rmse: 0.2954\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 208:  mse: 0.0095 nce_reg: -0.0592 loss: 0.0101 prediction_mean: 0.8450 prediction_std: 0.3485 rmse: 0.0975\n",
            "Val   208:  mse: 0.0908 nce_reg: -0.0548 loss: 0.0914 prediction_mean: 0.8072 prediction_std: 0.3360 rmse: 0.3014\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 209:  mse: 0.0124 nce_reg: -0.0591 loss: 0.0130 prediction_mean: 0.8447 prediction_std: 0.3489 rmse: 0.1114\n",
            "Val   209:  mse: 0.1011 nce_reg: -0.0567 loss: 0.1017 prediction_mean: 0.7286 prediction_std: 0.3536 rmse: 0.3180\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 210:  mse: 0.0106 nce_reg: -0.0592 loss: 0.0112 prediction_mean: 0.8444 prediction_std: 0.3484 rmse: 0.1028\n",
            "Val   210:  mse: 0.0860 nce_reg: -0.0565 loss: 0.0866 prediction_mean: 0.8610 prediction_std: 0.3490 rmse: 0.2932\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 211:  mse: 0.0119 nce_reg: -0.0591 loss: 0.0125 prediction_mean: 0.8446 prediction_std: 0.3493 rmse: 0.1092\n",
            "Val   211:  mse: 0.0897 nce_reg: -0.0560 loss: 0.0903 prediction_mean: 0.8095 prediction_std: 0.3651 rmse: 0.2996\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 212:  mse: 0.0106 nce_reg: -0.0586 loss: 0.0112 prediction_mean: 0.8447 prediction_std: 0.3489 rmse: 0.1028\n",
            "Val   212:  mse: 0.0876 nce_reg: -0.0561 loss: 0.0882 prediction_mean: 0.8224 prediction_std: 0.3458 rmse: 0.2960\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 213:  mse: 0.0139 nce_reg: -0.0594 loss: 0.0145 prediction_mean: 0.8442 prediction_std: 0.3485 rmse: 0.1177\n",
            "Val   213:  mse: 0.0889 nce_reg: -0.0565 loss: 0.0895 prediction_mean: 0.8075 prediction_std: 0.3452 rmse: 0.2982\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 214:  mse: 0.0114 nce_reg: -0.0586 loss: 0.0120 prediction_mean: 0.8442 prediction_std: 0.3461 rmse: 0.1067\n",
            "Val   214:  mse: 0.0890 nce_reg: -0.0558 loss: 0.0895 prediction_mean: 0.8071 prediction_std: 0.3556 rmse: 0.2983\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 215:  mse: 0.0104 nce_reg: -0.0585 loss: 0.0110 prediction_mean: 0.8450 prediction_std: 0.3487 rmse: 0.1019\n",
            "Val   215:  mse: 0.0873 nce_reg: -0.0568 loss: 0.0879 prediction_mean: 0.8499 prediction_std: 0.3395 rmse: 0.2955\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 216:  mse: 0.0118 nce_reg: -0.0583 loss: 0.0124 prediction_mean: 0.8448 prediction_std: 0.3483 rmse: 0.1086\n",
            "Val   216:  mse: 0.0951 nce_reg: -0.0536 loss: 0.0956 prediction_mean: 0.7691 prediction_std: 0.3482 rmse: 0.3084\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 217:  mse: 0.0131 nce_reg: -0.0589 loss: 0.0136 prediction_mean: 0.8450 prediction_std: 0.3499 rmse: 0.1143\n",
            "Val   217:  mse: 0.0907 nce_reg: -0.0555 loss: 0.0912 prediction_mean: 0.8338 prediction_std: 0.3496 rmse: 0.3011\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 218:  mse: 0.0110 nce_reg: -0.0581 loss: 0.0116 prediction_mean: 0.8440 prediction_std: 0.3471 rmse: 0.1047\n",
            "Val   218:  mse: 0.0940 nce_reg: -0.0553 loss: 0.0946 prediction_mean: 0.7666 prediction_std: 0.3448 rmse: 0.3066\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 219:  mse: 0.0101 nce_reg: -0.0571 loss: 0.0106 prediction_mean: 0.8442 prediction_std: 0.3483 rmse: 0.1003\n",
            "Val   219:  mse: 0.0902 nce_reg: -0.0539 loss: 0.0908 prediction_mean: 0.8543 prediction_std: 0.3636 rmse: 0.3004\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 220:  mse: 0.0095 nce_reg: -0.0562 loss: 0.0101 prediction_mean: 0.8456 prediction_std: 0.3490 rmse: 0.0976\n",
            "Val   220:  mse: 0.0893 nce_reg: -0.0527 loss: 0.0899 prediction_mean: 0.8199 prediction_std: 0.3608 rmse: 0.2989\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 221:  mse: 0.0104 nce_reg: -0.0560 loss: 0.0110 prediction_mean: 0.8444 prediction_std: 0.3498 rmse: 0.1022\n",
            "Val   221:  mse: 0.0898 nce_reg: -0.0542 loss: 0.0903 prediction_mean: 0.8370 prediction_std: 0.3656 rmse: 0.2996\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 222:  mse: 0.0111 nce_reg: -0.0562 loss: 0.0117 prediction_mean: 0.8448 prediction_std: 0.3498 rmse: 0.1054\n",
            "Val   222:  mse: 0.0866 nce_reg: -0.0555 loss: 0.0871 prediction_mean: 0.8501 prediction_std: 0.3435 rmse: 0.2943\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 223:  mse: 0.0107 nce_reg: -0.0567 loss: 0.0113 prediction_mean: 0.8440 prediction_std: 0.3478 rmse: 0.1036\n",
            "Val   223:  mse: 0.0911 nce_reg: -0.0549 loss: 0.0917 prediction_mean: 0.8152 prediction_std: 0.3540 rmse: 0.3019\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.34it/s]\n",
            "Train 224:  mse: 0.0111 nce_reg: -0.0563 loss: 0.0116 prediction_mean: 0.8444 prediction_std: 0.3497 rmse: 0.1052\n",
            "Val   224:  mse: 0.0887 nce_reg: -0.0526 loss: 0.0892 prediction_mean: 0.7937 prediction_std: 0.3562 rmse: 0.2978\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 225:  mse: 0.0120 nce_reg: -0.0559 loss: 0.0125 prediction_mean: 0.8442 prediction_std: 0.3490 rmse: 0.1095\n",
            "Val   225:  mse: 0.0871 nce_reg: -0.0537 loss: 0.0876 prediction_mean: 0.8414 prediction_std: 0.3574 rmse: 0.2951\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 226:  mse: 0.0110 nce_reg: -0.0564 loss: 0.0116 prediction_mean: 0.8446 prediction_std: 0.3482 rmse: 0.1049\n",
            "Val   226:  mse: 0.0926 nce_reg: -0.0527 loss: 0.0931 prediction_mean: 0.7834 prediction_std: 0.3463 rmse: 0.3043\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 227:  mse: 0.0100 nce_reg: -0.0555 loss: 0.0106 prediction_mean: 0.8446 prediction_std: 0.3489 rmse: 0.1002\n",
            "Val   227:  mse: 0.0877 nce_reg: -0.0523 loss: 0.0883 prediction_mean: 0.8356 prediction_std: 0.3549 rmse: 0.2962\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 228:  mse: 0.0094 nce_reg: -0.0540 loss: 0.0100 prediction_mean: 0.8446 prediction_std: 0.3497 rmse: 0.0972\n",
            "Val   228:  mse: 0.0878 nce_reg: -0.0514 loss: 0.0883 prediction_mean: 0.8527 prediction_std: 0.3559 rmse: 0.2963\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 229:  mse: 0.0095 nce_reg: -0.0537 loss: 0.0100 prediction_mean: 0.8446 prediction_std: 0.3487 rmse: 0.0973\n",
            "Val   229:  mse: 0.0879 nce_reg: -0.0498 loss: 0.0884 prediction_mean: 0.8185 prediction_std: 0.3523 rmse: 0.2965\n",
            "100% 167/167 [02:19<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 230:  mse: 0.0091 nce_reg: -0.0528 loss: 0.0096 prediction_mean: 0.8446 prediction_std: 0.3489 rmse: 0.0954\n",
            "Val   230:  mse: 0.0866 nce_reg: -0.0487 loss: 0.0871 prediction_mean: 0.8331 prediction_std: 0.3540 rmse: 0.2943\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 231:  mse: 0.0110 nce_reg: -0.0526 loss: 0.0116 prediction_mean: 0.8446 prediction_std: 0.3497 rmse: 0.1051\n",
            "Val   231:  mse: 0.0951 nce_reg: -0.0510 loss: 0.0956 prediction_mean: 0.7572 prediction_std: 0.3390 rmse: 0.3084\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 232:  mse: 0.0110 nce_reg: -0.0533 loss: 0.0116 prediction_mean: 0.8440 prediction_std: 0.3500 rmse: 0.1051\n",
            "Val   232:  mse: 0.0891 nce_reg: -0.0484 loss: 0.0896 prediction_mean: 0.8217 prediction_std: 0.3479 rmse: 0.2986\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 233:  mse: 0.0096 nce_reg: -0.0521 loss: 0.0101 prediction_mean: 0.8446 prediction_std: 0.3485 rmse: 0.0980\n",
            "Val   233:  mse: 0.0898 nce_reg: -0.0487 loss: 0.0903 prediction_mean: 0.8771 prediction_std: 0.3545 rmse: 0.2997\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 234:  mse: 0.0097 nce_reg: -0.0519 loss: 0.0102 prediction_mean: 0.8443 prediction_std: 0.3494 rmse: 0.0984\n",
            "Val   234:  mse: 0.0891 nce_reg: -0.0492 loss: 0.0896 prediction_mean: 0.8382 prediction_std: 0.3481 rmse: 0.2985\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 235:  mse: 0.0097 nce_reg: -0.0511 loss: 0.0102 prediction_mean: 0.8446 prediction_std: 0.3506 rmse: 0.0984\n",
            "Val   235:  mse: 0.0890 nce_reg: -0.0495 loss: 0.0895 prediction_mean: 0.8387 prediction_std: 0.3511 rmse: 0.2984\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 236:  mse: 0.0096 nce_reg: -0.0515 loss: 0.0101 prediction_mean: 0.8450 prediction_std: 0.3488 rmse: 0.0977\n",
            "Val   236:  mse: 0.0897 nce_reg: -0.0487 loss: 0.0902 prediction_mean: 0.7866 prediction_std: 0.3532 rmse: 0.2995\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 237:  mse: 0.0090 nce_reg: -0.0511 loss: 0.0095 prediction_mean: 0.8449 prediction_std: 0.3494 rmse: 0.0949\n",
            "Val   237:  mse: 0.0971 nce_reg: -0.0488 loss: 0.0976 prediction_mean: 0.7638 prediction_std: 0.3611 rmse: 0.3116\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 238:  mse: 0.0091 nce_reg: -0.0506 loss: 0.0096 prediction_mean: 0.8448 prediction_std: 0.3505 rmse: 0.0954\n",
            "Val   238:  mse: 0.1068 nce_reg: -0.0482 loss: 0.1073 prediction_mean: 0.7085 prediction_std: 0.3573 rmse: 0.3268\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 239:  mse: 0.0109 nce_reg: -0.0506 loss: 0.0114 prediction_mean: 0.8438 prediction_std: 0.3503 rmse: 0.1046\n",
            "Val   239:  mse: 0.0880 nce_reg: -0.0473 loss: 0.0884 prediction_mean: 0.8128 prediction_std: 0.3390 rmse: 0.2966\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 240:  mse: 0.0105 nce_reg: -0.0507 loss: 0.0110 prediction_mean: 0.8443 prediction_std: 0.3502 rmse: 0.1022\n",
            "Val   240:  mse: 0.0891 nce_reg: -0.0457 loss: 0.0895 prediction_mean: 0.8107 prediction_std: 0.3471 rmse: 0.2984\n",
            "100% 167/167 [02:29<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 241:  mse: 0.0087 nce_reg: -0.0498 loss: 0.0092 prediction_mean: 0.8443 prediction_std: 0.3493 rmse: 0.0931\n",
            "Val   241:  mse: 0.0883 nce_reg: -0.0470 loss: 0.0888 prediction_mean: 0.8442 prediction_std: 0.3565 rmse: 0.2972\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 242:  mse: 0.0134 nce_reg: -0.0498 loss: 0.0139 prediction_mean: 0.8444 prediction_std: 0.3503 rmse: 0.1159\n",
            "Val   242:  mse: 0.0886 nce_reg: -0.0466 loss: 0.0890 prediction_mean: 0.8263 prediction_std: 0.3480 rmse: 0.2976\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 243:  mse: 0.0111 nce_reg: -0.0504 loss: 0.0116 prediction_mean: 0.8450 prediction_std: 0.3511 rmse: 0.1054\n",
            "Val   243:  mse: 0.1085 nce_reg: -0.0491 loss: 0.1090 prediction_mean: 0.7092 prediction_std: 0.3555 rmse: 0.3293\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 244:  mse: 0.0115 nce_reg: -0.0510 loss: 0.0120 prediction_mean: 0.8446 prediction_std: 0.3498 rmse: 0.1074\n",
            "Val   244:  mse: 0.0916 nce_reg: -0.0483 loss: 0.0921 prediction_mean: 0.7909 prediction_std: 0.3581 rmse: 0.3027\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 245:  mse: 0.0087 nce_reg: -0.0500 loss: 0.0092 prediction_mean: 0.8447 prediction_std: 0.3501 rmse: 0.0931\n",
            "Val   245:  mse: 0.0903 nce_reg: -0.0478 loss: 0.0908 prediction_mean: 0.8163 prediction_std: 0.3593 rmse: 0.3005\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 246:  mse: 0.0087 nce_reg: -0.0494 loss: 0.0092 prediction_mean: 0.8457 prediction_std: 0.3497 rmse: 0.0932\n",
            "Val   246:  mse: 0.0980 nce_reg: -0.0458 loss: 0.0985 prediction_mean: 0.7437 prediction_std: 0.3559 rmse: 0.3131\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 247:  mse: 0.0095 nce_reg: -0.0489 loss: 0.0100 prediction_mean: 0.8440 prediction_std: 0.3512 rmse: 0.0976\n",
            "Val   247:  mse: 0.0934 nce_reg: -0.0448 loss: 0.0939 prediction_mean: 0.7829 prediction_std: 0.3435 rmse: 0.3056\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 248:  mse: 0.0095 nce_reg: -0.0491 loss: 0.0100 prediction_mean: 0.8440 prediction_std: 0.3489 rmse: 0.0974\n",
            "Val   248:  mse: 0.0960 nce_reg: -0.0449 loss: 0.0964 prediction_mean: 0.9066 prediction_std: 0.3592 rmse: 0.3098\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 249:  mse: 0.0124 nce_reg: -0.0495 loss: 0.0129 prediction_mean: 0.8443 prediction_std: 0.3506 rmse: 0.1115\n",
            "Val   249:  mse: 0.0909 nce_reg: -0.0477 loss: 0.0913 prediction_mean: 0.9005 prediction_std: 0.3599 rmse: 0.3014\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 250:  mse: 0.0102 nce_reg: -0.0491 loss: 0.0107 prediction_mean: 0.8451 prediction_std: 0.3495 rmse: 0.1010\n",
            "Val   250:  mse: 0.0924 nce_reg: -0.0452 loss: 0.0929 prediction_mean: 0.7986 prediction_std: 0.3714 rmse: 0.3041\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 251:  mse: 0.0085 nce_reg: -0.0478 loss: 0.0090 prediction_mean: 0.8447 prediction_std: 0.3496 rmse: 0.0922\n",
            "Val   251:  mse: 0.0895 nce_reg: -0.0450 loss: 0.0899 prediction_mean: 0.8404 prediction_std: 0.3553 rmse: 0.2991\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 252:  mse: 0.0087 nce_reg: -0.0477 loss: 0.0092 prediction_mean: 0.8450 prediction_std: 0.3502 rmse: 0.0935\n",
            "Val   252:  mse: 0.0870 nce_reg: -0.0465 loss: 0.0875 prediction_mean: 0.8666 prediction_std: 0.3570 rmse: 0.2949\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 253:  mse: 0.0098 nce_reg: -0.0479 loss: 0.0103 prediction_mean: 0.8439 prediction_std: 0.3511 rmse: 0.0989\n",
            "Val   253:  mse: 0.0879 nce_reg: -0.0461 loss: 0.0884 prediction_mean: 0.8310 prediction_std: 0.3532 rmse: 0.2965\n",
            "100% 167/167 [02:19<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.49it/s]\n",
            "Train 254:  mse: 0.0092 nce_reg: -0.0470 loss: 0.0096 prediction_mean: 0.8451 prediction_std: 0.3498 rmse: 0.0958\n",
            "Val   254:  mse: 0.0886 nce_reg: -0.0454 loss: 0.0890 prediction_mean: 0.8444 prediction_std: 0.3482 rmse: 0.2976\n",
            "100% 167/167 [02:18<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 255:  mse: 0.0098 nce_reg: -0.0473 loss: 0.0103 prediction_mean: 0.8447 prediction_std: 0.3495 rmse: 0.0992\n",
            "Val   255:  mse: 0.0904 nce_reg: -0.0453 loss: 0.0908 prediction_mean: 0.8714 prediction_std: 0.3673 rmse: 0.3006\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 256:  mse: 0.0094 nce_reg: -0.0476 loss: 0.0099 prediction_mean: 0.8446 prediction_std: 0.3512 rmse: 0.0969\n",
            "Val   256:  mse: 0.0913 nce_reg: -0.0438 loss: 0.0917 prediction_mean: 0.7820 prediction_std: 0.3537 rmse: 0.3021\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 257:  mse: 0.0095 nce_reg: -0.0468 loss: 0.0100 prediction_mean: 0.8449 prediction_std: 0.3510 rmse: 0.0977\n",
            "Val   257:  mse: 0.0874 nce_reg: -0.0424 loss: 0.0879 prediction_mean: 0.8209 prediction_std: 0.3476 rmse: 0.2957\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 258:  mse: 0.0090 nce_reg: -0.0463 loss: 0.0095 prediction_mean: 0.8443 prediction_std: 0.3503 rmse: 0.0951\n",
            "Val   258:  mse: 0.0886 nce_reg: -0.0442 loss: 0.0890 prediction_mean: 0.8524 prediction_std: 0.3606 rmse: 0.2977\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 259:  mse: 0.0088 nce_reg: -0.0468 loss: 0.0092 prediction_mean: 0.8440 prediction_std: 0.3506 rmse: 0.0937\n",
            "Val   259:  mse: 0.0926 nce_reg: -0.0433 loss: 0.0930 prediction_mean: 0.8568 prediction_std: 0.3666 rmse: 0.3042\n",
            "100% 167/167 [02:22<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 260:  mse: 0.0089 nce_reg: -0.0460 loss: 0.0094 prediction_mean: 0.8450 prediction_std: 0.3505 rmse: 0.0945\n",
            "Val   260:  mse: 0.0883 nce_reg: -0.0428 loss: 0.0888 prediction_mean: 0.8405 prediction_std: 0.3471 rmse: 0.2972\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 261:  mse: 0.0115 nce_reg: -0.0466 loss: 0.0120 prediction_mean: 0.8439 prediction_std: 0.3515 rmse: 0.1072\n",
            "Val   261:  mse: 0.0904 nce_reg: -0.0434 loss: 0.0908 prediction_mean: 0.8193 prediction_std: 0.3631 rmse: 0.3006\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 262:  mse: 0.0087 nce_reg: -0.0465 loss: 0.0092 prediction_mean: 0.8450 prediction_std: 0.3499 rmse: 0.0934\n",
            "Val   262:  mse: 0.0916 nce_reg: -0.0429 loss: 0.0921 prediction_mean: 0.8152 prediction_std: 0.3799 rmse: 0.3027\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 263:  mse: 0.0109 nce_reg: -0.0462 loss: 0.0114 prediction_mean: 0.8441 prediction_std: 0.3523 rmse: 0.1044\n",
            "Val   263:  mse: 0.0876 nce_reg: -0.0448 loss: 0.0881 prediction_mean: 0.8117 prediction_std: 0.3343 rmse: 0.2961\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.51it/s]\n",
            "Train 264:  mse: 0.0096 nce_reg: -0.0467 loss: 0.0100 prediction_mean: 0.8453 prediction_std: 0.3493 rmse: 0.0978\n",
            "Val   264:  mse: 0.0900 nce_reg: -0.0440 loss: 0.0905 prediction_mean: 0.8179 prediction_std: 0.3659 rmse: 0.3000\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 265:  mse: 0.0074 nce_reg: -0.0458 loss: 0.0078 prediction_mean: 0.8442 prediction_std: 0.3513 rmse: 0.0858\n",
            "Val   265:  mse: 0.0869 nce_reg: -0.0426 loss: 0.0873 prediction_mean: 0.8430 prediction_std: 0.3470 rmse: 0.2948\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 266:  mse: 0.0088 nce_reg: -0.0448 loss: 0.0093 prediction_mean: 0.8446 prediction_std: 0.3510 rmse: 0.0938\n",
            "Val   266:  mse: 0.0878 nce_reg: -0.0427 loss: 0.0883 prediction_mean: 0.8335 prediction_std: 0.3588 rmse: 0.2964\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 267:  mse: 0.0092 nce_reg: -0.0447 loss: 0.0097 prediction_mean: 0.8438 prediction_std: 0.3523 rmse: 0.0961\n",
            "Val   267:  mse: 0.0974 nce_reg: -0.0417 loss: 0.0978 prediction_mean: 0.9370 prediction_std: 0.3420 rmse: 0.3121\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 268:  mse: 0.0094 nce_reg: -0.0450 loss: 0.0099 prediction_mean: 0.8461 prediction_std: 0.3485 rmse: 0.0970\n",
            "Val   268:  mse: 0.0914 nce_reg: -0.0423 loss: 0.0918 prediction_mean: 0.8012 prediction_std: 0.3510 rmse: 0.3022\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 269:  mse: 0.0102 nce_reg: -0.0446 loss: 0.0106 prediction_mean: 0.8443 prediction_std: 0.3507 rmse: 0.1009\n",
            "Val   269:  mse: 0.0904 nce_reg: -0.0435 loss: 0.0908 prediction_mean: 0.8752 prediction_std: 0.3642 rmse: 0.3006\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 270:  mse: 0.0091 nce_reg: -0.0452 loss: 0.0096 prediction_mean: 0.8441 prediction_std: 0.3507 rmse: 0.0956\n",
            "Val   270:  mse: 0.0979 nce_reg: -0.0428 loss: 0.0984 prediction_mean: 0.7804 prediction_std: 0.3671 rmse: 0.3129\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.33it/s]\n",
            "Train 271:  mse: 0.0081 nce_reg: -0.0441 loss: 0.0086 prediction_mean: 0.8446 prediction_std: 0.3517 rmse: 0.0901\n",
            "Val   271:  mse: 0.0888 nce_reg: -0.0428 loss: 0.0893 prediction_mean: 0.8704 prediction_std: 0.3522 rmse: 0.2981\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 272:  mse: 0.0085 nce_reg: -0.0444 loss: 0.0089 prediction_mean: 0.8449 prediction_std: 0.3510 rmse: 0.0920\n",
            "Val   272:  mse: 0.0903 nce_reg: -0.0412 loss: 0.0907 prediction_mean: 0.7968 prediction_std: 0.3452 rmse: 0.3004\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 273:  mse: 0.0077 nce_reg: -0.0433 loss: 0.0081 prediction_mean: 0.8442 prediction_std: 0.3501 rmse: 0.0875\n",
            "Val   273:  mse: 0.0888 nce_reg: -0.0411 loss: 0.0892 prediction_mean: 0.8418 prediction_std: 0.3542 rmse: 0.2980\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 274:  mse: 0.0095 nce_reg: -0.0435 loss: 0.0100 prediction_mean: 0.8445 prediction_std: 0.3522 rmse: 0.0976\n",
            "Val   274:  mse: 0.0950 nce_reg: -0.0407 loss: 0.0954 prediction_mean: 0.7584 prediction_std: 0.3500 rmse: 0.3082\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 275:  mse: 0.0106 nce_reg: -0.0435 loss: 0.0110 prediction_mean: 0.8450 prediction_std: 0.3515 rmse: 0.1027\n",
            "Val   275:  mse: 0.0889 nce_reg: -0.0416 loss: 0.0893 prediction_mean: 0.8724 prediction_std: 0.3502 rmse: 0.2982\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 276:  mse: 0.0096 nce_reg: -0.0432 loss: 0.0100 prediction_mean: 0.8440 prediction_std: 0.3502 rmse: 0.0979\n",
            "Val   276:  mse: 0.0899 nce_reg: -0.0405 loss: 0.0903 prediction_mean: 0.8256 prediction_std: 0.3457 rmse: 0.2998\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 277:  mse: 0.0078 nce_reg: -0.0428 loss: 0.0082 prediction_mean: 0.8446 prediction_std: 0.3512 rmse: 0.0883\n",
            "Val   277:  mse: 0.0952 nce_reg: -0.0410 loss: 0.0956 prediction_mean: 0.7779 prediction_std: 0.3682 rmse: 0.3085\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 278:  mse: 0.0074 nce_reg: -0.0425 loss: 0.0078 prediction_mean: 0.8451 prediction_std: 0.3514 rmse: 0.0858\n",
            "Val   278:  mse: 0.0931 nce_reg: -0.0387 loss: 0.0935 prediction_mean: 0.7886 prediction_std: 0.3597 rmse: 0.3051\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 279:  mse: 0.0070 nce_reg: -0.0418 loss: 0.0074 prediction_mean: 0.8447 prediction_std: 0.3526 rmse: 0.0837\n",
            "Val   279:  mse: 0.0933 nce_reg: -0.0389 loss: 0.0937 prediction_mean: 0.7953 prediction_std: 0.3533 rmse: 0.3055\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 280:  mse: 0.0076 nce_reg: -0.0416 loss: 0.0080 prediction_mean: 0.8442 prediction_std: 0.3510 rmse: 0.0872\n",
            "Val   280:  mse: 0.0940 nce_reg: -0.0393 loss: 0.0944 prediction_mean: 0.8096 prediction_std: 0.3679 rmse: 0.3065\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.51it/s]\n",
            "Train 281:  mse: 0.0074 nce_reg: -0.0406 loss: 0.0078 prediction_mean: 0.8443 prediction_std: 0.3514 rmse: 0.0859\n",
            "Val   281:  mse: 0.0933 nce_reg: -0.0392 loss: 0.0937 prediction_mean: 0.7996 prediction_std: 0.3561 rmse: 0.3054\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 282:  mse: 0.0078 nce_reg: -0.0405 loss: 0.0082 prediction_mean: 0.8445 prediction_std: 0.3522 rmse: 0.0885\n",
            "Val   282:  mse: 0.0952 nce_reg: -0.0376 loss: 0.0956 prediction_mean: 0.7849 prediction_std: 0.3573 rmse: 0.3085\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 283:  mse: 0.0094 nce_reg: -0.0407 loss: 0.0098 prediction_mean: 0.8448 prediction_std: 0.3515 rmse: 0.0972\n",
            "Val   283:  mse: 0.0906 nce_reg: -0.0380 loss: 0.0910 prediction_mean: 0.8390 prediction_std: 0.3482 rmse: 0.3010\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.49it/s]\n",
            "Train 284:  mse: 0.0086 nce_reg: -0.0407 loss: 0.0090 prediction_mean: 0.8442 prediction_std: 0.3505 rmse: 0.0927\n",
            "Val   284:  mse: 0.0921 nce_reg: -0.0391 loss: 0.0925 prediction_mean: 0.8170 prediction_std: 0.3678 rmse: 0.3035\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 285:  mse: 0.0104 nce_reg: -0.0409 loss: 0.0108 prediction_mean: 0.8450 prediction_std: 0.3521 rmse: 0.1021\n",
            "Val   285:  mse: 0.0908 nce_reg: -0.0386 loss: 0.0912 prediction_mean: 0.8407 prediction_std: 0.3531 rmse: 0.3013\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 286:  mse: 0.0086 nce_reg: -0.0406 loss: 0.0090 prediction_mean: 0.8443 prediction_std: 0.3504 rmse: 0.0929\n",
            "Val   286:  mse: 0.0938 nce_reg: -0.0381 loss: 0.0942 prediction_mean: 0.7954 prediction_std: 0.3479 rmse: 0.3063\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 287:  mse: 0.0086 nce_reg: -0.0401 loss: 0.0090 prediction_mean: 0.8442 prediction_std: 0.3503 rmse: 0.0928\n",
            "Val   287:  mse: 0.0921 nce_reg: -0.0369 loss: 0.0924 prediction_mean: 0.8599 prediction_std: 0.3536 rmse: 0.3034\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 288:  mse: 0.0104 nce_reg: -0.0404 loss: 0.0108 prediction_mean: 0.8445 prediction_std: 0.3521 rmse: 0.1021\n",
            "Val   288:  mse: 0.0963 nce_reg: -0.0389 loss: 0.0967 prediction_mean: 0.7609 prediction_std: 0.3548 rmse: 0.3104\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 289:  mse: 0.0084 nce_reg: -0.0404 loss: 0.0088 prediction_mean: 0.8446 prediction_std: 0.3512 rmse: 0.0916\n",
            "Val   289:  mse: 0.0890 nce_reg: -0.0366 loss: 0.0894 prediction_mean: 0.8599 prediction_std: 0.3532 rmse: 0.2984\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 290:  mse: 0.0069 nce_reg: -0.0395 loss: 0.0073 prediction_mean: 0.8448 prediction_std: 0.3521 rmse: 0.0831\n",
            "Val   290:  mse: 0.0902 nce_reg: -0.0366 loss: 0.0906 prediction_mean: 0.8499 prediction_std: 0.3549 rmse: 0.3004\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 291:  mse: 0.0076 nce_reg: -0.0393 loss: 0.0080 prediction_mean: 0.8443 prediction_std: 0.3518 rmse: 0.0871\n",
            "Val   291:  mse: 0.0914 nce_reg: -0.0364 loss: 0.0918 prediction_mean: 0.8873 prediction_std: 0.3531 rmse: 0.3023\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 292:  mse: 0.0072 nce_reg: -0.0390 loss: 0.0076 prediction_mean: 0.8450 prediction_std: 0.3517 rmse: 0.0849\n",
            "Val   292:  mse: 0.0991 nce_reg: -0.0364 loss: 0.0995 prediction_mean: 0.7802 prediction_std: 0.3770 rmse: 0.3149\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 293:  mse: 0.0079 nce_reg: -0.0388 loss: 0.0083 prediction_mean: 0.8444 prediction_std: 0.3524 rmse: 0.0889\n",
            "Val   293:  mse: 0.0899 nce_reg: -0.0371 loss: 0.0903 prediction_mean: 0.8725 prediction_std: 0.3631 rmse: 0.2998\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 294:  mse: 0.0080 nce_reg: -0.0382 loss: 0.0084 prediction_mean: 0.8453 prediction_std: 0.3532 rmse: 0.0893\n",
            "Val   294:  mse: 0.1142 nce_reg: -0.0354 loss: 0.1146 prediction_mean: 0.7035 prediction_std: 0.3643 rmse: 0.3380\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 295:  mse: 0.0080 nce_reg: -0.0390 loss: 0.0084 prediction_mean: 0.8445 prediction_std: 0.3513 rmse: 0.0895\n",
            "Val   295:  mse: 0.0968 nce_reg: -0.0368 loss: 0.0972 prediction_mean: 0.7602 prediction_std: 0.3537 rmse: 0.3112\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 296:  mse: 0.0079 nce_reg: -0.0386 loss: 0.0083 prediction_mean: 0.8445 prediction_std: 0.3515 rmse: 0.0888\n",
            "Val   296:  mse: 0.0880 nce_reg: -0.0361 loss: 0.0884 prediction_mean: 0.8578 prediction_std: 0.3394 rmse: 0.2967\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 297:  mse: 0.0065 nce_reg: -0.0375 loss: 0.0069 prediction_mean: 0.8447 prediction_std: 0.3528 rmse: 0.0807\n",
            "Val   297:  mse: 0.0939 nce_reg: -0.0344 loss: 0.0942 prediction_mean: 0.8535 prediction_std: 0.3758 rmse: 0.3064\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 298:  mse: 0.0086 nce_reg: -0.0377 loss: 0.0089 prediction_mean: 0.8443 prediction_std: 0.3527 rmse: 0.0926\n",
            "Val   298:  mse: 0.0917 nce_reg: -0.0359 loss: 0.0921 prediction_mean: 0.8798 prediction_std: 0.3409 rmse: 0.3029\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 299:  mse: 0.0081 nce_reg: -0.0379 loss: 0.0085 prediction_mean: 0.8442 prediction_std: 0.3495 rmse: 0.0901\n",
            "Val   299:  mse: 0.0905 nce_reg: -0.0354 loss: 0.0909 prediction_mean: 0.8458 prediction_std: 0.3628 rmse: 0.3009\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 300:  mse: 0.0101 nce_reg: -0.0378 loss: 0.0105 prediction_mean: 0.8456 prediction_std: 0.3526 rmse: 0.1004\n",
            "Val   300:  mse: 0.0924 nce_reg: -0.0361 loss: 0.0928 prediction_mean: 0.8412 prediction_std: 0.3606 rmse: 0.3041\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 301:  mse: 0.0097 nce_reg: -0.0381 loss: 0.0101 prediction_mean: 0.8440 prediction_std: 0.3494 rmse: 0.0984\n",
            "Val   301:  mse: 0.0945 nce_reg: -0.0346 loss: 0.0948 prediction_mean: 0.7879 prediction_std: 0.3702 rmse: 0.3074\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 302:  mse: 0.0077 nce_reg: -0.0379 loss: 0.0081 prediction_mean: 0.8447 prediction_std: 0.3521 rmse: 0.0878\n",
            "Val   302:  mse: 0.0899 nce_reg: -0.0363 loss: 0.0902 prediction_mean: 0.8109 prediction_std: 0.3542 rmse: 0.2998\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 303:  mse: 0.0074 nce_reg: -0.0372 loss: 0.0078 prediction_mean: 0.8444 prediction_std: 0.3517 rmse: 0.0859\n",
            "Val   303:  mse: 0.0928 nce_reg: -0.0341 loss: 0.0932 prediction_mean: 0.8261 prediction_std: 0.3495 rmse: 0.3047\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 304:  mse: 0.0075 nce_reg: -0.0371 loss: 0.0079 prediction_mean: 0.8444 prediction_std: 0.3527 rmse: 0.0867\n",
            "Val   304:  mse: 0.0937 nce_reg: -0.0350 loss: 0.0941 prediction_mean: 0.8558 prediction_std: 0.3676 rmse: 0.3061\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 305:  mse: 0.0081 nce_reg: -0.0372 loss: 0.0085 prediction_mean: 0.8442 prediction_std: 0.3520 rmse: 0.0899\n",
            "Val   305:  mse: 0.0915 nce_reg: -0.0351 loss: 0.0919 prediction_mean: 0.8661 prediction_std: 0.3565 rmse: 0.3026\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 306:  mse: 0.0086 nce_reg: -0.0375 loss: 0.0090 prediction_mean: 0.8451 prediction_std: 0.3532 rmse: 0.0927\n",
            "Val   306:  mse: 0.0918 nce_reg: -0.0345 loss: 0.0922 prediction_mean: 0.8123 prediction_std: 0.3510 rmse: 0.3031\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 307:  mse: 0.0070 nce_reg: -0.0367 loss: 0.0074 prediction_mean: 0.8442 prediction_std: 0.3511 rmse: 0.0839\n",
            "Val   307:  mse: 0.0917 nce_reg: -0.0349 loss: 0.0920 prediction_mean: 0.8393 prediction_std: 0.3696 rmse: 0.3028\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 308:  mse: 0.0074 nce_reg: -0.0363 loss: 0.0077 prediction_mean: 0.8447 prediction_std: 0.3523 rmse: 0.0858\n",
            "Val   308:  mse: 0.0874 nce_reg: -0.0346 loss: 0.0877 prediction_mean: 0.8099 prediction_std: 0.3535 rmse: 0.2956\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 309:  mse: 0.0089 nce_reg: -0.0362 loss: 0.0093 prediction_mean: 0.8448 prediction_std: 0.3529 rmse: 0.0944\n",
            "Val   309:  mse: 0.0915 nce_reg: -0.0345 loss: 0.0918 prediction_mean: 0.7970 prediction_std: 0.3482 rmse: 0.3024\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 310:  mse: 0.0065 nce_reg: -0.0360 loss: 0.0069 prediction_mean: 0.8448 prediction_std: 0.3519 rmse: 0.0806\n",
            "Val   310:  mse: 0.1027 nce_reg: -0.0348 loss: 0.1031 prediction_mean: 0.7460 prediction_std: 0.3749 rmse: 0.3205\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 311:  mse: 0.0072 nce_reg: -0.0355 loss: 0.0076 prediction_mean: 0.8446 prediction_std: 0.3532 rmse: 0.0849\n",
            "Val   311:  mse: 0.0919 nce_reg: -0.0344 loss: 0.0923 prediction_mean: 0.8496 prediction_std: 0.3683 rmse: 0.3032\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 312:  mse: 0.0095 nce_reg: -0.0360 loss: 0.0098 prediction_mean: 0.8450 prediction_std: 0.3528 rmse: 0.0974\n",
            "Val   312:  mse: 0.0914 nce_reg: -0.0333 loss: 0.0918 prediction_mean: 0.8730 prediction_std: 0.3472 rmse: 0.3024\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 313:  mse: 0.0084 nce_reg: -0.0360 loss: 0.0087 prediction_mean: 0.8442 prediction_std: 0.3508 rmse: 0.0916\n",
            "Val   313:  mse: 0.0921 nce_reg: -0.0344 loss: 0.0924 prediction_mean: 0.8284 prediction_std: 0.3633 rmse: 0.3034\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 314:  mse: 0.0089 nce_reg: -0.0359 loss: 0.0093 prediction_mean: 0.8451 prediction_std: 0.3524 rmse: 0.0945\n",
            "Val   314:  mse: 0.0934 nce_reg: -0.0338 loss: 0.0938 prediction_mean: 0.8604 prediction_std: 0.3611 rmse: 0.3057\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 315:  mse: 0.0083 nce_reg: -0.0365 loss: 0.0087 prediction_mean: 0.8443 prediction_std: 0.3516 rmse: 0.0912\n",
            "Val   315:  mse: 0.0948 nce_reg: -0.0342 loss: 0.0951 prediction_mean: 0.7981 prediction_std: 0.3481 rmse: 0.3079\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 316:  mse: 0.0079 nce_reg: -0.0354 loss: 0.0083 prediction_mean: 0.8448 prediction_std: 0.3529 rmse: 0.0890\n",
            "Val   316:  mse: 0.0999 nce_reg: -0.0322 loss: 0.1002 prediction_mean: 0.7703 prediction_std: 0.3685 rmse: 0.3160\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 317:  mse: 0.0071 nce_reg: -0.0357 loss: 0.0075 prediction_mean: 0.8441 prediction_std: 0.3525 rmse: 0.0843\n",
            "Val   317:  mse: 0.0919 nce_reg: -0.0333 loss: 0.0922 prediction_mean: 0.8600 prediction_std: 0.3611 rmse: 0.3031\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 318:  mse: 0.0073 nce_reg: -0.0352 loss: 0.0077 prediction_mean: 0.8453 prediction_std: 0.3527 rmse: 0.0855\n",
            "Val   318:  mse: 0.0954 nce_reg: -0.0345 loss: 0.0957 prediction_mean: 0.8077 prediction_std: 0.3634 rmse: 0.3088\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 319:  mse: 0.0078 nce_reg: -0.0353 loss: 0.0082 prediction_mean: 0.8443 prediction_std: 0.3527 rmse: 0.0884\n",
            "Val   319:  mse: 0.0916 nce_reg: -0.0333 loss: 0.0919 prediction_mean: 0.8221 prediction_std: 0.3432 rmse: 0.3026\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.33it/s]\n",
            "Train 320:  mse: 0.0090 nce_reg: -0.0358 loss: 0.0094 prediction_mean: 0.8444 prediction_std: 0.3525 rmse: 0.0951\n",
            "Val   320:  mse: 0.0946 nce_reg: -0.0345 loss: 0.0949 prediction_mean: 0.8227 prediction_std: 0.3538 rmse: 0.3076\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 321:  mse: 0.0094 nce_reg: -0.0362 loss: 0.0097 prediction_mean: 0.8451 prediction_std: 0.3524 rmse: 0.0967\n",
            "Val   321:  mse: 0.0990 nce_reg: -0.0343 loss: 0.0993 prediction_mean: 0.7701 prediction_std: 0.3595 rmse: 0.3146\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 322:  mse: 0.0089 nce_reg: -0.0361 loss: 0.0092 prediction_mean: 0.8443 prediction_std: 0.3512 rmse: 0.0943\n",
            "Val   322:  mse: 0.0952 nce_reg: -0.0330 loss: 0.0955 prediction_mean: 0.7794 prediction_std: 0.3430 rmse: 0.3085\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 323:  mse: 0.0069 nce_reg: -0.0354 loss: 0.0073 prediction_mean: 0.8440 prediction_std: 0.3515 rmse: 0.0834\n",
            "Val   323:  mse: 0.0936 nce_reg: -0.0327 loss: 0.0939 prediction_mean: 0.8421 prediction_std: 0.3606 rmse: 0.3059\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 324:  mse: 0.0075 nce_reg: -0.0348 loss: 0.0078 prediction_mean: 0.8443 prediction_std: 0.3530 rmse: 0.0864\n",
            "Val   324:  mse: 0.0905 nce_reg: -0.0314 loss: 0.0908 prediction_mean: 0.8541 prediction_std: 0.3502 rmse: 0.3008\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 325:  mse: 0.0065 nce_reg: -0.0344 loss: 0.0069 prediction_mean: 0.8446 prediction_std: 0.3522 rmse: 0.0809\n",
            "Val   325:  mse: 0.0903 nce_reg: -0.0332 loss: 0.0907 prediction_mean: 0.8337 prediction_std: 0.3539 rmse: 0.3006\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 326:  mse: 0.0067 nce_reg: -0.0342 loss: 0.0071 prediction_mean: 0.8449 prediction_std: 0.3531 rmse: 0.0820\n",
            "Val   326:  mse: 0.0954 nce_reg: -0.0325 loss: 0.0957 prediction_mean: 0.7889 prediction_std: 0.3537 rmse: 0.3088\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 327:  mse: 0.0076 nce_reg: -0.0342 loss: 0.0079 prediction_mean: 0.8442 prediction_std: 0.3521 rmse: 0.0871\n",
            "Val   327:  mse: 0.0943 nce_reg: -0.0327 loss: 0.0946 prediction_mean: 0.8347 prediction_std: 0.3551 rmse: 0.3070\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 328:  mse: 0.0085 nce_reg: -0.0345 loss: 0.0089 prediction_mean: 0.8448 prediction_std: 0.3522 rmse: 0.0923\n",
            "Val   328:  mse: 0.1054 nce_reg: -0.0337 loss: 0.1057 prediction_mean: 0.7402 prediction_std: 0.3622 rmse: 0.3246\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 329:  mse: 0.0078 nce_reg: -0.0343 loss: 0.0082 prediction_mean: 0.8445 prediction_std: 0.3513 rmse: 0.0886\n",
            "Val   329:  mse: 0.0952 nce_reg: -0.0315 loss: 0.0955 prediction_mean: 0.8142 prediction_std: 0.3600 rmse: 0.3086\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 330:  mse: 0.0069 nce_reg: -0.0335 loss: 0.0072 prediction_mean: 0.8441 prediction_std: 0.3529 rmse: 0.0831\n",
            "Val   330:  mse: 0.0909 nce_reg: -0.0314 loss: 0.0912 prediction_mean: 0.8812 prediction_std: 0.3480 rmse: 0.3016\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 331:  mse: 0.0087 nce_reg: -0.0340 loss: 0.0091 prediction_mean: 0.8443 prediction_std: 0.3532 rmse: 0.0935\n",
            "Val   331:  mse: 0.0970 nce_reg: -0.0316 loss: 0.0974 prediction_mean: 0.9125 prediction_std: 0.3454 rmse: 0.3115\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 332:  mse: 0.0067 nce_reg: -0.0343 loss: 0.0071 prediction_mean: 0.8452 prediction_std: 0.3526 rmse: 0.0821\n",
            "Val   332:  mse: 0.0935 nce_reg: -0.0318 loss: 0.0939 prediction_mean: 0.8414 prediction_std: 0.3622 rmse: 0.3058\n",
            "100% 167/167 [02:18<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.48it/s]\n",
            "Train 333:  mse: 0.0067 nce_reg: -0.0332 loss: 0.0070 prediction_mean: 0.8443 prediction_std: 0.3527 rmse: 0.0817\n",
            "Val   333:  mse: 0.0944 nce_reg: -0.0307 loss: 0.0947 prediction_mean: 0.8265 prediction_std: 0.3622 rmse: 0.3072\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 334:  mse: 0.0077 nce_reg: -0.0329 loss: 0.0081 prediction_mean: 0.8441 prediction_std: 0.3532 rmse: 0.0879\n",
            "Val   334:  mse: 0.0936 nce_reg: -0.0315 loss: 0.0939 prediction_mean: 0.8256 prediction_std: 0.3608 rmse: 0.3060\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 335:  mse: 0.0091 nce_reg: -0.0331 loss: 0.0095 prediction_mean: 0.8445 prediction_std: 0.3537 rmse: 0.0956\n",
            "Val   335:  mse: 0.0888 nce_reg: -0.0326 loss: 0.0891 prediction_mean: 0.8353 prediction_std: 0.3505 rmse: 0.2980\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 336:  mse: 0.0068 nce_reg: -0.0335 loss: 0.0071 prediction_mean: 0.8440 prediction_std: 0.3513 rmse: 0.0822\n",
            "Val   336:  mse: 0.0976 nce_reg: -0.0313 loss: 0.0980 prediction_mean: 0.8603 prediction_std: 0.3765 rmse: 0.3125\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 337:  mse: 0.0071 nce_reg: -0.0329 loss: 0.0074 prediction_mean: 0.8448 prediction_std: 0.3524 rmse: 0.0841\n",
            "Val   337:  mse: 0.0954 nce_reg: -0.0300 loss: 0.0957 prediction_mean: 0.8196 prediction_std: 0.3642 rmse: 0.3088\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 338:  mse: 0.0069 nce_reg: -0.0323 loss: 0.0073 prediction_mean: 0.8452 prediction_std: 0.3531 rmse: 0.0833\n",
            "Val   338:  mse: 0.0928 nce_reg: -0.0326 loss: 0.0932 prediction_mean: 0.8855 prediction_std: 0.3515 rmse: 0.3047\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 339:  mse: 0.0078 nce_reg: -0.0328 loss: 0.0081 prediction_mean: 0.8444 prediction_std: 0.3529 rmse: 0.0883\n",
            "Val   339:  mse: 0.0958 nce_reg: -0.0311 loss: 0.0961 prediction_mean: 0.8057 prediction_std: 0.3642 rmse: 0.3095\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 340:  mse: 0.0068 nce_reg: -0.0324 loss: 0.0072 prediction_mean: 0.8444 prediction_std: 0.3517 rmse: 0.0827\n",
            "Val   340:  mse: 0.0911 nce_reg: -0.0308 loss: 0.0914 prediction_mean: 0.8730 prediction_std: 0.3540 rmse: 0.3018\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 341:  mse: 0.0067 nce_reg: -0.0319 loss: 0.0070 prediction_mean: 0.8446 prediction_std: 0.3537 rmse: 0.0817\n",
            "Val   341:  mse: 0.0909 nce_reg: -0.0312 loss: 0.0912 prediction_mean: 0.8652 prediction_std: 0.3412 rmse: 0.3014\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 342:  mse: 0.0097 nce_reg: -0.0324 loss: 0.0100 prediction_mean: 0.8436 prediction_std: 0.3522 rmse: 0.0986\n",
            "Val   342:  mse: 0.0908 nce_reg: -0.0297 loss: 0.0911 prediction_mean: 0.8079 prediction_std: 0.3397 rmse: 0.3014\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 343:  mse: 0.0086 nce_reg: -0.0323 loss: 0.0089 prediction_mean: 0.8447 prediction_std: 0.3521 rmse: 0.0929\n",
            "Val   343:  mse: 0.0950 nce_reg: -0.0308 loss: 0.0953 prediction_mean: 0.8355 prediction_std: 0.3741 rmse: 0.3082\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.49it/s]\n",
            "Train 344:  mse: 0.0064 nce_reg: -0.0323 loss: 0.0067 prediction_mean: 0.8451 prediction_std: 0.3526 rmse: 0.0801\n",
            "Val   344:  mse: 0.0925 nce_reg: -0.0303 loss: 0.0928 prediction_mean: 0.8085 prediction_std: 0.3531 rmse: 0.3042\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 345:  mse: 0.0082 nce_reg: -0.0318 loss: 0.0086 prediction_mean: 0.8446 prediction_std: 0.3527 rmse: 0.0908\n",
            "Val   345:  mse: 0.0961 nce_reg: -0.0301 loss: 0.0964 prediction_mean: 0.7824 prediction_std: 0.3536 rmse: 0.3100\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 346:  mse: 0.0082 nce_reg: -0.0318 loss: 0.0086 prediction_mean: 0.8446 prediction_std: 0.3524 rmse: 0.0908\n",
            "Val   346:  mse: 0.0946 nce_reg: -0.0298 loss: 0.0949 prediction_mean: 0.8135 prediction_std: 0.3664 rmse: 0.3075\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 347:  mse: 0.0070 nce_reg: -0.0314 loss: 0.0073 prediction_mean: 0.8444 prediction_std: 0.3518 rmse: 0.0837\n",
            "Val   347:  mse: 0.0951 nce_reg: -0.0300 loss: 0.0954 prediction_mean: 0.8100 prediction_std: 0.3637 rmse: 0.3084\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 348:  mse: 0.0059 nce_reg: -0.0308 loss: 0.0062 prediction_mean: 0.8449 prediction_std: 0.3541 rmse: 0.0766\n",
            "Val   348:  mse: 0.0980 nce_reg: -0.0300 loss: 0.0983 prediction_mean: 0.7653 prediction_std: 0.3544 rmse: 0.3131\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.49it/s]\n",
            "Train 349:  mse: 0.0071 nce_reg: -0.0313 loss: 0.0074 prediction_mean: 0.8446 prediction_std: 0.3534 rmse: 0.0842\n",
            "Val   349:  mse: 0.0919 nce_reg: -0.0287 loss: 0.0921 prediction_mean: 0.8363 prediction_std: 0.3562 rmse: 0.3031\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 350:  mse: 0.0068 nce_reg: -0.0312 loss: 0.0071 prediction_mean: 0.8440 prediction_std: 0.3536 rmse: 0.0824\n",
            "Val   350:  mse: 0.0921 nce_reg: -0.0302 loss: 0.0924 prediction_mean: 0.8618 prediction_std: 0.3505 rmse: 0.3034\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 351:  mse: 0.0069 nce_reg: -0.0313 loss: 0.0072 prediction_mean: 0.8452 prediction_std: 0.3521 rmse: 0.0831\n",
            "Val   351:  mse: 0.0967 nce_reg: -0.0301 loss: 0.0970 prediction_mean: 0.7852 prediction_std: 0.3647 rmse: 0.3110\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 352:  mse: 0.0083 nce_reg: -0.0314 loss: 0.0086 prediction_mean: 0.8444 prediction_std: 0.3536 rmse: 0.0909\n",
            "Val   352:  mse: 0.0980 nce_reg: -0.0287 loss: 0.0983 prediction_mean: 0.7726 prediction_std: 0.3612 rmse: 0.3131\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 353:  mse: 0.0066 nce_reg: -0.0308 loss: 0.0069 prediction_mean: 0.8443 prediction_std: 0.3525 rmse: 0.0814\n",
            "Val   353:  mse: 0.0934 nce_reg: -0.0295 loss: 0.0937 prediction_mean: 0.8239 prediction_std: 0.3628 rmse: 0.3056\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 354:  mse: 0.0083 nce_reg: -0.0314 loss: 0.0086 prediction_mean: 0.8442 prediction_std: 0.3523 rmse: 0.0910\n",
            "Val   354:  mse: 0.0894 nce_reg: -0.0295 loss: 0.0897 prediction_mean: 0.8115 prediction_std: 0.3426 rmse: 0.2990\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.33it/s]\n",
            "Train 355:  mse: 0.0063 nce_reg: -0.0304 loss: 0.0066 prediction_mean: 0.8452 prediction_std: 0.3530 rmse: 0.0791\n",
            "Val   355:  mse: 0.0975 nce_reg: -0.0289 loss: 0.0978 prediction_mean: 0.7696 prediction_std: 0.3581 rmse: 0.3122\n",
            "100% 167/167 [02:30<00:00,  1.11it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 356:  mse: 0.0062 nce_reg: -0.0299 loss: 0.0065 prediction_mean: 0.8443 prediction_std: 0.3535 rmse: 0.0785\n",
            "Val   356:  mse: 0.0974 nce_reg: -0.0282 loss: 0.0977 prediction_mean: 0.7845 prediction_std: 0.3583 rmse: 0.3121\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 357:  mse: 0.0086 nce_reg: -0.0299 loss: 0.0089 prediction_mean: 0.8446 prediction_std: 0.3546 rmse: 0.0929\n",
            "Val   357:  mse: 0.0972 nce_reg: -0.0293 loss: 0.0975 prediction_mean: 0.7901 prediction_std: 0.3531 rmse: 0.3117\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 358:  mse: 0.0075 nce_reg: -0.0301 loss: 0.0079 prediction_mean: 0.8445 prediction_std: 0.3522 rmse: 0.0869\n",
            "Val   358:  mse: 0.0937 nce_reg: -0.0289 loss: 0.0940 prediction_mean: 0.8133 prediction_std: 0.3653 rmse: 0.3062\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 359:  mse: 0.0064 nce_reg: -0.0301 loss: 0.0067 prediction_mean: 0.8445 prediction_std: 0.3538 rmse: 0.0798\n",
            "Val   359:  mse: 0.0945 nce_reg: -0.0283 loss: 0.0948 prediction_mean: 0.8036 prediction_std: 0.3630 rmse: 0.3074\n",
            "100% 167/167 [02:22<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 360:  mse: 0.0073 nce_reg: -0.0299 loss: 0.0076 prediction_mean: 0.8445 prediction_std: 0.3530 rmse: 0.0853\n",
            "Val   360:  mse: 0.1040 nce_reg: -0.0291 loss: 0.1043 prediction_mean: 0.7501 prediction_std: 0.3627 rmse: 0.3225\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 361:  mse: 0.0064 nce_reg: -0.0299 loss: 0.0067 prediction_mean: 0.8443 prediction_std: 0.3532 rmse: 0.0799\n",
            "Val   361:  mse: 0.0928 nce_reg: -0.0285 loss: 0.0931 prediction_mean: 0.8445 prediction_std: 0.3671 rmse: 0.3047\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 362:  mse: 0.0086 nce_reg: -0.0302 loss: 0.0089 prediction_mean: 0.8442 prediction_std: 0.3529 rmse: 0.0928\n",
            "Val   362:  mse: 0.0933 nce_reg: -0.0290 loss: 0.0936 prediction_mean: 0.8169 prediction_std: 0.3527 rmse: 0.3055\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 363:  mse: 0.0084 nce_reg: -0.0296 loss: 0.0087 prediction_mean: 0.8447 prediction_std: 0.3524 rmse: 0.0916\n",
            "Val   363:  mse: 0.0953 nce_reg: -0.0284 loss: 0.0956 prediction_mean: 0.7941 prediction_std: 0.3652 rmse: 0.3087\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 364:  mse: 0.0070 nce_reg: -0.0294 loss: 0.0073 prediction_mean: 0.8444 prediction_std: 0.3539 rmse: 0.0835\n",
            "Val   364:  mse: 0.0928 nce_reg: -0.0277 loss: 0.0931 prediction_mean: 0.8453 prediction_std: 0.3532 rmse: 0.3047\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 365:  mse: 0.0055 nce_reg: -0.0293 loss: 0.0058 prediction_mean: 0.8450 prediction_std: 0.3525 rmse: 0.0743\n",
            "Val   365:  mse: 0.0952 nce_reg: -0.0284 loss: 0.0954 prediction_mean: 0.8170 prediction_std: 0.3555 rmse: 0.3085\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 366:  mse: 0.0059 nce_reg: -0.0285 loss: 0.0062 prediction_mean: 0.8447 prediction_std: 0.3534 rmse: 0.0770\n",
            "Val   366:  mse: 0.0956 nce_reg: -0.0274 loss: 0.0959 prediction_mean: 0.8159 prediction_std: 0.3584 rmse: 0.3093\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 367:  mse: 0.0063 nce_reg: -0.0286 loss: 0.0066 prediction_mean: 0.8450 prediction_std: 0.3537 rmse: 0.0795\n",
            "Val   367:  mse: 0.1008 nce_reg: -0.0274 loss: 0.1011 prediction_mean: 0.7707 prediction_std: 0.3590 rmse: 0.3176\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 368:  mse: 0.0081 nce_reg: -0.0286 loss: 0.0084 prediction_mean: 0.8443 prediction_std: 0.3531 rmse: 0.0902\n",
            "Val   368:  mse: 0.0920 nce_reg: -0.0274 loss: 0.0923 prediction_mean: 0.8630 prediction_std: 0.3546 rmse: 0.3033\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 369:  mse: 0.0105 nce_reg: -0.0292 loss: 0.0108 prediction_mean: 0.8448 prediction_std: 0.3504 rmse: 0.1024\n",
            "Val   369:  mse: 0.0994 nce_reg: -0.0275 loss: 0.0997 prediction_mean: 0.7694 prediction_std: 0.3591 rmse: 0.3153\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 370:  mse: 0.0090 nce_reg: -0.0294 loss: 0.0093 prediction_mean: 0.8440 prediction_std: 0.3527 rmse: 0.0950\n",
            "Val   370:  mse: 0.0913 nce_reg: -0.0280 loss: 0.0916 prediction_mean: 0.7957 prediction_std: 0.3546 rmse: 0.3022\n",
            "100% 167/167 [02:19<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 371:  mse: 0.0056 nce_reg: -0.0294 loss: 0.0059 prediction_mean: 0.8445 prediction_std: 0.3534 rmse: 0.0747\n",
            "Val   371:  mse: 0.0939 nce_reg: -0.0271 loss: 0.0941 prediction_mean: 0.7950 prediction_std: 0.3516 rmse: 0.3064\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 372:  mse: 0.0064 nce_reg: -0.0289 loss: 0.0066 prediction_mean: 0.8451 prediction_std: 0.3544 rmse: 0.0797\n",
            "Val   372:  mse: 0.0983 nce_reg: -0.0259 loss: 0.0985 prediction_mean: 0.8394 prediction_std: 0.3614 rmse: 0.3135\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 373:  mse: 0.0065 nce_reg: -0.0289 loss: 0.0068 prediction_mean: 0.8436 prediction_std: 0.3523 rmse: 0.0809\n",
            "Val   373:  mse: 0.0981 nce_reg: -0.0273 loss: 0.0984 prediction_mean: 0.8075 prediction_std: 0.3651 rmse: 0.3133\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 374:  mse: 0.0070 nce_reg: -0.0287 loss: 0.0072 prediction_mean: 0.8448 prediction_std: 0.3535 rmse: 0.0834\n",
            "Val   374:  mse: 0.0902 nce_reg: -0.0269 loss: 0.0905 prediction_mean: 0.8441 prediction_std: 0.3522 rmse: 0.3003\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.48it/s]\n",
            "Train 375:  mse: 0.0087 nce_reg: -0.0290 loss: 0.0090 prediction_mean: 0.8443 prediction_std: 0.3533 rmse: 0.0932\n",
            "Val   375:  mse: 0.0942 nce_reg: -0.0278 loss: 0.0945 prediction_mean: 0.8288 prediction_std: 0.3616 rmse: 0.3069\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 376:  mse: 0.0067 nce_reg: -0.0288 loss: 0.0070 prediction_mean: 0.8446 prediction_std: 0.3535 rmse: 0.0819\n",
            "Val   376:  mse: 0.0917 nce_reg: -0.0271 loss: 0.0920 prediction_mean: 0.8366 prediction_std: 0.3573 rmse: 0.3029\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 377:  mse: 0.0081 nce_reg: -0.0286 loss: 0.0084 prediction_mean: 0.8443 prediction_std: 0.3527 rmse: 0.0902\n",
            "Val   377:  mse: 0.0940 nce_reg: -0.0277 loss: 0.0943 prediction_mean: 0.8102 prediction_std: 0.3617 rmse: 0.3066\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 378:  mse: 0.0070 nce_reg: -0.0285 loss: 0.0073 prediction_mean: 0.8443 prediction_std: 0.3524 rmse: 0.0839\n",
            "Val   378:  mse: 0.0947 nce_reg: -0.0276 loss: 0.0950 prediction_mean: 0.7919 prediction_std: 0.3692 rmse: 0.3078\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 379:  mse: 0.0054 nce_reg: -0.0282 loss: 0.0056 prediction_mean: 0.8452 prediction_std: 0.3535 rmse: 0.0733\n",
            "Val   379:  mse: 0.0978 nce_reg: -0.0262 loss: 0.0981 prediction_mean: 0.8004 prediction_std: 0.3700 rmse: 0.3128\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 380:  mse: 0.0063 nce_reg: -0.0279 loss: 0.0066 prediction_mean: 0.8441 prediction_std: 0.3539 rmse: 0.0793\n",
            "Val   380:  mse: 0.0931 nce_reg: -0.0272 loss: 0.0934 prediction_mean: 0.8173 prediction_std: 0.3662 rmse: 0.3051\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 381:  mse: 0.0052 nce_reg: -0.0279 loss: 0.0055 prediction_mean: 0.8448 prediction_std: 0.3547 rmse: 0.0721\n",
            "Val   381:  mse: 0.0933 nce_reg: -0.0264 loss: 0.0936 prediction_mean: 0.8597 prediction_std: 0.3574 rmse: 0.3054\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 382:  mse: 0.0076 nce_reg: -0.0279 loss: 0.0079 prediction_mean: 0.8446 prediction_std: 0.3541 rmse: 0.0871\n",
            "Val   382:  mse: 0.0923 nce_reg: -0.0271 loss: 0.0925 prediction_mean: 0.7881 prediction_std: 0.3534 rmse: 0.3038\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 383:  mse: 0.0075 nce_reg: -0.0284 loss: 0.0078 prediction_mean: 0.8440 prediction_std: 0.3535 rmse: 0.0868\n",
            "Val   383:  mse: 0.0905 nce_reg: -0.0269 loss: 0.0907 prediction_mean: 0.8564 prediction_std: 0.3338 rmse: 0.3008\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.46it/s]\n",
            "Train 384:  mse: 0.0068 nce_reg: -0.0283 loss: 0.0071 prediction_mean: 0.8446 prediction_std: 0.3527 rmse: 0.0826\n",
            "Val   384:  mse: 0.0921 nce_reg: -0.0268 loss: 0.0923 prediction_mean: 0.8296 prediction_std: 0.3578 rmse: 0.3034\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 385:  mse: 0.0059 nce_reg: -0.0278 loss: 0.0062 prediction_mean: 0.8444 prediction_std: 0.3541 rmse: 0.0768\n",
            "Val   385:  mse: 0.0956 nce_reg: -0.0264 loss: 0.0959 prediction_mean: 0.8177 prediction_std: 0.3599 rmse: 0.3092\n",
            "100% 167/167 [02:22<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 386:  mse: 0.0085 nce_reg: -0.0279 loss: 0.0088 prediction_mean: 0.8447 prediction_std: 0.3531 rmse: 0.0922\n",
            "Val   386:  mse: 0.0925 nce_reg: -0.0261 loss: 0.0927 prediction_mean: 0.8228 prediction_std: 0.3578 rmse: 0.3041\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 387:  mse: 0.0077 nce_reg: -0.0279 loss: 0.0080 prediction_mean: 0.8440 prediction_std: 0.3531 rmse: 0.0878\n",
            "Val   387:  mse: 0.0991 nce_reg: -0.0273 loss: 0.0993 prediction_mean: 0.7786 prediction_std: 0.3563 rmse: 0.3148\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.51it/s]\n",
            "Train 388:  mse: 0.0078 nce_reg: -0.0278 loss: 0.0081 prediction_mean: 0.8444 prediction_std: 0.3519 rmse: 0.0883\n",
            "Val   388:  mse: 0.0965 nce_reg: -0.0265 loss: 0.0968 prediction_mean: 0.8109 prediction_std: 0.3654 rmse: 0.3107\n",
            "100% 167/167 [02:19<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 389:  mse: 0.0080 nce_reg: -0.0282 loss: 0.0083 prediction_mean: 0.8445 prediction_std: 0.3543 rmse: 0.0897\n",
            "Val   389:  mse: 0.0958 nce_reg: -0.0257 loss: 0.0961 prediction_mean: 0.8217 prediction_std: 0.3663 rmse: 0.3095\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 390:  mse: 0.0061 nce_reg: -0.0278 loss: 0.0064 prediction_mean: 0.8446 prediction_std: 0.3522 rmse: 0.0781\n",
            "Val   390:  mse: 0.0943 nce_reg: -0.0263 loss: 0.0945 prediction_mean: 0.7951 prediction_std: 0.3476 rmse: 0.3070\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 391:  mse: 0.0056 nce_reg: -0.0274 loss: 0.0059 prediction_mean: 0.8444 prediction_std: 0.3539 rmse: 0.0750\n",
            "Val   391:  mse: 0.0920 nce_reg: -0.0263 loss: 0.0922 prediction_mean: 0.8464 prediction_std: 0.3595 rmse: 0.3033\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 392:  mse: 0.0063 nce_reg: -0.0273 loss: 0.0066 prediction_mean: 0.8447 prediction_std: 0.3549 rmse: 0.0797\n",
            "Val   392:  mse: 0.0898 nce_reg: -0.0268 loss: 0.0901 prediction_mean: 0.8412 prediction_std: 0.3445 rmse: 0.2997\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 393:  mse: 0.0062 nce_reg: -0.0269 loss: 0.0065 prediction_mean: 0.8443 prediction_std: 0.3537 rmse: 0.0789\n",
            "Val   393:  mse: 0.0946 nce_reg: -0.0263 loss: 0.0949 prediction_mean: 0.8872 prediction_std: 0.3652 rmse: 0.3076\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 394:  mse: 0.0072 nce_reg: -0.0272 loss: 0.0074 prediction_mean: 0.8441 prediction_std: 0.3521 rmse: 0.0847\n",
            "Val   394:  mse: 0.0971 nce_reg: -0.0261 loss: 0.0973 prediction_mean: 0.8090 prediction_std: 0.3608 rmse: 0.3116\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 395:  mse: 0.0069 nce_reg: -0.0268 loss: 0.0072 prediction_mean: 0.8444 prediction_std: 0.3546 rmse: 0.0830\n",
            "Val   395:  mse: 0.0966 nce_reg: -0.0252 loss: 0.0968 prediction_mean: 0.8369 prediction_std: 0.3562 rmse: 0.3108\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 396:  mse: 0.0058 nce_reg: -0.0267 loss: 0.0060 prediction_mean: 0.8449 prediction_std: 0.3529 rmse: 0.0759\n",
            "Val   396:  mse: 0.0967 nce_reg: -0.0255 loss: 0.0969 prediction_mean: 0.8035 prediction_std: 0.3559 rmse: 0.3109\n",
            "100% 167/167 [02:19<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 397:  mse: 0.0061 nce_reg: -0.0267 loss: 0.0063 prediction_mean: 0.8443 prediction_std: 0.3554 rmse: 0.0778\n",
            "Val   397:  mse: 0.0957 nce_reg: -0.0249 loss: 0.0959 prediction_mean: 0.7893 prediction_std: 0.3562 rmse: 0.3093\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 398:  mse: 0.0065 nce_reg: -0.0266 loss: 0.0067 prediction_mean: 0.8447 prediction_std: 0.3534 rmse: 0.0805\n",
            "Val   398:  mse: 0.0960 nce_reg: -0.0253 loss: 0.0962 prediction_mean: 0.8085 prediction_std: 0.3634 rmse: 0.3098\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 399:  mse: 0.0061 nce_reg: -0.0263 loss: 0.0064 prediction_mean: 0.8445 prediction_std: 0.3550 rmse: 0.0783\n",
            "Val   399:  mse: 0.0956 nce_reg: -0.0251 loss: 0.0959 prediction_mean: 0.8169 prediction_std: 0.3404 rmse: 0.3092\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 400:  mse: 0.0076 nce_reg: -0.0264 loss: 0.0079 prediction_mean: 0.8444 prediction_std: 0.3522 rmse: 0.0873\n",
            "Val   400:  mse: 0.0921 nce_reg: -0.0260 loss: 0.0924 prediction_mean: 0.8693 prediction_std: 0.3639 rmse: 0.3035\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 401:  mse: 0.0083 nce_reg: -0.0265 loss: 0.0086 prediction_mean: 0.8450 prediction_std: 0.3541 rmse: 0.0911\n",
            "Val   401:  mse: 0.0927 nce_reg: -0.0251 loss: 0.0929 prediction_mean: 0.8770 prediction_std: 0.3299 rmse: 0.3044\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 402:  mse: 0.0062 nce_reg: -0.0266 loss: 0.0065 prediction_mean: 0.8445 prediction_std: 0.3524 rmse: 0.0790\n",
            "Val   402:  mse: 0.0967 nce_reg: -0.0248 loss: 0.0969 prediction_mean: 0.8216 prediction_std: 0.3689 rmse: 0.3109\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 403:  mse: 0.0068 nce_reg: -0.0264 loss: 0.0070 prediction_mean: 0.8448 prediction_std: 0.3550 rmse: 0.0822\n",
            "Val   403:  mse: 0.0988 nce_reg: -0.0250 loss: 0.0990 prediction_mean: 0.7782 prediction_std: 0.3640 rmse: 0.3143\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 404:  mse: 0.0069 nce_reg: -0.0265 loss: 0.0072 prediction_mean: 0.8449 prediction_std: 0.3520 rmse: 0.0833\n",
            "Val   404:  mse: 0.0951 nce_reg: -0.0252 loss: 0.0954 prediction_mean: 0.8514 prediction_std: 0.3553 rmse: 0.3084\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 405:  mse: 0.0057 nce_reg: -0.0261 loss: 0.0060 prediction_mean: 0.8443 prediction_std: 0.3539 rmse: 0.0757\n",
            "Val   405:  mse: 0.0951 nce_reg: -0.0249 loss: 0.0954 prediction_mean: 0.8246 prediction_std: 0.3487 rmse: 0.3084\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 406:  mse: 0.0060 nce_reg: -0.0261 loss: 0.0063 prediction_mean: 0.8447 prediction_std: 0.3540 rmse: 0.0778\n",
            "Val   406:  mse: 0.0981 nce_reg: -0.0245 loss: 0.0983 prediction_mean: 0.8124 prediction_std: 0.3687 rmse: 0.3132\n",
            "100% 167/167 [02:27<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 407:  mse: 0.0055 nce_reg: -0.0257 loss: 0.0058 prediction_mean: 0.8444 prediction_std: 0.3540 rmse: 0.0744\n",
            "Val   407:  mse: 0.0953 nce_reg: -0.0253 loss: 0.0956 prediction_mean: 0.8110 prediction_std: 0.3539 rmse: 0.3087\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 408:  mse: 0.0069 nce_reg: -0.0257 loss: 0.0071 prediction_mean: 0.8447 prediction_std: 0.3544 rmse: 0.0829\n",
            "Val   408:  mse: 0.0931 nce_reg: -0.0244 loss: 0.0933 prediction_mean: 0.8423 prediction_std: 0.3576 rmse: 0.3051\n",
            "100% 167/167 [02:25<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 409:  mse: 0.0065 nce_reg: -0.0254 loss: 0.0068 prediction_mean: 0.8442 prediction_std: 0.3537 rmse: 0.0807\n",
            "Val   409:  mse: 0.0909 nce_reg: -0.0247 loss: 0.0911 prediction_mean: 0.8408 prediction_std: 0.3477 rmse: 0.3015\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 410:  mse: 0.0087 nce_reg: -0.0259 loss: 0.0089 prediction_mean: 0.8441 prediction_std: 0.3539 rmse: 0.0932\n",
            "Val   410:  mse: 0.0922 nce_reg: -0.0247 loss: 0.0925 prediction_mean: 0.8210 prediction_std: 0.3545 rmse: 0.3037\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.40it/s]\n",
            "Train 411:  mse: 0.0064 nce_reg: -0.0256 loss: 0.0067 prediction_mean: 0.8444 prediction_std: 0.3528 rmse: 0.0802\n",
            "Val   411:  mse: 0.0988 nce_reg: -0.0240 loss: 0.0990 prediction_mean: 0.8216 prediction_std: 0.3710 rmse: 0.3143\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 412:  mse: 0.0055 nce_reg: -0.0254 loss: 0.0057 prediction_mean: 0.8444 prediction_std: 0.3541 rmse: 0.0740\n",
            "Val   412:  mse: 0.0936 nce_reg: -0.0240 loss: 0.0938 prediction_mean: 0.8168 prediction_std: 0.3564 rmse: 0.3059\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.36it/s]\n",
            "Train 413:  mse: 0.0051 nce_reg: -0.0250 loss: 0.0053 prediction_mean: 0.8447 prediction_std: 0.3539 rmse: 0.0713\n",
            "Val   413:  mse: 0.0949 nce_reg: -0.0239 loss: 0.0951 prediction_mean: 0.8130 prediction_std: 0.3642 rmse: 0.3081\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 414:  mse: 0.0058 nce_reg: -0.0252 loss: 0.0060 prediction_mean: 0.8445 prediction_std: 0.3550 rmse: 0.0760\n",
            "Val   414:  mse: 0.0957 nce_reg: -0.0235 loss: 0.0960 prediction_mean: 0.8023 prediction_std: 0.3588 rmse: 0.3094\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 415:  mse: 0.0061 nce_reg: -0.0251 loss: 0.0064 prediction_mean: 0.8444 prediction_std: 0.3541 rmse: 0.0783\n",
            "Val   415:  mse: 0.1011 nce_reg: -0.0236 loss: 0.1013 prediction_mean: 0.7757 prediction_std: 0.3640 rmse: 0.3180\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 416:  mse: 0.0083 nce_reg: -0.0251 loss: 0.0086 prediction_mean: 0.8443 prediction_std: 0.3537 rmse: 0.0911\n",
            "Val   416:  mse: 0.0944 nce_reg: -0.0226 loss: 0.0946 prediction_mean: 0.7778 prediction_std: 0.3452 rmse: 0.3072\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 417:  mse: 0.0076 nce_reg: -0.0251 loss: 0.0078 prediction_mean: 0.8442 prediction_std: 0.3522 rmse: 0.0870\n",
            "Val   417:  mse: 0.0969 nce_reg: -0.0242 loss: 0.0971 prediction_mean: 0.8175 prediction_std: 0.3508 rmse: 0.3112\n",
            "100% 167/167 [02:20<00:00,  1.19it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 418:  mse: 0.0070 nce_reg: -0.0251 loss: 0.0072 prediction_mean: 0.8445 prediction_std: 0.3545 rmse: 0.0834\n",
            "Val   418:  mse: 0.0945 nce_reg: -0.0245 loss: 0.0947 prediction_mean: 0.8428 prediction_std: 0.3591 rmse: 0.3074\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 419:  mse: 0.0062 nce_reg: -0.0256 loss: 0.0065 prediction_mean: 0.8450 prediction_std: 0.3528 rmse: 0.0788\n",
            "Val   419:  mse: 0.0938 nce_reg: -0.0239 loss: 0.0940 prediction_mean: 0.8407 prediction_std: 0.3589 rmse: 0.3062\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 420:  mse: 0.0049 nce_reg: -0.0247 loss: 0.0051 prediction_mean: 0.8444 prediction_std: 0.3542 rmse: 0.0699\n",
            "Val   420:  mse: 0.1033 nce_reg: -0.0229 loss: 0.1035 prediction_mean: 0.7689 prediction_std: 0.3538 rmse: 0.3213\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.37it/s]\n",
            "Train 421:  mse: 0.0062 nce_reg: -0.0245 loss: 0.0065 prediction_mean: 0.8443 prediction_std: 0.3548 rmse: 0.0788\n",
            "Val   421:  mse: 0.0938 nce_reg: -0.0230 loss: 0.0940 prediction_mean: 0.8849 prediction_std: 0.3499 rmse: 0.3062\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 422:  mse: 0.0055 nce_reg: -0.0245 loss: 0.0057 prediction_mean: 0.8442 prediction_std: 0.3543 rmse: 0.0739\n",
            "Val   422:  mse: 0.0983 nce_reg: -0.0227 loss: 0.0985 prediction_mean: 0.8127 prediction_std: 0.3613 rmse: 0.3135\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 423:  mse: 0.0054 nce_reg: -0.0244 loss: 0.0057 prediction_mean: 0.8444 prediction_std: 0.3544 rmse: 0.0735\n",
            "Val   423:  mse: 0.0971 nce_reg: -0.0223 loss: 0.0973 prediction_mean: 0.8717 prediction_std: 0.3531 rmse: 0.3115\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 424:  mse: 0.0066 nce_reg: -0.0245 loss: 0.0069 prediction_mean: 0.8443 prediction_std: 0.3542 rmse: 0.0813\n",
            "Val   424:  mse: 0.0958 nce_reg: -0.0230 loss: 0.0960 prediction_mean: 0.8235 prediction_std: 0.3632 rmse: 0.3094\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 425:  mse: 0.0066 nce_reg: -0.0242 loss: 0.0069 prediction_mean: 0.8442 prediction_std: 0.3539 rmse: 0.0814\n",
            "Val   425:  mse: 0.0971 nce_reg: -0.0232 loss: 0.0973 prediction_mean: 0.8072 prediction_std: 0.3618 rmse: 0.3116\n",
            "100% 167/167 [02:23<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 426:  mse: 0.0072 nce_reg: -0.0243 loss: 0.0075 prediction_mean: 0.8447 prediction_std: 0.3540 rmse: 0.0849\n",
            "Val   426:  mse: 0.0977 nce_reg: -0.0226 loss: 0.0979 prediction_mean: 0.8170 prediction_std: 0.3637 rmse: 0.3126\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 427:  mse: 0.0057 nce_reg: -0.0241 loss: 0.0060 prediction_mean: 0.8440 prediction_std: 0.3542 rmse: 0.0758\n",
            "Val   427:  mse: 0.0945 nce_reg: -0.0228 loss: 0.0947 prediction_mean: 0.8200 prediction_std: 0.3551 rmse: 0.3074\n",
            "100% 167/167 [02:28<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 428:  mse: 0.0055 nce_reg: -0.0241 loss: 0.0058 prediction_mean: 0.8453 prediction_std: 0.3547 rmse: 0.0743\n",
            "Val   428:  mse: 0.0926 nce_reg: -0.0226 loss: 0.0929 prediction_mean: 0.8309 prediction_std: 0.3495 rmse: 0.3044\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.38it/s]\n",
            "Train 429:  mse: 0.0059 nce_reg: -0.0238 loss: 0.0062 prediction_mean: 0.8443 prediction_std: 0.3544 rmse: 0.0769\n",
            "Val   429:  mse: 0.0976 nce_reg: -0.0226 loss: 0.0979 prediction_mean: 0.8122 prediction_std: 0.3494 rmse: 0.3125\n",
            "100% 167/167 [02:29<00:00,  1.12it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 430:  mse: 0.0069 nce_reg: -0.0240 loss: 0.0072 prediction_mean: 0.8451 prediction_std: 0.3542 rmse: 0.0832\n",
            "Val   430:  mse: 0.0937 nce_reg: -0.0230 loss: 0.0939 prediction_mean: 0.7835 prediction_std: 0.3482 rmse: 0.3061\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 431:  mse: 0.0077 nce_reg: -0.0242 loss: 0.0079 prediction_mean: 0.8435 prediction_std: 0.3527 rmse: 0.0876\n",
            "Val   431:  mse: 0.1006 nce_reg: -0.0230 loss: 0.1008 prediction_mean: 0.8919 prediction_std: 0.3685 rmse: 0.3172\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 432:  mse: 0.0064 nce_reg: -0.0241 loss: 0.0066 prediction_mean: 0.8442 prediction_std: 0.3538 rmse: 0.0799\n",
            "Val   432:  mse: 0.0928 nce_reg: -0.0231 loss: 0.0930 prediction_mean: 0.8555 prediction_std: 0.3412 rmse: 0.3047\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.44it/s]\n",
            "Train 433:  mse: 0.0058 nce_reg: -0.0240 loss: 0.0060 prediction_mean: 0.8453 prediction_std: 0.3543 rmse: 0.0761\n",
            "Val   433:  mse: 0.0971 nce_reg: -0.0220 loss: 0.0973 prediction_mean: 0.7799 prediction_std: 0.3415 rmse: 0.3116\n",
            "100% 167/167 [02:27<00:00,  1.13it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 434:  mse: 0.0060 nce_reg: -0.0238 loss: 0.0063 prediction_mean: 0.8446 prediction_std: 0.3539 rmse: 0.0777\n",
            "Val   434:  mse: 0.0958 nce_reg: -0.0219 loss: 0.0960 prediction_mean: 0.7969 prediction_std: 0.3545 rmse: 0.3095\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 435:  mse: 0.0047 nce_reg: -0.0232 loss: 0.0050 prediction_mean: 0.8438 prediction_std: 0.3551 rmse: 0.0687\n",
            "Val   435:  mse: 0.0937 nce_reg: -0.0224 loss: 0.0939 prediction_mean: 0.8632 prediction_std: 0.3654 rmse: 0.3061\n",
            "100% 167/167 [02:24<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 436:  mse: 0.0057 nce_reg: -0.0231 loss: 0.0059 prediction_mean: 0.8451 prediction_std: 0.3546 rmse: 0.0755\n",
            "Val   436:  mse: 0.0924 nce_reg: -0.0219 loss: 0.0926 prediction_mean: 0.8321 prediction_std: 0.3670 rmse: 0.3040\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 437:  mse: 0.0089 nce_reg: -0.0231 loss: 0.0091 prediction_mean: 0.8438 prediction_std: 0.3532 rmse: 0.0944\n",
            "Val   437:  mse: 0.0965 nce_reg: -0.0229 loss: 0.0967 prediction_mean: 0.8398 prediction_std: 0.3637 rmse: 0.3106\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 438:  mse: 0.0065 nce_reg: -0.0238 loss: 0.0067 prediction_mean: 0.8449 prediction_std: 0.3529 rmse: 0.0804\n",
            "Val   438:  mse: 0.0933 nce_reg: -0.0211 loss: 0.0936 prediction_mean: 0.8255 prediction_std: 0.3481 rmse: 0.3055\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.42it/s]\n",
            "Train 439:  mse: 0.0064 nce_reg: -0.0231 loss: 0.0066 prediction_mean: 0.8446 prediction_std: 0.3538 rmse: 0.0801\n",
            "Val   439:  mse: 0.0984 nce_reg: -0.0207 loss: 0.0986 prediction_mean: 0.7984 prediction_std: 0.3574 rmse: 0.3136\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 440:  mse: 0.0054 nce_reg: -0.0231 loss: 0.0056 prediction_mean: 0.8445 prediction_std: 0.3534 rmse: 0.0733\n",
            "Val   440:  mse: 0.0953 nce_reg: -0.0210 loss: 0.0955 prediction_mean: 0.8414 prediction_std: 0.3562 rmse: 0.3087\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.47it/s]\n",
            "Train 441:  mse: 0.0050 nce_reg: -0.0227 loss: 0.0053 prediction_mean: 0.8442 prediction_std: 0.3544 rmse: 0.0710\n",
            "Val   441:  mse: 0.0998 nce_reg: -0.0208 loss: 0.1000 prediction_mean: 0.8170 prediction_std: 0.3729 rmse: 0.3158\n",
            "100% 167/167 [02:18<00:00,  1.20it/s]\n",
            "100% 14/14 [00:09<00:00,  1.43it/s]\n",
            "Train 442:  mse: 0.0073 nce_reg: -0.0229 loss: 0.0075 prediction_mean: 0.8451 prediction_std: 0.3541 rmse: 0.0855\n",
            "Val   442:  mse: 0.0965 nce_reg: -0.0218 loss: 0.0967 prediction_mean: 0.8127 prediction_std: 0.3515 rmse: 0.3106\n",
            "100% 167/167 [02:22<00:00,  1.17it/s]\n",
            "100% 14/14 [00:09<00:00,  1.50it/s]\n",
            "Train 443:  mse: 0.0076 nce_reg: -0.0231 loss: 0.0078 prediction_mean: 0.8443 prediction_std: 0.3537 rmse: 0.0870\n",
            "Val   443:  mse: 0.0963 nce_reg: -0.0221 loss: 0.0965 prediction_mean: 0.8044 prediction_std: 0.3566 rmse: 0.3103\n",
            "100% 167/167 [02:21<00:00,  1.18it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 444:  mse: 0.0065 nce_reg: -0.0230 loss: 0.0067 prediction_mean: 0.8445 prediction_std: 0.3538 rmse: 0.0807\n",
            "Val   444:  mse: 0.1050 nce_reg: -0.0214 loss: 0.1052 prediction_mean: 0.7543 prediction_std: 0.3653 rmse: 0.3240\n",
            "100% 167/167 [02:24<00:00,  1.16it/s]\n",
            "100% 14/14 [00:10<00:00,  1.40it/s]\n",
            "Train 445:  mse: 0.0067 nce_reg: -0.0230 loss: 0.0070 prediction_mean: 0.8447 prediction_std: 0.3541 rmse: 0.0821\n",
            "Val   445:  mse: 0.0962 nce_reg: -0.0213 loss: 0.0964 prediction_mean: 0.8131 prediction_std: 0.3491 rmse: 0.3102\n",
            "100% 167/167 [02:23<00:00,  1.16it/s]\n",
            "100% 14/14 [00:09<00:00,  1.45it/s]\n",
            "Train 446:  mse: 0.0116 nce_reg: -0.0238 loss: 0.0118 prediction_mean: 0.8435 prediction_std: 0.3531 rmse: 0.1075\n",
            "Val   446:  mse: 0.1010 nce_reg: -0.0225 loss: 0.1012 prediction_mean: 0.7612 prediction_std: 0.3549 rmse: 0.3177\n",
            "100% 167/167 [02:26<00:00,  1.14it/s]\n",
            "100% 14/14 [00:10<00:00,  1.35it/s]\n",
            "Train 447:  mse: 0.0070 nce_reg: -0.0235 loss: 0.0073 prediction_mean: 0.8438 prediction_std: 0.3537 rmse: 0.0838\n",
            "Val   447:  mse: 0.0964 nce_reg: -0.0215 loss: 0.0966 prediction_mean: 0.9048 prediction_std: 0.3498 rmse: 0.3105\n",
            "100% 167/167 [02:28<00:00,  1.12it/s]\n",
            "100% 14/14 [00:10<00:00,  1.39it/s]\n",
            "Train 448:  mse: 0.0054 nce_reg: -0.0235 loss: 0.0057 prediction_mean: 0.8452 prediction_std: 0.3533 rmse: 0.0737\n",
            "Val   448:  mse: 0.1025 nce_reg: -0.0221 loss: 0.1027 prediction_mean: 0.7587 prediction_std: 0.3704 rmse: 0.3201\n",
            "100% 167/167 [02:25<00:00,  1.15it/s]\n",
            "100% 14/14 [00:09<00:00,  1.41it/s]\n",
            "Train 449:  mse: 0.0048 nce_reg: -0.0229 loss: 0.0051 prediction_mean: 0.8440 prediction_std: 0.3551 rmse: 0.0696\n",
            "Val   449:  mse: 0.0923 nce_reg: -0.0215 loss: 0.0926 prediction_mean: 0.8255 prediction_std: 0.3554 rmse: 0.3039\n",
            "Loading model from output/test/run_0/models/model_138\n",
            "Model saved to: output/test/run_0/models/model_best\n",
            "100% 23/23 [00:16<00:00,  1.35it/s]\n",
            "Test:  mse: 0.0924 nce_reg: -0.0956 loss: 0.0934 prediction_mean: 0.8909 prediction_std: 0.3384 rmse: 0.3040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kmBJwcn4r_Z"
      },
      "source": [
        "!cp /content/OTGNN/output/test/run_0/models/model_best /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZGgqjv8uC0s"
      },
      "source": [
        "!mv /content/drive/MyDrive/model_best /content/drive/MyDrive/model_best_210903"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9Z680oFTxyK"
      },
      "source": [
        "#Load model dict and start excutable conda(skip)\n",
        "\n",
        "*   위에 언급했듯 conda의 environment가 colab의 environ과 다르므로 이를 극복하기 위해 !conda run(experimental이므로 오류가 있을 수 있음)를 통해 버전 맞춰주기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u38398ziX4GY"
      },
      "source": [
        "cd content/OTGNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl2uzK8eTBez",
        "outputId": "517f4093-8493-4ef5-927a-198ffd0739cf"
      },
      "source": [
        "!pip uninstall POT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: POT 0.8.0.dev0\n",
            "Uninstalling POT-0.8.0.dev0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/site-packages/POT-0.8.0.dev0.dist-info/*\n",
            "    /usr/local/lib/python3.6/site-packages/ot/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled POT-0.8.0.dev0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaYvgdxfYogV"
      },
      "source": [
        "\n",
        "\n",
        "*   POT colab버전과 충돌하여 버전 매치가 되지 않으므로 pip uninstall하고 conda run을 다시 실행\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE1S1LFlYTec",
        "outputId": "0c3e1776-bf96-48fa-e49f-2f41d9a9787b"
      },
      "source": [
        "!conda install -c conda-forge pot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ReV-z4TbBm"
      },
      "source": [
        "!conda run"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb9azMZUS37M"
      },
      "source": [
        "import ot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TlKhswXQ6mk"
      },
      "source": [
        "from OTGNN.utils.model_utils import load_model\n",
        "from OTGNN.models.proto_net import ProtoNet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeFvDmsVRH1S"
      },
      "source": [
        "model, args = load_model(model_class = ProtoNet, path='/content/OTGNN/output/test/run_0/models/model_best',device=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUm1hHxLTsSZ"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15HoYopLVKif"
      },
      "source": [
        "#Preprocessing Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0jG1yrQUI_J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "08abb061-aff0-4471-b419-b83106146c0c"
      },
      "source": [
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>SMILES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>test_597</td>\n",
              "      <td>N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>test_598</td>\n",
              "      <td>CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>test_599</td>\n",
              "      <td>Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>test_600</td>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>test_601</td>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>602 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          uid                                             SMILES\n",
              "0      test_0       COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C\n",
              "1      test_1  CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...\n",
              "2      test_2  C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...\n",
              "3      test_3  CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...\n",
              "4      test_4  CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...\n",
              "..        ...                                                ...\n",
              "597  test_597  N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...\n",
              "598  test_598  CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...\n",
              "599  test_599  Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...\n",
              "600  test_600     c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1\n",
              "601  test_601  c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...\n",
              "\n",
              "[602 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxLkz2ISVhB_"
      },
      "source": [
        "df_test = test_data.reset_index().drop(['uid','index'],axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtBw7voqViFT"
      },
      "source": [
        "df_test['s1_t1_gap'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Og3vMlV_1MV1",
        "outputId": "beadd288-e9fa-4fd2-8665-d5f6e756989d"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>s1_t1_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>602 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                SMILES  s1_t1_gap\n",
              "0         COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C          0\n",
              "1    CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...          0\n",
              "2    C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...          0\n",
              "3    CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...          0\n",
              "4    CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...          0\n",
              "..                                                 ...        ...\n",
              "597  N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...          0\n",
              "598  CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...          0\n",
              "599  Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...          0\n",
              "600     c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1          0\n",
              "601  c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...          0\n",
              "\n",
              "[602 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNcs87s1Zq07"
      },
      "source": [
        "!cp -r /content/OTGNN/data/lipo /content/OTGNN/data/ST_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db_Dfa74WRhz"
      },
      "source": [
        "!rm /content/OTGNN/data/ST_test/split_0.json /content/OTGNN/data/ST_test/split_1.json /content/OTGNN/data/ST_test/split_2.json /content/OTGNN/data/ST_test/split_3.json /content/OTGNN/data/ST_test/split_4.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHo987aLV35M"
      },
      "source": [
        "df_test.to_csv('/content/OTGNN/data/ST_test/raw.csv', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY5R8RBVJErj"
      },
      "source": [
        "infer = pd.read_csv('/content/OTGNN/data/ST_test/raw.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "wgU3cT5x1V2r",
        "outputId": "160fc569-2c73-4f4f-9b18-f724b2c76987"
      },
      "source": [
        "infer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CCN(CC(=O)O)C1CC(NC(=O)N2CC(C)(C)OC3(CCCC3)C2)C1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>601 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C  0\n",
              "0    CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)...  0\n",
              "1    C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(...  0\n",
              "2    CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3cc...  0\n",
              "3    CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cn...  0\n",
              "4     CCN(CC(=O)O)C1CC(NC(=O)N2CC(C)(C)OC3(CCCC3)C2)C1  0\n",
              "..                                                 ... ..\n",
              "596  N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccc...  0\n",
              "597  CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C...  0\n",
              "598  Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc...  0\n",
              "599     c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1  0\n",
              "600  c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc...  0\n",
              "\n",
              "[601 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYaGi2HoJUJI"
      },
      "source": [
        "spltest = split_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiNb7gq6I8KG"
      },
      "source": [
        "a = infer.index.to_list()\n",
        "a.append(len(a))\n",
        "spltest['test'] = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maIRshst1d1a",
        "outputId": "4f5015e2-32f9-4449-9e13-91e4d3ed23f4"
      },
      "source": [
        "spltest['test']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365,\n",
              " 366,\n",
              " 367,\n",
              " 368,\n",
              " 369,\n",
              " 370,\n",
              " 371,\n",
              " 372,\n",
              " 373,\n",
              " 374,\n",
              " 375,\n",
              " 376,\n",
              " 377,\n",
              " 378,\n",
              " 379,\n",
              " 380,\n",
              " 381,\n",
              " 382,\n",
              " 383,\n",
              " 384,\n",
              " 385,\n",
              " 386,\n",
              " 387,\n",
              " 388,\n",
              " 389,\n",
              " 390,\n",
              " 391,\n",
              " 392,\n",
              " 393,\n",
              " 394,\n",
              " 395,\n",
              " 396,\n",
              " 397,\n",
              " 398,\n",
              " 399,\n",
              " 400,\n",
              " 401,\n",
              " 402,\n",
              " 403,\n",
              " 404,\n",
              " 405,\n",
              " 406,\n",
              " 407,\n",
              " 408,\n",
              " 409,\n",
              " 410,\n",
              " 411,\n",
              " 412,\n",
              " 413,\n",
              " 414,\n",
              " 415,\n",
              " 416,\n",
              " 417,\n",
              " 418,\n",
              " 419,\n",
              " 420,\n",
              " 421,\n",
              " 422,\n",
              " 423,\n",
              " 424,\n",
              " 425,\n",
              " 426,\n",
              " 427,\n",
              " 428,\n",
              " 429,\n",
              " 430,\n",
              " 431,\n",
              " 432,\n",
              " 433,\n",
              " 434,\n",
              " 435,\n",
              " 436,\n",
              " 437,\n",
              " 438,\n",
              " 439,\n",
              " 440,\n",
              " 441,\n",
              " 442,\n",
              " 443,\n",
              " 444,\n",
              " 445,\n",
              " 446,\n",
              " 447,\n",
              " 448,\n",
              " 449,\n",
              " 450,\n",
              " 451,\n",
              " 452,\n",
              " 453,\n",
              " 454,\n",
              " 455,\n",
              " 456,\n",
              " 457,\n",
              " 458,\n",
              " 459,\n",
              " 460,\n",
              " 461,\n",
              " 462,\n",
              " 463,\n",
              " 464,\n",
              " 465,\n",
              " 466,\n",
              " 467,\n",
              " 468,\n",
              " 469,\n",
              " 470,\n",
              " 471,\n",
              " 472,\n",
              " 473,\n",
              " 474,\n",
              " 475,\n",
              " 476,\n",
              " 477,\n",
              " 478,\n",
              " 479,\n",
              " 480,\n",
              " 481,\n",
              " 482,\n",
              " 483,\n",
              " 484,\n",
              " 485,\n",
              " 486,\n",
              " 487,\n",
              " 488,\n",
              " 489,\n",
              " 490,\n",
              " 491,\n",
              " 492,\n",
              " 493,\n",
              " 494,\n",
              " 495,\n",
              " 496,\n",
              " 497,\n",
              " 498,\n",
              " 499,\n",
              " 500,\n",
              " 501,\n",
              " 502,\n",
              " 503,\n",
              " 504,\n",
              " 505,\n",
              " 506,\n",
              " 507,\n",
              " 508,\n",
              " 509,\n",
              " 510,\n",
              " 511,\n",
              " 512,\n",
              " 513,\n",
              " 514,\n",
              " 515,\n",
              " 516,\n",
              " 517,\n",
              " 518,\n",
              " 519,\n",
              " 520,\n",
              " 521,\n",
              " 522,\n",
              " 523,\n",
              " 524,\n",
              " 525,\n",
              " 526,\n",
              " 527,\n",
              " 528,\n",
              " 529,\n",
              " 530,\n",
              " 531,\n",
              " 532,\n",
              " 533,\n",
              " 534,\n",
              " 535,\n",
              " 536,\n",
              " 537,\n",
              " 538,\n",
              " 539,\n",
              " 540,\n",
              " 541,\n",
              " 542,\n",
              " 543,\n",
              " 544,\n",
              " 545,\n",
              " 546,\n",
              " 547,\n",
              " 548,\n",
              " 549,\n",
              " 550,\n",
              " 551,\n",
              " 552,\n",
              " 553,\n",
              " 554,\n",
              " 555,\n",
              " 556,\n",
              " 557,\n",
              " 558,\n",
              " 559,\n",
              " 560,\n",
              " 561,\n",
              " 562,\n",
              " 563,\n",
              " 564,\n",
              " 565,\n",
              " 566,\n",
              " 567,\n",
              " 568,\n",
              " 569,\n",
              " 570,\n",
              " 571,\n",
              " 572,\n",
              " 573,\n",
              " 574,\n",
              " 575,\n",
              " 576,\n",
              " 577,\n",
              " 578,\n",
              " 579,\n",
              " 580,\n",
              " 581,\n",
              " 582,\n",
              " 583,\n",
              " 584,\n",
              " 585,\n",
              " 586,\n",
              " 587,\n",
              " 588,\n",
              " 589,\n",
              " 590,\n",
              " 591,\n",
              " 592,\n",
              " 593,\n",
              " 594,\n",
              " 595,\n",
              " 596,\n",
              " 597,\n",
              " 598,\n",
              " 599,\n",
              " 600,\n",
              " 601]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30To6HizJjhi"
      },
      "source": [
        "with open(\"/content/OTGNN/data/ST_test/split_4.json\", \"w\") as st_json:\n",
        "\n",
        "    json.dump(spltest,st_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKit6360yZRT"
      },
      "source": [
        "!mv /content/OTGNN/data/lipo /content/OTGNN/data/lipo_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9wRhaAeygUd"
      },
      "source": [
        "!mv /content/OTGNN/data/ST_test /content/OTGNN/data/lipo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-fsn0MloLTx"
      },
      "source": [
        "!mv /content/OTGNN/data/lipo/split_4.json /content/OTGNN/data/lipo/split_0.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeCQ5GdHyGsn",
        "outputId": "85ef61eb-688b-48e0-dec3-d48b24b0cea1"
      },
      "source": [
        "!python train_proto.py -data lipo -output_dir output/test -lr 5e-4 \\\n",
        "  -n_epochs 300 -n_hidden 60 -n_ffn_hidden 110 -batch_size 32 -n_pc 10 \\\n",
        "  -pc_size 10 -pc_hidden 10 -distance_metric wasserstein -separate_lr \\\n",
        "  -lr_pc 5e-3 -opt_method emd -mult_num_atoms -nce_coef 0.01 -pretrain_model '/content/drive/MyDrive/model_best'\n",
        "  #n_hidden=50,n_ffn_hidden=100,batch_size=16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from: /content/drive/MyDrive/model_best\n",
            "  0% 0/19 [00:00<?, ?it/s]/content/OTGNN/models/ot_modules.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  nce_reg = torch.nn.LogSoftmax()(torch.stack(all_nce_dists))[0]\n",
            "100% 19/19 [00:09<00:00,  1.94it/s]\n",
            "Test:  mse: 0.7809 nce_reg: -0.1128 loss: 0.7820 prediction_mean: 0.7795 prediction_std: 0.4163 rmse: 0.8837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRkNY2zmy8eR"
      },
      "source": [
        "with open(\"/content/OTGNN/output/test/test_output.jsonl\", \"r+\") as output:\n",
        "  result_list = list(output)\n",
        "results = []\n",
        "for result_name in result_list:\n",
        "  result = json.loads(result_name)\n",
        "  results.append(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_mqwgmHafvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7576dc4-312f-4189-e6fe-cffce667d486"
      },
      "source": [
        "results[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0.0,\n",
              " 'pred': 2.0239148139953613,\n",
              " 'smiles': 'CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)C(C)(C)[C@@H]1CC3)C(C)(C)O'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvUAislc3gx3"
      },
      "source": [
        "sample_submission = pd.read_csv(directory +'sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "iS7kovnZ5Avn",
        "outputId": "2bac8831-9981-43a0-8fd5-e711927eca78"
      },
      "source": [
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>ST1_GAP(eV)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>test_597</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>test_598</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>test_599</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>test_600</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>test_601</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>602 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          uid  ST1_GAP(eV)\n",
              "0      test_0            0\n",
              "1      test_1            0\n",
              "2      test_2            0\n",
              "3      test_3            0\n",
              "4      test_4            0\n",
              "..        ...          ...\n",
              "597  test_597            0\n",
              "598  test_598            0\n",
              "599  test_599            0\n",
              "600  test_600            0\n",
              "601  test_601            0\n",
              "\n",
              "[602 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk9HEBju4k9u",
        "outputId": "53fda480-fc76-48da-a4e2-c4d131966193"
      },
      "source": [
        "result_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{\"smiles\": \"COc1ccc(S(=O)(=O)NC2CCN(C3CCCCC3)CC2)c(C)c1C\", \"label\": 0.0, \"pred\": 0.8731123805046082}\\n',\n",
              " '{\"smiles\": \"CC(CCCC1CCC2C3=C(CC[C@]12C)[C@@]1(C)CC[C@H](C)C(C)(C)[C@@H]1CC3)C(C)(C)O\", \"label\": 0.0, \"pred\": 2.0239148139953613}\\n',\n",
              " '{\"smiles\": \"C[C@@H]1C[C@@H]1c1ccc2c(c1)c(-c1ccc[nH]c1=O)c(C(=O)NS(C)(=O)=O)n2Cc1ccc(F)cc1F\", \"label\": 0.0, \"pred\": 0.9025053381919861}\\n',\n",
              " '{\"smiles\": \"CCCn1c(=O)c2ccccc2n2c(SCC(=O)NC(Cc3ccccc3)c3ccccc3)nnc12\", \"label\": 0.0, \"pred\": 1.2575137615203857}\\n',\n",
              " '{\"smiles\": \"CC(C)CN(C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)OCc1cncs1)S(=O)(=O)c1ccc2nc(N)sc2c1\", \"label\": 0.0, \"pred\": 0.7356685996055603}\\n',\n",
              " '{\"smiles\": \"CCN(CC(=O)O)C1CC(NC(=O)N2CC(C)(C)OC3(CCCC3)C2)C1\", \"label\": 0.0, \"pred\": 0.5603334307670593}\\n',\n",
              " '{\"smiles\": \"C#Cc1ccc(C(C(=O)Nc2c(C)cccc2C)N(C(=O)C(CO)NC(=O)OC(C)(C)C)C2CC2C)cc1\", \"label\": 0.0, \"pred\": 1.6882858276367188}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(N(C(=O)Cc2nc(N)n[nH]2)C2(C(=O)Nc3ccccc3C)CCCCC2)cc1\", \"label\": 0.0, \"pred\": 1.0191398859024048}\\n',\n",
              " '{\"smiles\": \"Cc1ccccc1CNC(=O)C1CC(=O)N(CCCN(C)C)C1\", \"label\": 0.0, \"pred\": 1.0089844465255737}\\n',\n",
              " '{\"smiles\": \"Cc1c(N)cccc1Oc1cc(Oc2cccc(N)c2C)c(C2C3CC4CC(C3)CC2C4)c(Oc2cccc(N)c2C)c1\", \"label\": 0.0, \"pred\": 0.7389373183250427}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2nc3c(C(=O)N4CCN(C(CO)c5cccc(N6CCNCC6)c5)C[C@H]4C)cnn3c(C(F)(F)F)c2C)cc1\", \"label\": 0.0, \"pred\": 0.5666655898094177}\\n',\n",
              " '{\"smiles\": \"Cc1nn(S(=O)(=O)c2ccc(OC(C)C)cc2)c(C)c1S(=O)(=O)N1CCCC1\", \"label\": 0.0, \"pred\": 1.1166675090789795}\\n',\n",
              " '{\"smiles\": \"COC(=O)[C@H]1C[C@H](n2cnnn2)CN1C(=O)OC(C)(C)C\", \"label\": 0.0, \"pred\": 0.7304367423057556}\\n',\n",
              " '{\"smiles\": \"CCCCCCC(C)NC1CCC2CCCCC2C1\", \"label\": 0.0, \"pred\": 0.2535693049430847}\\n',\n",
              " '{\"smiles\": \"OCC1CCN(CCOc2ccc3ncccc3c2)C1\", \"label\": 0.0, \"pred\": 1.022529125213623}\\n',\n",
              " '{\"smiles\": \"CNCC1CCC(C(C)C)CC1CCCc1ccccc1\", \"label\": 0.0, \"pred\": 1.338793158531189}\\n',\n",
              " '{\"smiles\": \"CCCC[C@H](N)C(=O)N[C@@H](Cc1ccc(N)cc1)C(=O)NC(=O)[C@H](CC(C)C)NCCc1ccccc1\", \"label\": 0.0, \"pred\": 0.6389150023460388}\\n',\n",
              " '{\"smiles\": \"Cc1[nH]ncc1S(=O)(=O)N1CSC[C@H]1C(=O)O\", \"label\": 0.0, \"pred\": 0.7259815335273743}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)OC(=O)OC1(O)C=CC(N)=C([N+](=O)[O-])C1\", \"label\": 0.0, \"pred\": 1.0036606788635254}\\n',\n",
              " '{\"smiles\": \"O=C(NCC(=O)N(Cc1cccs1)C(C(=O)NC1CCCCC1)c1ccccc1)c1cccs1\", \"label\": 0.0, \"pred\": 1.412366509437561}\\n',\n",
              " '{\"smiles\": \"O=C(CC1=C(O)CCn2c1nc1ccccc12)Nc1ccc2c(c1)CCN2\", \"label\": 0.0, \"pred\": 0.7835304141044617}\\n',\n",
              " '{\"smiles\": \"NCC(NC(=O)CCOc1ccccc1-c1ccccc1)C1CC1\", \"label\": 0.0, \"pred\": 1.149152398109436}\\n',\n",
              " '{\"smiles\": \"CC(C)C(C)(C)C(C)(C(=O)OCCOP(=O)(O)O)C(C)(C)C\", \"label\": 0.0, \"pred\": 0.5311972498893738}\\n',\n",
              " '{\"smiles\": \"CC1(O)C(F)C(COP(=O)(O)OP(=O)(O)OP(=O)(O)O)OC1n1ccc(=O)[nH]c1=S\", \"label\": 0.0, \"pred\": 1.3552138805389404}\\n',\n",
              " '{\"smiles\": \"Nc1cc(C(=O)NCC2CCCO2)cc(Cl)c1Cl\", \"label\": 0.0, \"pred\": 0.8662514090538025}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(C(F)(F)F)ccc1N1CCCCCC1CO\", \"label\": 0.0, \"pred\": 0.9440314173698425}\\n',\n",
              " '{\"smiles\": \"CCCc1cc(C(=O)OCC)[nH]c1CCC=O\", \"label\": 0.0, \"pred\": 0.8672243356704712}\\n',\n",
              " '{\"smiles\": \"O=Cc1cc(F)cc(OCc2c(Cl)cccc2[N+](=O)[O-])c1\", \"label\": 0.0, \"pred\": 0.2758330702781677}\\n',\n",
              " '{\"smiles\": \"CCCNC(Cc1ccnc(N)c1)C(C)CC\", \"label\": 0.0, \"pred\": 0.6242961287498474}\\n',\n",
              " '{\"smiles\": \"COc1ccc(C2CCCCCN2CC(=O)N2CCNC(=O)C2)cc1\", \"label\": 0.0, \"pred\": 0.36670631170272827}\\n',\n",
              " '{\"smiles\": \"O=C(NCCc1ccc(F)cc1)C(=O)NCCN1CCNCC1\", \"label\": 0.0, \"pred\": 0.5792824625968933}\\n',\n",
              " '{\"smiles\": \"Cc1nn(C)c(C)c1C(=O)N1CC(O)CC1C(=O)O\", \"label\": 0.0, \"pred\": 0.760075032711029}\\n',\n",
              " '{\"smiles\": \"C[C@H](COC1CCCCO1)c1cccc(CO)c1\", \"label\": 0.0, \"pred\": 1.224928379058838}\\n',\n",
              " '{\"smiles\": \"O=C(Cc1ccc(Cl)cc1)NNC(=O)c1ccc2c(=O)n3c(nc2c1)CCCCCC3\", \"label\": 0.0, \"pred\": 1.3225946426391602}\\n',\n",
              " '{\"smiles\": \"c1ccc(CN2Cc3ccccc3-n3nncc3C2)nc1\", \"label\": 0.0, \"pred\": 0.5164267420768738}\\n',\n",
              " '{\"smiles\": \"CC(C)COc1ccc(/C(=C\\\\\\\\C(=O)O)c2ccc(Cl)cc2)cc1\", \"label\": 0.0, \"pred\": 1.0407828092575073}\\n',\n",
              " '{\"smiles\": \"CNc1ccc2c(=O)n(-c3ccc(NC(=O)NS(=O)(=O)c4ccc(C)s4)cc3)cc(CN(C)C)c2c1\", \"label\": 0.0, \"pred\": 0.813654363155365}\\n',\n",
              " '{\"smiles\": \"COc1ccc(C(=O)OC(C)C(=O)c2ccc3c(c2)CCC3)cc1S(=O)(=O)NC1CC1\", \"label\": 0.0, \"pred\": 0.7268196940422058}\\n',\n",
              " '{\"smiles\": \"COC(=O)C[C@H]1CCC[C@H](C)N1\", \"label\": 0.0, \"pred\": 0.3875306248664856}\\n',\n",
              " '{\"smiles\": \"C=C(COC(C)(C)O)CC(C)CC(C)C\", \"label\": 0.0, \"pred\": 2.177901268005371}\\n',\n",
              " '{\"smiles\": \"CN(Cc1csc(Br)c1)C(=O)C(O)c1ccccc1\", \"label\": 0.0, \"pred\": 1.4507752656936646}\\n',\n",
              " '{\"smiles\": \"CCNC(=O)[C@H]1O[C@@H](n2cnc3c(NCC(c4ccccc4)c4ccccc4)nc(NCCN4CCNCC4)nc32)[C@H](O)[C@@H]1O\", \"label\": 0.0, \"pred\": 0.9851605296134949}\\n',\n",
              " '{\"smiles\": \"C=C(C)C(=O)OCCNC(=C)C(N)=O\", \"label\": 0.0, \"pred\": 0.2770199179649353}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(C(CN2CCCC2)N2CCNCC2)cc1\", \"label\": 0.0, \"pred\": 0.407632052898407}\\n',\n",
              " '{\"smiles\": \"CC(Cc1cccs1)N(C)/C(N)=N/C1CCCC1\", \"label\": 0.0, \"pred\": 0.7609023451805115}\\n',\n",
              " '{\"smiles\": \"CCn1cc(C=C(NC(=O)c2ccccc2Cl)C(=O)NCCc2c[nH]c3ccc(C)cc23)c2ccccc21\", \"label\": 0.0, \"pred\": 1.2562122344970703}\\n',\n",
              " '{\"smiles\": \"CC(C)CN(C1CCOCC1)C1CN(Cc2nccs2)C1\", \"label\": 0.0, \"pred\": 0.4638964533805847}\\n',\n",
              " '{\"smiles\": \"CCCCCCOc1ccc(-c2cnc(-c3ccc(OCC(F)CCCCC)cc3)nc2)cc1\", \"label\": 0.0, \"pred\": 1.2582751512527466}\\n',\n",
              " '{\"smiles\": \"Cc1cc(F)ccc1CCNC(=O)CCCCCl\", \"label\": 0.0, \"pred\": 1.3208484649658203}\\n',\n",
              " '{\"smiles\": \"OC[C@@H]1O[C@@H](n2cnc3c2ncn2ccnc32)C[C@H]1O\", \"label\": 0.0, \"pred\": 1.0873557329177856}\\n',\n",
              " '{\"smiles\": \"CCOc1ccccc1NC(=O)c1oc2c(c1C)/C(=N/Nc1ccccc1)CCC2\", \"label\": 0.0, \"pred\": 0.961245596408844}\\n',\n",
              " '{\"smiles\": \"CCCNC(=O)C(Cc1ccccc1)N(Cc1ccc(Br)cc1)C(=O)CCCN(c1ccc(OCC)cc1)S(C)(=O)=O\", \"label\": 0.0, \"pred\": 0.8289620280265808}\\n',\n",
              " '{\"smiles\": \"O=C(NCc1ccco1)NCC(c1ccccc1)c1c[nH]c2ccccc12\", \"label\": 0.0, \"pred\": 1.2362204790115356}\\n',\n",
              " '{\"smiles\": \"Cc1ccccc1N1CCN(C(=O)NC2CCC(C(=O)O)CC2)CC1\", \"label\": 0.0, \"pred\": 1.1688873767852783}\\n',\n",
              " '{\"smiles\": \"C=C(C(=O)OC)c1ccc(OC)c(F)c1\", \"label\": 0.0, \"pred\": 1.0366004705429077}\\n',\n",
              " '{\"smiles\": \"CC(O)(Cc1ccoc1)c1cc2ccccc2s1\", \"label\": 0.0, \"pred\": 1.3942718505859375}\\n',\n",
              " '{\"smiles\": \"COc1ccc(C2CCN(C(=O)c3ccc(S(=O)(=O)N4CCCC4)cc3)C2)cc1\", \"label\": 0.0, \"pred\": 0.6914994120597839}\\n',\n",
              " '{\"smiles\": \"CCCNC(Cc1c(C)cccc1C)C(OC)C1CC1\", \"label\": 0.0, \"pred\": 1.0380510091781616}\\n',\n",
              " '{\"smiles\": \"CCC(C)[C@H](NC(=O)[C@@H](NC(=O)[C@H](Cc1ccccc1)C[C@@H](O)[C@@H](N)Cc1ccccc1)C(C)C)C(N)=O\", \"label\": 0.0, \"pred\": 1.0023341178894043}\\n',\n",
              " '{\"smiles\": \"O=C(NC1CCCCCC1)C1CCN(C(=O)C2Sc3ccccc3NC2=O)CC1\", \"label\": 0.0, \"pred\": 0.920214831829071}\\n',\n",
              " '{\"smiles\": \"COCCNc1ccccc1CNC(=O)c1ccncc1Cl\", \"label\": 0.0, \"pred\": 1.0435314178466797}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)NC(CNC(=O)c1cc(F)ccc1F)CC(C)C\", \"label\": 0.0, \"pred\": 0.8893967270851135}\\n',\n",
              " '{\"smiles\": \"CCN(CCc1ccncc1)C(=O)C(=O)NC(C)C12CC3CC(CC(C3)C1)C2\", \"label\": 0.0, \"pred\": 0.3011876940727234}\\n',\n",
              " '{\"smiles\": \"COc1ccc([C@@H]2CC(=O)Nc3c2c(C)nn3-c2ccc(Cl)nn2)cc1OCC(C)C\", \"label\": 0.0, \"pred\": 0.667613685131073}\\n',\n",
              " '{\"smiles\": \"COc1ccccc1-n1ccc([C@H]2N(C)C(=O)c3ccccc3N2C)c1\", \"label\": 0.0, \"pred\": 0.927540123462677}\\n',\n",
              " '{\"smiles\": \"CN(C)C(=O)OCCN1CCN(CC(F)(F)F)CC1(C)C\", \"label\": 0.0, \"pred\": 0.18281669914722443}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-n2cnnc2C(C)C)cn1\", \"label\": 0.0, \"pred\": 0.8508507609367371}\\n',\n",
              " '{\"smiles\": \"Cn1c(-c2ccccc2C(F)(F)F)nnc1C(C)(C)Oc1ncccc1C#N\", \"label\": 0.0, \"pred\": 1.132294774055481}\\n',\n",
              " '{\"smiles\": \"CCNC(C)c1cc(F)c(C)cc1Sc1nccc(=O)[nH]1\", \"label\": 0.0, \"pred\": 0.794043242931366}\\n',\n",
              " '{\"smiles\": \"CCCCNC(=O)C(C)N(Cc1ccccc1F)C(=O)CN(c1ccccc1OC)S(C)(=O)=O\", \"label\": 0.0, \"pred\": 1.1536740064620972}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(-c2ccc(C(=O)NCCCO)o2)cc1\", \"label\": 0.0, \"pred\": 1.567805290222168}\\n',\n",
              " '{\"smiles\": \"COC(=O)c1ccc2[nH]c3c(c2c1)CN(C(=O)C1CCCN(C(=O)C(C)C)C1)CC3\", \"label\": 0.0, \"pred\": 0.6806320548057556}\\n',\n",
              " '{\"smiles\": \"CCc1nn(C)cc1C(=O)N(C)[C@@H]1CNC[C@H]1O\", \"label\": 0.0, \"pred\": 0.550496518611908}\\n',\n",
              " '{\"smiles\": \"C=CCn1cc(CC(=O)OC)c2cccnc21\", \"label\": 0.0, \"pred\": 1.0115886926651}\\n',\n",
              " '{\"smiles\": \"COC[C@@H]1[C@H](C(=O)Nc2ccc3c(c2)OCCO3)CCC(=O)N1C\", \"label\": 0.0, \"pred\": 0.7034558653831482}\\n',\n",
              " '{\"smiles\": \"Cc1[nH]c(=S)sc1CC(=O)N[C@@H]1CCCN(c2ccccc2F)C1=O\", \"label\": 0.0, \"pred\": 1.1380013227462769}\\n',\n",
              " '{\"smiles\": \"O=COc1cccc(-c2cccc(C(=O)O)c2)c1\", \"label\": 0.0, \"pred\": 0.611689031124115}\\n',\n",
              " '{\"smiles\": \"Cc1scc(C(=O)Nc2ccc(N3CCC(C)CC3)nc2)c1C\", \"label\": 0.0, \"pred\": 0.8013727068901062}\\n',\n",
              " '{\"smiles\": \"COC(=O)C[C@@H]1COc2cc(O[C@@H]3CCc4c(Oc5c(F)cc(-c6cnn(CC(C)(C)O)c6)cc5F)ccc(F)c43)ccc21\", \"label\": 0.0, \"pred\": 0.8031834959983826}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C(=O)O)ccc1-c1ccc(NS(C)(=O)=O)cc1\", \"label\": 0.0, \"pred\": 0.917539656162262}\\n',\n",
              " '{\"smiles\": \"NNC(Cc1nccs1)c1cc(C(F)(F)F)ccc1Br\", \"label\": 0.0, \"pred\": 0.7648623585700989}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(F)c(CNc2cccc(O)c2)c1\", \"label\": 0.0, \"pred\": 1.1881998777389526}\\n',\n",
              " '{\"smiles\": \"Cn1ccnc1[C@@H](NC(=O)Cc1ccc(Cl)c(Cl)c1)c1ccc(Cl)cc1\", \"label\": 0.0, \"pred\": 1.075711965560913}\\n',\n",
              " '{\"smiles\": \"COc1cccc(C2/C(=C(/O)c3ccc4c(c3)CCCO4)C(=O)C(=O)N2c2cccc(C(F)(F)F)c2)c1\", \"label\": 0.0, \"pred\": 0.5679423213005066}\\n',\n",
              " '{\"smiles\": \"OC1CC(Oc2cccc(I)c2)C12CCCC2\", \"label\": 0.0, \"pred\": 0.7590168118476868}\\n',\n",
              " '{\"smiles\": \"Cc1nc(C2(NC(=O)CCc3c(C)nc(N4CCOCC4)[nH]c3=O)CCCCCC2)no1\", \"label\": 0.0, \"pred\": 0.903155505657196}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-c2ccc(Oc3ccc([N+](=O)[O-])cc3)cc2)[nH]c(C(N)=O)c1N\", \"label\": 0.0, \"pred\": 0.7425548434257507}\\n',\n",
              " '{\"smiles\": \"Cc1n[nH]c(C)c1C(=O)N1CCSCC1S(C)(=O)=O\", \"label\": 0.0, \"pred\": 0.3807753920555115}\\n',\n",
              " '{\"smiles\": \"C=CCNC(=O)CNC(=O)Nc1ccn(-c2ccc(F)cc2C)n1\", \"label\": 0.0, \"pred\": 1.0126229524612427}\\n',\n",
              " '{\"smiles\": \"Cc1noc(C)c1CSc1nc(=O)[nH]c(C)c1C(=O)O\", \"label\": 0.0, \"pred\": 0.37729138135910034}\\n',\n",
              " '{\"smiles\": \"O=C(NCCCSc1ccc(F)cc1)C1CCCN(C(=O)c2cccs2)C1\", \"label\": 0.0, \"pred\": 1.0675536394119263}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c2c(c1)OC1(CCN(C(=O)c3ccc4c(c3)CCCC(=O)N4)CC1)CC2=O\", \"label\": 0.0, \"pred\": 0.8850484490394592}\\n',\n",
              " '{\"smiles\": \"CCCCCCOc1ccc([C@@H]2C3=C(CC(C)(C)CC3=O)Nc3[nH]c(=S)[nH]c(=O)c32)cc1OC\", \"label\": 0.0, \"pred\": 0.5420348048210144}\\n',\n",
              " '{\"smiles\": \"CCOCC(C)(N)c1noc(-c2ccnnc2)n1\", \"label\": 0.0, \"pred\": 1.1282551288604736}\\n',\n",
              " '{\"smiles\": \"COc1cc(F)c2c(c1)[C@H](N(Cc1ccccc1C(N)=O)C(=O)c1cccnc1)CC2\", \"label\": 0.0, \"pred\": 0.5783283114433289}\\n',\n",
              " '{\"smiles\": \"CCOC=C1C(=O)CC(C)(C)CC1=O\", \"label\": 0.0, \"pred\": 0.46136659383773804}\\n',\n",
              " '{\"smiles\": \"CN(C)c1ccc(N/C=C\\\\\\\\C(=O)c2ccsc2)cc1\", \"label\": 0.0, \"pred\": 0.6093634963035583}\\n',\n",
              " '{\"smiles\": \"CCNC(Cc1nc(-c2ccc(C)c(F)c2)no1)C(C)C\", \"label\": 0.0, \"pred\": 0.9887420535087585}\\n',\n",
              " '{\"smiles\": \"CN(C(=O)N(CCC(=O)O)C1CC1)C1CC1\", \"label\": 0.0, \"pred\": 0.3529040217399597}\\n',\n",
              " '{\"smiles\": \"O=C(CN(c1nc2ccccc2s1)S(=O)(=O)c1ccccc1)N1CCN(c2ncccn2)CC1\", \"label\": 0.0, \"pred\": 0.49748533964157104}\\n',\n",
              " '{\"smiles\": \"CCNC(c1ccc(Cl)cc1)C1(C)CCCO1\", \"label\": 0.0, \"pred\": 0.8438056111335754}\\n',\n",
              " '{\"smiles\": \"CC1CN(C)CCC1NCCC(=O)N1CCN(c2ncccn2)CC1\", \"label\": 0.0, \"pred\": 0.6497067809104919}\\n',\n",
              " '{\"smiles\": \"CCCCCNc1nc(N)nc2ccn(Cc3cc(OCC#N)ccc3OC)c12\", \"label\": 0.0, \"pred\": 0.6238353848457336}\\n',\n",
              " '{\"smiles\": \"CCCN(CCBr)CC1COc2ccccc21\", \"label\": 0.0, \"pred\": 0.770662248134613}\\n',\n",
              " '{\"smiles\": \"C=CCn1c(C(C)C)nc(-c2ccc(Br)cc2Cl)c1N\", \"label\": 0.0, \"pred\": 0.9032498002052307}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(S(=O)(=O)N2CCCC(C(=O)N3C4COCC3C4)C2)cc1\", \"label\": 0.0, \"pred\": 1.1817035675048828}\\n',\n",
              " '{\"smiles\": \"CC(=O)N[C@@H]1[C@@H](O)C[C@@](O)(Cc2cccc3c2S(=O)(=O)NC3=O)O[C@H]1[C@H](O)[C@H](O)CO\", \"label\": 0.0, \"pred\": 0.534615695476532}\\n',\n",
              " '{\"smiles\": \"O=C(CSc1cc(C(=O)NC2CC2)c2ccccc2n1)c1cccc([N+](=O)[O-])c1\", \"label\": 0.0, \"pred\": 0.5466892123222351}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c(CNC(=O)CN2CCCCCC2=O)c(C)c1\", \"label\": 0.0, \"pred\": 0.9743265509605408}\\n',\n",
              " '{\"smiles\": \"O=C(CSc1ccc2c(c1)CCC2)c1cccs1\", \"label\": 0.0, \"pred\": 0.39760226011276245}\\n',\n",
              " '{\"smiles\": \"CCCC1CCCN(Cc2cccc(C(=O)O)c2)C1\", \"label\": 0.0, \"pred\": 0.19037385284900665}\\n',\n",
              " '{\"smiles\": \"COC(=O)c1ncn(-c2sc([C@@H](C)O)cc2[N+](=O)[O-])n1\", \"label\": 0.0, \"pred\": 0.5417847037315369}\\n',\n",
              " '{\"smiles\": \"CCN(CC1CCC1)C(=O)c1cc(OC)ccc1Br\", \"label\": 0.0, \"pred\": 1.2949376106262207}\\n',\n",
              " '{\"smiles\": \"NC(=O)c1cc(S(=O)(=O)NCc2ccc(Cl)cc2)c2c(c1)nc(NCc1ccccc1Cl)n2C[C@H]1CCCCC[C@H]1O\", \"label\": 0.0, \"pred\": 0.719944417476654}\\n',\n",
              " '{\"smiles\": \"CN(c1ccccc1)c1cc(C(F)(F)F)cc(N)n1\", \"label\": 0.0, \"pred\": 0.8255078196525574}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(COc2ccc3c(c2)CCCc2nncn2-3)cc1\", \"label\": 0.0, \"pred\": 0.9127936959266663}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2nnc(NC(=O)c3ccc(Cl)c(S(=O)(=O)N4CCN(C)CC4)c3)s2)cc1\", \"label\": 0.0, \"pred\": 0.23909182846546173}\\n',\n",
              " '{\"smiles\": \"O=C1N/C(=C\\\\\\\\c2cc(Br)c(I)o2)C(=O)N1Cc1ccccc1Cl\", \"label\": 0.0, \"pred\": 1.514108657836914}\\n',\n",
              " '{\"smiles\": \"CC(=O)OCC1(c2ccc(-c3nc(I)c(NC(=O)C(F)(F)F)cc3Cl)cc2)CC1\", \"label\": 0.0, \"pred\": 1.3972034454345703}\\n',\n",
              " '{\"smiles\": \"COc1ccc(OCCn2c(NC(=O)c3ccccc3Cl)nc3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.7205712199211121}\\n',\n",
              " '{\"smiles\": \"CC(C)COc1ccc(CC2CNc3ccc(O)cc3O2)cc1\", \"label\": 0.0, \"pred\": 0.9324464201927185}\\n',\n",
              " '{\"smiles\": \"Cc1snc(-c2ccccc2)c1-c1ccc(S(C)(=O)=O)cc1\", \"label\": 0.0, \"pred\": 1.1345610618591309}\\n',\n",
              " '{\"smiles\": \"O=[N+]([O-])c1ccc(C(O)Cc2ccc(F)cc2F)o1\", \"label\": 0.0, \"pred\": 0.8533895611763}\\n',\n",
              " '{\"smiles\": \"C=CCc1ccc(OC)cc1NCC(C)C\", \"label\": 0.0, \"pred\": 0.7134241461753845}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)OC(=O)NC1(C(=O)O)CCN(C(=O)c2cn[nH]c2)C1\", \"label\": 0.0, \"pred\": 0.6609472632408142}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)NCCc1ccc2c(c1)NCC(c1ccccc1)O2\", \"label\": 0.0, \"pred\": 0.7846302390098572}\\n',\n",
              " '{\"smiles\": \"CC(C)n1ncc2cc(C(=O)N3CCC[C@@H]3[C@H]3CCCN3C)cnc21\", \"label\": 0.0, \"pred\": 0.7410929799079895}\\n',\n",
              " '{\"smiles\": \"O=C(O)[C@@H]1CN(C(=O)Nc2cccc([N+](=O)[O-])c2)C[C@H]1C(F)(F)F\", \"label\": 0.0, \"pred\": 0.6306244730949402}\\n',\n",
              " '{\"smiles\": \"CC(Nc1cccc(Cl)c1)N1C(=O)CCC1=O\", \"label\": 0.0, \"pred\": 0.8107126355171204}\\n',\n",
              " '{\"smiles\": \"COC(=O)CC(NC(=O)c1ccc(C#N)cc1)c1ccccc1Cl\", \"label\": 0.0, \"pred\": 0.7819154858589172}\\n',\n",
              " '{\"smiles\": \"CC(C)C(Sc1cccc(F)c1)C(=O)NN\", \"label\": 0.0, \"pred\": 0.9413151144981384}\\n',\n",
              " '{\"smiles\": \"CCNc1nc(-c2ccc(Cl)cn2)nc(C2CC2)c1I\", \"label\": 0.0, \"pred\": 0.4050446152687073}\\n',\n",
              " '{\"smiles\": \"CC(=O)c1ccc(NC(=O)[C@@H](C)N[C@H](C)c2cc(F)c(Cl)cc2Cl)cc1\", \"label\": 0.0, \"pred\": 0.7273203730583191}\\n',\n",
              " '{\"smiles\": \"CCC(C)N(C)Cc1ccc(CNCC(C)C)cn1\", \"label\": 0.0, \"pred\": 0.22743256390094757}\\n',\n",
              " '{\"smiles\": \"N#Cc1ccc(CNC(=O)c2cc(Br)ccc2F)c(F)c1\", \"label\": 0.0, \"pred\": 0.9277840256690979}\\n',\n",
              " '{\"smiles\": \"Nc1cc(-c2cscn2)ccc1OCC(=O)Nc1ccccc1F\", \"label\": 0.0, \"pred\": 1.0168622732162476}\\n',\n",
              " '{\"smiles\": \"CC1CC(C(=O)Nc2ccc(C(F)(F)F)cc2)CCN1\", \"label\": 0.0, \"pred\": 1.027777910232544}\\n',\n",
              " '{\"smiles\": \"CC[C@@H](C)[C@H](NC(=O)COC(=O)c1ccc(N(C)C)cc1)C(=O)OC\", \"label\": 0.0, \"pred\": 0.9834557175636292}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)c1cc(C(=O)NC(C)c2ccc(-n3ccnc3)cc2)cc([N+](=O)[O-])c1\", \"label\": 0.0, \"pred\": 0.6575095057487488}\\n',\n",
              " '{\"smiles\": \"NC1CCCCC1CC(=O)NCc1ccccc1C(F)(F)F\", \"label\": 0.0, \"pred\": 1.1401338577270508}\\n',\n",
              " '{\"smiles\": \"Cc1c(N)cc(S(=O)(=O)NCC(=O)NC2CC2)cc1F\", \"label\": 0.0, \"pred\": 0.7910521626472473}\\n',\n",
              " '{\"smiles\": \"COc1cc(C(=O)Nc2ccc(F)c(F)c2)ccc1OCc1cscn1\", \"label\": 0.0, \"pred\": 1.1171455383300781}\\n',\n",
              " '{\"smiles\": \"CC[C@@H](C)c1ccccc1NC(=O)COC(=O)c1nn(C)c(=O)c2ccccc12\", \"label\": 0.0, \"pred\": 0.9365398287773132}\\n',\n",
              " '{\"smiles\": \"COc1ccc(NC(=O)CSc2nc3sc4c(c3c(=O)n2-c2ccccc2)CCCC4)cc1\", \"label\": 0.0, \"pred\": 0.5752119421958923}\\n',\n",
              " '{\"smiles\": \"OCC(Cc1ccc(O)cc1)Cc1ccc(F)cc1\", \"label\": 0.0, \"pred\": 1.2650145292282104}\\n',\n",
              " '{\"smiles\": \"CCc1nc2ccccc2n1C1CCCCC1CC\", \"label\": 0.0, \"pred\": 1.0107094049453735}\\n',\n",
              " '{\"smiles\": \"CS(=O)(=O)CCNc1nccc(-c2cccc(-c3cnc4ccc(N5CCCC5)nn34)n2)n1\", \"label\": 0.0, \"pred\": 0.4987632632255554}\\n',\n",
              " '{\"smiles\": \"CC1=CCC(C2CCCOC2=O)C1(C)C\", \"label\": 0.0, \"pred\": 1.4333715438842773}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)NC(=O)CSc1nnc(-c2ccccc2)c2ccccc12\", \"label\": 0.0, \"pred\": 1.1261208057403564}\\n',\n",
              " '{\"smiles\": \"CC1CCCC(C)C1NC(=O)CCc1cnn(C)c1\", \"label\": 0.0, \"pred\": 0.6669463515281677}\\n',\n",
              " '{\"smiles\": \"C=CCCCCCCC(=O)N1CCC[C@H]1C(=O)NC(=O)OC(C)(C)C\", \"label\": 0.0, \"pred\": 1.1075221300125122}\\n',\n",
              " '{\"smiles\": \"Cc1noc(/C=C/c2sc3ccccc3c2Cl)c1[N+](=O)[O-]\", \"label\": 0.0, \"pred\": 1.4856655597686768}\\n',\n",
              " '{\"smiles\": \"Nc1ccc(CN2C(=O)c3ccccc3C2=O)cc1F\", \"label\": 0.0, \"pred\": 0.19845052063465118}\\n',\n",
              " '{\"smiles\": \"CCNc1ncc(Br)c(NCC(O)CC(C)C)n1\", \"label\": 0.0, \"pred\": 0.9412046074867249}\\n',\n",
              " '{\"smiles\": \"CC(C)c1ccc(/C=C/C(=O)NCCc2cn3cc(Cl)cc(Cl)c3n2)cc1\", \"label\": 0.0, \"pred\": 1.1510179042816162}\\n',\n",
              " '{\"smiles\": \"CCC(O)(CC)CN1CCS(=O)C(C)(C)C1\", \"label\": 0.0, \"pred\": 0.3093417286872864}\\n',\n",
              " '{\"smiles\": \"CCCCCCCCCNC(=O)CCn1c(=O)[nH]c(=O)c2ccccc21\", \"label\": 0.0, \"pred\": 0.8347670435905457}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(CNc2nncs2)o1\", \"label\": 0.0, \"pred\": 0.8760771155357361}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2nnc(SCC(=O)NC3(C#N)CCCCC3)n2N)cc1\", \"label\": 0.0, \"pred\": 1.0032683610916138}\\n',\n",
              " '{\"smiles\": \"O=c1[nH]c2cc3c4nc5nc(nc6[nH]c(nc7nc(nc([nH]4)c3cc2[nH]1)-c1ccccc1-7)c1ccccc61)-c1ccccc1-5\", \"label\": 0.0, \"pred\": 0.7594839930534363}\\n',\n",
              " '{\"smiles\": \"OC(CNc1ncnc2c1oc1ccccc12)C1CCCC1\", \"label\": 0.0, \"pred\": 0.7678709626197815}\\n',\n",
              " '{\"smiles\": \"CCc1cc(C(=O)NC(CCC(=O)O)C(=O)O)cc(Cl)n1\", \"label\": 0.0, \"pred\": 0.5326091647148132}\\n',\n",
              " '{\"smiles\": \"CCCOc1ccc(C(=O)Nc2cccc(C3SCCS3)c2)cc1OCC\", \"label\": 0.0, \"pred\": 0.9314687848091125}\\n',\n",
              " '{\"smiles\": \"CCN(CC)C(=O)CN(C)Cc1ccc(N)c(F)c1\", \"label\": 0.0, \"pred\": 0.6498957276344299}\\n',\n",
              " '{\"smiles\": \"O=C(O)CC[C@H](NC(=O)c1cccc(Cl)c1)C(=O)O\", \"label\": 0.0, \"pred\": 0.7882325053215027}\\n',\n",
              " '{\"smiles\": \"N#Cc1cccc(C(=O)Nc2n[nH]c(-c3cccc(Br)c3)n2)c1\", \"label\": 0.0, \"pred\": 0.9050481915473938}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)[Si](C)(C)OCc1cc(O[Si](C)(C)C(C)(C)C)cc(=O)o1\", \"label\": 0.0, \"pred\": 2.040555715560913}\\n',\n",
              " '{\"smiles\": \"O=C(NCCNCc1ccccc1O)c1sccc1Nc1ccnc2[nH]ccc12\", \"label\": 0.0, \"pred\": 1.1501898765563965}\\n',\n",
              " '{\"smiles\": \"CC(C)C1CNC(C)(C)CN1Cc1ccc2c(c1)CCC2\", \"label\": 0.0, \"pred\": 0.7546949982643127}\\n',\n",
              " '{\"smiles\": \"COc1ccc(NC(=O)CN2C(=O)NC(C)(c3cc(F)ccc3F)C2=O)cc1S(=O)(=O)N(C)C\", \"label\": 0.0, \"pred\": 0.9902006983757019}\\n',\n",
              " '{\"smiles\": \"CCC1(CC)NC(=O)CN(c2cc(F)c(F)c(F)c2)C1=O\", \"label\": 0.0, \"pred\": 0.9769830107688904}\\n',\n",
              " '{\"smiles\": \"O=C(O)C1=C2CCCN2C(=O)C(F)C1Nc1ccc(Br)cc1F\", \"label\": 0.0, \"pred\": 0.9416361451148987}\\n',\n",
              " '{\"smiles\": \"O=C(O)[C@H]1CCCN1Cc1ccc(-c2ccccc2[N+](=O)[O-])s1\", \"label\": 0.0, \"pred\": 0.645886242389679}\\n',\n",
              " '{\"smiles\": \"CC(C)CC1(c2nc3ccc(C#N)cc3[nH]2)CCCC1\", \"label\": 0.0, \"pred\": 1.09876549243927}\\n',\n",
              " '{\"smiles\": \"COC(=O)Nc1ccc(-c2cc(C(CC(C)C)NC(=O)C=Cc3cc(Cl)ccc3-n3cnnn3)c(Cl)nn2)cc1\", \"label\": 0.0, \"pred\": 0.9270293116569519}\\n',\n",
              " '{\"smiles\": \"Cc1cn(-c2ccccn2)c(C)c1Cc1sc2c(c1C(=O)N1C[C@](C)(O)CO1)c(=O)n(C)c(=O)n2C(C)C\", \"label\": 0.0, \"pred\": 0.6233493685722351}\\n',\n",
              " '{\"smiles\": \"CC(C)CN(CC(C)(C#N)NC1CC1)C(C)C\", \"label\": 0.0, \"pred\": 0.10636849701404572}\\n',\n",
              " '{\"smiles\": \"CC1CC=CCC1COCC(O)CNCC1(C)CCCO1\", \"label\": 0.0, \"pred\": 0.8647804856300354}\\n',\n",
              " '{\"smiles\": \"O=C(CNC(=O)c1ccc(F)cc1)NCc1n[nH]c(=O)n1C1CC1\", \"label\": 0.0, \"pred\": 0.9566611647605896}\\n',\n",
              " '{\"smiles\": \"CNCCc1nc(-c2ccccn2)nn1C\", \"label\": 0.0, \"pred\": 0.7696148753166199}\\n',\n",
              " '{\"smiles\": \"CNC(Cc1ccccc1[N+](=O)[O-])c1c(F)cccc1Cl\", \"label\": 0.0, \"pred\": 0.4394003748893738}\\n',\n",
              " '{\"smiles\": \"CC(=O)Nc1cc(NC(=O)NC(CCC(=O)O)Cc2ccccc2)ccc1C\", \"label\": 0.0, \"pred\": 1.0796308517456055}\\n',\n",
              " '{\"smiles\": \"COc1ccccc1N1CCN(C(=O)CN(CC2CCCO2)C(C)=O)CC1\", \"label\": 0.0, \"pred\": 1.1671576499938965}\\n',\n",
              " '{\"smiles\": \"COc1cc(Cl)c(NC(C)c2ccc(O)cc2)cc1OC\", \"label\": 0.0, \"pred\": 0.8459489941596985}\\n',\n",
              " '{\"smiles\": \"CCOC(C(N)Cc1cc(CC)nn1C)C(C)(C)C\", \"label\": 0.0, \"pred\": 0.9651156067848206}\\n',\n",
              " '{\"smiles\": \"Cc1cc(Cl)cc2c1NC(=O)C2(O)C(C(=O)C1=CCC=C=C1)c1ccccc1\", \"label\": 0.0, \"pred\": 0.8281871676445007}\\n',\n",
              " '{\"smiles\": \"CC(C)c1nc(CS(=O)(=O)c2cccc(C(=O)O)c2)no1\", \"label\": 0.0, \"pred\": 0.5522386431694031}\\n',\n",
              " '{\"smiles\": \"CC(C)C1CNC(C)(C2CC2)CN1CCC(C)(C)C\", \"label\": 0.0, \"pred\": 0.22036738693714142}\\n',\n",
              " '{\"smiles\": \"CCN/C(=N\\\\\\\\CC1(CCOC)CCC1)NCCCCCOC\", \"label\": 0.0, \"pred\": 0.8844665884971619}\\n',\n",
              " '{\"smiles\": \"CCn1nccc1N1CCC[C@H](N[C@@H](C)C2CCC2)C1=O\", \"label\": 0.0, \"pred\": 0.8525319695472717}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(NS(=O)(=O)c2ccc3c(c2)CCCN3)c1\", \"label\": 0.0, \"pred\": 1.2410728931427002}\\n',\n",
              " '{\"smiles\": \"Cc1nc(C(F)(F)F)cc2nc(S(=O)(=O)Nc3cc(F)ccc3F)nn12\", \"label\": 0.0, \"pred\": 0.8166590332984924}\\n',\n",
              " '{\"smiles\": \"CCCCNC(c1ccccc1)c1ccc(OC)cc1\", \"label\": 0.0, \"pred\": 0.7947667241096497}\\n',\n",
              " '{\"smiles\": \"CC/C(=C/CO)c1cccc(CCc2ccc(CO[Si](C)(C)C(C)(C)C)c(CO[Si](C)(C)C(C)(C)C)c2)c1\", \"label\": 0.0, \"pred\": 1.2661213874816895}\\n',\n",
              " '{\"smiles\": \"CCOc1ccccc1OCC(=O)N1CCCC1c1nc2ccccc2[nH]1\", \"label\": 0.0, \"pred\": 1.0796297788619995}\\n',\n",
              " '{\"smiles\": \"CCCNC(Cc1ccc(CC)cc1)C(CCC)OCC\", \"label\": 0.0, \"pred\": 1.032300591468811}\\n',\n",
              " '{\"smiles\": \"COc1cccc(C(=O)[C@H]2N=NC[C@H]2c2ccccc2)c1\", \"label\": 0.0, \"pred\": 0.6584785580635071}\\n',\n",
              " '{\"smiles\": \"CC(=O)Nc1cccc(NC(C)=S)c1\", \"label\": 0.0, \"pred\": 0.3152419924736023}\\n',\n",
              " '{\"smiles\": \"Nc1ccc(C(=O)N2CCN(Cc3ccc(F)c(Cl)c3)CC2)cc1\", \"label\": 0.0, \"pred\": 0.958777129650116}\\n',\n",
              " '{\"smiles\": \"O=C(C1CC1c1ccco1)N(CC1CCCCC1)C1CC1\", \"label\": 0.0, \"pred\": 1.4427499771118164}\\n',\n",
              " '{\"smiles\": \"O=C1[C@@H]2Cc3c([nH]c4ccccc34)CN2C(=O)CN1C1CCCCC1\", \"label\": 0.0, \"pred\": 0.5345514416694641}\\n',\n",
              " '{\"smiles\": \"Nc1cc2c(c(S(=O)(=O)NCCCC3CC3)c1)OCCC2\", \"label\": 0.0, \"pred\": 1.0832563638687134}\\n',\n",
              " '{\"smiles\": \"CCC(CN)(Cc1ccccc1)N1CCOC2CCCC21\", \"label\": 0.0, \"pred\": 0.9418173432350159}\\n',\n",
              " '{\"smiles\": \"CC(C)CNCc1c(Cl)cccc1-n1cnc(C#N)n1\", \"label\": 0.0, \"pred\": 0.8358287215232849}\\n',\n",
              " '{\"smiles\": \"CCC(CC)CN(CC)CC=CCN\", \"label\": 0.0, \"pred\": 0.8111544847488403}\\n',\n",
              " '{\"smiles\": \"CCOC(c1noc(-c2ccncc2N)n1)C1CC1\", \"label\": 0.0, \"pred\": 1.469987392425537}\\n',\n",
              " '{\"smiles\": \"CC(C(=O)c1cccc(OC(F)F)c1)c1ccccn1\", \"label\": 0.0, \"pred\": 0.6160922646522522}\\n',\n",
              " '{\"smiles\": \"Cc1occc1Sc1nc(Cl)c(C#N)s1\", \"label\": 0.0, \"pred\": 1.3537042140960693}\\n',\n",
              " '{\"smiles\": \"CCCN(C=CC=C(C#N)C#N)CC(=O)OCCOc1ccccc1\", \"label\": 0.0, \"pred\": 2.148176431655884}\\n',\n",
              " '{\"smiles\": \"COc1nc2ccc(C)cc2c2c(O)cncc12\", \"label\": 0.0, \"pred\": 0.931025505065918}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c(CC(C(=O)O)c2c(F)cccc2Cl)c(C)c1\", \"label\": 0.0, \"pred\": 1.0716081857681274}\\n',\n",
              " '{\"smiles\": \"CC(OC(=O)CNC(=O)c1cccc([N+](=O)[O-])c1)C(=O)Nc1ccc2c(c1)OCCO2\", \"label\": 0.0, \"pred\": 0.37387651205062866}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(NC(C)C(=O)N2CCOCC2)c1C\", \"label\": 0.0, \"pred\": 0.7334291338920593}\\n',\n",
              " '{\"smiles\": \"N#Cc1cccc(CS(=O)(=O)Oc2ccc3ccc(=O)oc3c2)c1\", \"label\": 0.0, \"pred\": 1.3245646953582764}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2[nH]c(=O)c(-c3nc4c(C)cccn4c3NCC3CCCO3)cc2c1\", \"label\": 0.0, \"pred\": 0.9619448781013489}\\n',\n",
              " '{\"smiles\": \"N#CCC(F)(F)c1ccc2c(c1)CCCO2\", \"label\": 0.0, \"pred\": 0.9323622584342957}\\n',\n",
              " '{\"smiles\": \"CC(C)CNS(=O)(=O)Nc1ccc(C#N)cn1\", \"label\": 0.0, \"pred\": 0.9832953810691833}\\n',\n",
              " '{\"smiles\": \"Cc1cc([N+](=O)[O-])ccc1-n1cccc(C)c1=O\", \"label\": 0.0, \"pred\": 0.383558452129364}\\n',\n",
              " '{\"smiles\": \"C[C@H]1CCc2cc(-c3ccc(N4CCOCC4)nn3)ccc2N1C(=O)c1ccc(O)cc1O\", \"label\": 0.0, \"pred\": 0.8069490790367126}\\n',\n",
              " '{\"smiles\": \"O=C1C2C(=NN1c1ccccc1)N=C1CCCCC1C21C(=O)Nc2ccccc21\", \"label\": 0.0, \"pred\": 0.9151996970176697}\\n',\n",
              " '{\"smiles\": \"O=C(O)c1ccc2cnc(Br)nc2c1\", \"label\": 0.0, \"pred\": 0.6981737017631531}\\n',\n",
              " '{\"smiles\": \"CCCCc1nc2nc(CO)sc2n1Cc1ccc(OCc2ccc(-c3nn[nH]n3)cc2)cc1\", \"label\": 0.0, \"pred\": 0.9102759957313538}\\n',\n",
              " '{\"smiles\": \"COCCCOc1ccccc1NC(=O)Cn1ncc(=O)c2ccccc21\", \"label\": 0.0, \"pred\": 0.9249778389930725}\\n',\n",
              " '{\"smiles\": \"CCCC1CCC(CCc2cc(F)c(C#Cc3ccc(F)c(F)c3)c(F)c2)CC1\", \"label\": 0.0, \"pred\": 1.1933892965316772}\\n',\n",
              " '{\"smiles\": \"Cc1cc(S(=O)(=O)NC2CCCCC2C)cc(N)c1C\", \"label\": 0.0, \"pred\": 1.1517972946166992}\\n',\n",
              " '{\"smiles\": \"c1cn(-c2ccc(CSc3nc4ncncc4[nH]3)cc2)cn1\", \"label\": 0.0, \"pred\": 0.7578801512718201}\\n',\n",
              " '{\"smiles\": \"COc1cccc(C(=O)COC(=O)CCN2C(=O)c3cc(Cl)c(Cl)cc3C2=O)c1\", \"label\": 0.0, \"pred\": 0.23050184547901154}\\n',\n",
              " '{\"smiles\": \"COC(=O)CSc1nc(N)cc2ncnn12\", \"label\": 0.0, \"pred\": 1.2070436477661133}\\n',\n",
              " '{\"smiles\": \"CNC(c1ccsc1)c1cc(Cl)ccc1C\", \"label\": 0.0, \"pred\": 1.0738481283187866}\\n',\n",
              " '{\"smiles\": \"Fc1cccc(F)c1CNc1cc2c(cc1Cl)OCO2\", \"label\": 0.0, \"pred\": 0.8934687376022339}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2cc(C(=O)NCC(C)C)c3cc(F)ccc3n2)c(OC)c1\", \"label\": 0.0, \"pred\": 1.1715710163116455}\\n',\n",
              " '{\"smiles\": \"O=C(O)Cc1c(Cl)cnc(C(F)F)c1O\", \"label\": 0.0, \"pred\": 0.6379720568656921}\\n',\n",
              " '{\"smiles\": \"Clc1cc2cc(-c3cnn(CC4CC4)c3)ccc2cn1\", \"label\": 0.0, \"pred\": 0.9690212607383728}\\n',\n",
              " '{\"smiles\": \"COc1cc(-c2ccc3ncc(C(=O)C4CC4)c(N4CCC(CCN5CCCC5)CC4)c3c2)cc(Cl)c1O\", \"label\": 0.0, \"pred\": 0.7837244868278503}\\n',\n",
              " '{\"smiles\": \"O=C(O)C1CCN(c2ccc(OC3CC3)c(Cl)c2)C1\", \"label\": 0.0, \"pred\": 1.043892502784729}\\n',\n",
              " '{\"smiles\": \"CCc1ccc(C(CCO)N2CCNCC2)cc1\", \"label\": 0.0, \"pred\": 0.4462457299232483}\\n',\n",
              " '{\"smiles\": \"CC(=O)c1ccccc1-c1ccc2c(c1)C[C@@H](CNC(=O)CCCc1cccs1)O2\", \"label\": 0.0, \"pred\": 0.7137076258659363}\\n',\n",
              " '{\"smiles\": \"CC(C)N(CCSC(F)(F)F)CC(=O)O\", \"label\": 0.0, \"pred\": 0.3238987326622009}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C(=O)CC2(N)CCC2)ccc1F\", \"label\": 0.0, \"pred\": 0.6695751547813416}\\n',\n",
              " '{\"smiles\": \"CNCc1sccc1N\", \"label\": 0.0, \"pred\": 1.6474109888076782}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(C)c1-c1nc(NS(=O)(=O)c2cccc(NC3CCOCC3)n2)ccc1Cl\", \"label\": 0.0, \"pred\": 0.5264222025871277}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(/C=C/C(=O)N[C@@H](C)c2cccc(Cl)c2)s1\", \"label\": 0.0, \"pred\": 1.5565900802612305}\\n',\n",
              " '{\"smiles\": \"CCOC1(C(=O)c2ccc3nc(C)ccc3c2)CCCC1\", \"label\": 0.0, \"pred\": 0.624822199344635}\\n',\n",
              " '{\"smiles\": \"CCOC1(c2nc(C(N)C(=O)O)cs2)CCCC1\", \"label\": 0.0, \"pred\": 1.3778254985809326}\\n',\n",
              " '{\"smiles\": \"CC(C)C[C@H](NCCCCc1ccc(Cl)c(Cl)c1)C(=O)O\", \"label\": 0.0, \"pred\": 0.8546751141548157}\\n',\n",
              " '{\"smiles\": \"Cc1cnc(N2CCCN2)nc1C\", \"label\": 0.0, \"pred\": 0.8509133458137512}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2cc(-c3ccccc3)ccc2N2c3ccccc3-c3ccccc3-c3cc(-c4ccccc4)cc1c32\", \"label\": 0.0, \"pred\": 0.8182119727134705}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(S(=O)(=O)N(C)c2nc(N3CCN(Cc4ccccc4)CC3)nc3ccccc23)cc1\", \"label\": 0.0, \"pred\": 0.6312434077262878}\\n',\n",
              " '{\"smiles\": \"CCNC(=O)c1ccc(S(=O)(=O)NC(=O)c2ccc(OC(=O)OC(CC)CC)nc2)cc1\", \"label\": 0.0, \"pred\": 0.5435618758201599}\\n',\n",
              " '{\"smiles\": \"C=CCN1C(N)=NCC12CCN(CC)CC2\", \"label\": 0.0, \"pred\": 1.2370799779891968}\\n',\n",
              " '{\"smiles\": \"Cn1c(-c2cccc(Cl)c2)nc(Br)c1CO\", \"label\": 0.0, \"pred\": 1.2309235334396362}\\n',\n",
              " '{\"smiles\": \"CC(C)=C(C)CC(C)CC1CCCCCCCCCCCCCC1\", \"label\": 0.0, \"pred\": 2.0186803340911865}\\n',\n",
              " '{\"smiles\": \"CC(/C=C(\\\\\\\\C)C=C(C(=O)O)C(=O)O)=C(/Cl)c1ccccc1\", \"label\": 0.0, \"pred\": 1.4338053464889526}\\n',\n",
              " '{\"smiles\": \"COC1CN(Cc2nc(Cl)ccc2Cl)CC1OC\", \"label\": 0.0, \"pred\": 0.6301942467689514}\\n',\n",
              " '{\"smiles\": \"O=C(O)CSc1cnc(NC(=O)N(CCCOc2cccc(OC(F)(F)F)c2)C2CCCCC2)s1\", \"label\": 0.0, \"pred\": 1.2773076295852661}\\n',\n",
              " '{\"smiles\": \"CC(C)c1sc(NC(=O)c2ccc(=O)[nH]n2)nc1-c1ccccc1\", \"label\": 0.0, \"pred\": 0.9019345641136169}\\n',\n",
              " '{\"smiles\": \"NC(=O)c1ccsc1NC(=O)Cn1nnc(-c2ccccc2)n1\", \"label\": 0.0, \"pred\": 1.0885341167449951}\\n',\n",
              " '{\"smiles\": \"C[Si](C)(C)N1C(=O)C2=NC(=O)N([Si](C)(C)C)C2([Si](C)(C)C)N([Si](C)(C)C)C1=O\", \"label\": 0.0, \"pred\": 1.1610357761383057}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(C(C)c2ccc(C#N)cc2)cn1\", \"label\": 0.0, \"pred\": 0.7754190564155579}\\n',\n",
              " '{\"smiles\": \"CC1=Nc2nn(C)cc2CC1\", \"label\": 0.0, \"pred\": 1.3522415161132812}\\n',\n",
              " '{\"smiles\": \"CCCC(C)Nc1ncccc1[N+](=O)[O-]\", \"label\": 0.0, \"pred\": 0.5280182957649231}\\n',\n",
              " '{\"smiles\": \"Nc1ccc(Cl)cc1-c1nc2cc(F)cc(Cl)c2o1\", \"label\": 0.0, \"pred\": 1.0636169910430908}\\n',\n",
              " '{\"smiles\": \"Cn1c(CCCNS(=O)(=O)N2CCCC2)nc2ccccc21\", \"label\": 0.0, \"pred\": 1.432379126548767}\\n',\n",
              " '{\"smiles\": \"CCCCCCCC(NC)C(OC)C(C)(C)C\", \"label\": 0.0, \"pred\": 0.3386879563331604}\\n',\n",
              " '{\"smiles\": \"CCC(C)[C@H](N)C(=O)N(C)C(C)C1CC1\", \"label\": 0.0, \"pred\": 0.651195228099823}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)CN1CCN(Cc2ccc(OC)cc2)CC1\", \"label\": 0.0, \"pred\": 0.3777446150779724}\\n',\n",
              " '{\"smiles\": \"CC(C)(C(=O)NC1CCC(=O)NC1=O)C(N)=NO\", \"label\": 0.0, \"pred\": 0.34425634145736694}\\n',\n",
              " '{\"smiles\": \"O=C(NN=Cc1ccc(O)cc1)c1c[nH]c2ccccc12\", \"label\": 0.0, \"pred\": 1.2424983978271484}\\n',\n",
              " '{\"smiles\": \"Cc1nc2ccc(-c3ccc4c(c3)CC=C(CC(=O)N3CC=C(c5ccccc5)CC3)CCO4)cc2[nH]1\", \"label\": 0.0, \"pred\": 0.7328440546989441}\\n',\n",
              " '{\"smiles\": \"CCOc1ccc(OCCCN2CCCCC2C(=O)O)cc1\", \"label\": 0.0, \"pred\": 1.0770034790039062}\\n',\n",
              " '{\"smiles\": \"COCC(N)C(=O)Nc1c(C#N)cccc1OC\", \"label\": 0.0, \"pred\": 1.4422094821929932}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2cc(=O)[nH]c(=S)n2C[C@@H](C)N)c(OC)c1\", \"label\": 0.0, \"pred\": 0.2428562194108963}\\n',\n",
              " '{\"smiles\": \"CCNC(=O)N(Cc1c(-c2ccccc2)noc1N1CCc2ccccc2C1)C[C@H]1CCCO1\", \"label\": 0.0, \"pred\": 0.9568901658058167}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)C(=CNc1ccc(F)c(Cl)c1)C(=O)OCC\", \"label\": 0.0, \"pred\": 0.9346908926963806}\\n',\n",
              " '{\"smiles\": \"COc1ccc(C)cc1S(=O)(=O)Nc1ccc(Nc2ccc(C#N)cc2)nc1\", \"label\": 0.0, \"pred\": 0.9262654185295105}\\n',\n",
              " '{\"smiles\": \"O=C(O)[C@H]1CCCN(C(=O)[C@H]2CCCN2C(=O)c2cc(Cl)ccc2Cl)C1\", \"label\": 0.0, \"pred\": 0.9219184517860413}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)cc(-c2ccc(CN(C)CC(=O)O)cc2)c1\", \"label\": 0.0, \"pred\": 0.9808363318443298}\\n',\n",
              " '{\"smiles\": \"CC1CCN(C(=O)CNC(=O)c2ccc(Cl)c(Cl)c2)C1\", \"label\": 0.0, \"pred\": 0.9164342284202576}\\n',\n",
              " '{\"smiles\": \"CSCC(=O)N1CCCC(C)(C)CC1\", \"label\": 0.0, \"pred\": 0.6004166007041931}\\n',\n",
              " '{\"smiles\": \"COc1ccc(S(=O)(=O)Nc2ccnc(Cl)n2)cc1\", \"label\": 0.0, \"pred\": 0.7162829041481018}\\n',\n",
              " '{\"smiles\": \"CONC(=O)CC(O)c1ccc(Cl)cc1\", \"label\": 0.0, \"pred\": 1.2030775547027588}\\n',\n",
              " '{\"smiles\": \"C=C1CC2(CCC(OC)C(C)C2)C(=O)C1=C\", \"label\": 0.0, \"pred\": 1.0785853862762451}\\n',\n",
              " '{\"smiles\": \"COC(=O)CNC(=O)COC(=O)c1cc2c(C)nn(-c3ccc(F)cc3)c2s1\", \"label\": 0.0, \"pred\": 1.1534888744354248}\\n',\n",
              " '{\"smiles\": \"COCCOCCCOCc1ccc(C(=O)O)cc1C\", \"label\": 0.0, \"pred\": 0.7768688797950745}\\n',\n",
              " '{\"smiles\": \"O=C(C1CCCO1)N1CCOc2ccc(CN3CCCCC3)cc2C1\", \"label\": 0.0, \"pred\": 0.6931282877922058}\\n',\n",
              " '{\"smiles\": \"CC(C)n1c(CCNC(=O)c2ccc(Br)o2)nc2ccccc21\", \"label\": 0.0, \"pred\": 0.7964361310005188}\\n',\n",
              " '{\"smiles\": \"CNC(=O)CSC1=NC=NC(=O)C1I\", \"label\": 0.0, \"pred\": 0.7150186896324158}\\n',\n",
              " '{\"smiles\": \"CCCNC(c1cncc(Br)c1)c1ccc(Cl)c(OC)c1\", \"label\": 0.0, \"pred\": 1.0798392295837402}\\n',\n",
              " '{\"smiles\": \"COc1ccccc1CNC(=O)COC(=O)c1cc(O)c2ccccc2c1O\", \"label\": 0.0, \"pred\": 1.1791486740112305}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(C)c(NC(=O)C(C#N)=Cc2c(-c3ccccc3)[nH]c3ccccc23)c1\", \"label\": 0.0, \"pred\": 1.0203132629394531}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)C1=C(C)N(c2ccccc2)C(=O)N[C@@H]1c1cccc([N+](=O)[O-])c1\", \"label\": 0.0, \"pred\": 0.49504727125167847}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(N2C(=O)C(=O)/C(=C(\\\\\\\\O)c3ccc4c(c3)CCO4)C2c2cccc(OC(C)C)c2)cc1C\", \"label\": 0.0, \"pred\": 0.7124068140983582}\\n',\n",
              " '{\"smiles\": \"CCN/C(=N\\\\\\\\CCCCn1ccccc1=O)N1CC[C@@H](O)C1\", \"label\": 0.0, \"pred\": 1.0227940082550049}\\n',\n",
              " '{\"smiles\": \"COc1ccc(CCN2C(=O)C(SC(C)C)=C(c3cccs3)C2=O)cc1\", \"label\": 0.0, \"pred\": 1.2184542417526245}\\n',\n",
              " '{\"smiles\": \"CCNCC1CCN(C(COC)C(C)C)C1\", \"label\": 0.0, \"pred\": 0.3078894019126892}\\n',\n",
              " '{\"smiles\": \"CCc1cc(C(C#N)Cc2cc(F)ccc2OC)ccc1OC\", \"label\": 0.0, \"pred\": 0.9723995327949524}\\n',\n",
              " '{\"smiles\": \"Cn1nc(C(=O)N2CCC[C@@H](C(=O)NC3CC3)C2)c2c1CCN(C(=O)c1ccccc1F)C2\", \"label\": 0.0, \"pred\": 0.6747097373008728}\\n',\n",
              " '{\"smiles\": \"C=CC=CC(=C)c1cc(C=O)ccc1N\", \"label\": 0.0, \"pred\": 1.128245234489441}\\n',\n",
              " '{\"smiles\": \"CCN(CC#N)C(=O)[C@@H](C)c1ccc2cc(OC)ccc2c1\", \"label\": 0.0, \"pred\": 1.3750824928283691}\\n',\n",
              " '{\"smiles\": \"N#CC(C(=O)c1ccc([N+](=O)[O-])cc1)c1ccc(F)cc1\", \"label\": 0.0, \"pred\": 0.35623735189437866}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc(-c2nnc(SCCN3CCOC3=O)n2C2CCCC2)cc1\", \"label\": 0.0, \"pred\": 0.8867174983024597}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(-n2nnc(C(=O)N3CCC4(CCC4)C3)c2C)c1\", \"label\": 0.0, \"pred\": 0.8810946345329285}\\n',\n",
              " '{\"smiles\": \"CC1CCCCC1OCC(O)CNOCc1ccccc1\", \"label\": 0.0, \"pred\": 1.2140748500823975}\\n',\n",
              " '{\"smiles\": \"COC(=O)c1ccc(-c2ccc(-c3ncc(N4CCN(CCc5ccccc5C)CC4)cn3)cc2)cc1C1=CCNCC1\", \"label\": 0.0, \"pred\": 0.7520326972007751}\\n',\n",
              " '{\"smiles\": \"CCCNC(C1=CCCCCC1)c1ccncc1C\", \"label\": 0.0, \"pred\": 0.9296985268592834}\\n',\n",
              " '{\"smiles\": \"CCCCCCCCOC(=O)/C(C#N)=C\\\\\\\\c1ccc(OCC(N)=O)cc1\", \"label\": 0.0, \"pred\": 1.1339701414108276}\\n',\n",
              " '{\"smiles\": \"CCC(Sc1ccc(Cl)cc1)C(=O)NCCC1=CCCCC1\", \"label\": 0.0, \"pred\": 1.2474002838134766}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)C(Sc1ccc(F)c(Cl)c1)c1ccccc1\", \"label\": 0.0, \"pred\": 0.9237802624702454}\\n',\n",
              " '{\"smiles\": \"CCCCCC(C)NCCCC(C)(C)C(N)=NO\", \"label\": 0.0, \"pred\": 1.5162901878356934}\\n',\n",
              " '{\"smiles\": \"CC1CN(CC(=O)NCc2cccs2)c2ccccc2NC1=O\", \"label\": 0.0, \"pred\": 0.6539999842643738}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(/N=C/C23c4ccccc4C(c4ccccc42)[C@@H]2C(=O)N(c4ccc(C)cc4C)C(=O)[C@@H]23)c(C)c1\", \"label\": 0.0, \"pred\": 0.9392494559288025}\\n',\n",
              " '{\"smiles\": \"O=C(CSc1nnc2ccc(-c3ccco3)nn12)Nc1ccc(F)cc1F\", \"label\": 0.0, \"pred\": 0.6520870327949524}\\n',\n",
              " '{\"smiles\": \"COCCN/C(=N\\\\\\\\Cc1nnc(C)n1C)NCC(C)(C)N1CCOCC1\", \"label\": 0.0, \"pred\": 0.9114904999732971}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(C)c(NC(=O)c2ccc(-c3cc4ccccc4oc3=O)cc2)c1\", \"label\": 0.0, \"pred\": 1.0950154066085815}\\n',\n",
              " '{\"smiles\": \"CCc1ccc(NC(=O)C(C(C)C)N2CCCC(C)C2)cc1N\", \"label\": 0.0, \"pred\": 0.8198681473731995}\\n',\n",
              " '{\"smiles\": \"CC(=O)NC(CC(=O)OCC(=O)Nc1ccc(C)cc1[N+](=O)[O-])c1ccc(Cl)cc1\", \"label\": 0.0, \"pred\": 0.8596231341362}\\n',\n",
              " '{\"smiles\": \"CC(=O)N(CCNC(=O)c1ccc(C)c(C)c1)C1CC1\", \"label\": 0.0, \"pred\": 1.049426794052124}\\n',\n",
              " '{\"smiles\": \"OCCn1ncc2c1CCCC2NC1CCCCCCC1\", \"label\": 0.0, \"pred\": 1.4082667827606201}\\n',\n",
              " '{\"smiles\": \"CCCCCC(O)(COc1ccc(F)cc1)CS[C@H]1C(O)CC(=O)[C@@H]1CCCCCCC(=O)O\", \"label\": 0.0, \"pred\": 0.9724997878074646}\\n',\n",
              " '{\"smiles\": \"COc1ccc(Br)c(NC(=O)c2csc(CCN)n2)c1\", \"label\": 0.0, \"pred\": 0.6819536089897156}\\n',\n",
              " '{\"smiles\": \"CSc1ccc(COC(=O)c2ccc(S(=O)(=O)N3CCN(C(C)=O)CC3)cc2)cc1\", \"label\": 0.0, \"pred\": 0.4667019248008728}\\n',\n",
              " '{\"smiles\": \"CC(=O)N(c1nc(COC(=O)CNC(=O)c2ccc(C)c(C)c2)cs1)c1ccccc1F\", \"label\": 0.0, \"pred\": 0.8901028037071228}\\n',\n",
              " '{\"smiles\": \"CCSCCSCCO\", \"label\": 0.0, \"pred\": 0.3773919939994812}\\n',\n",
              " '{\"smiles\": \"COc1ccc(S(=O)(=O)N2CCOCC2)cc1NC(=O)COc1ccccc1-c1ccccc1\", \"label\": 0.0, \"pred\": 1.055816411972046}\\n',\n",
              " '{\"smiles\": \"CCC(Oc1ccccc1C)C(=O)NCc1ccccc1Cl\", \"label\": 0.0, \"pred\": 1.0410099029541016}\\n',\n",
              " '{\"smiles\": \"O=Cc1cc(O)n(O)c1O\", \"label\": 0.0, \"pred\": 0.8519220352172852}\\n',\n",
              " '{\"smiles\": \"CN(CCCNC(=O)CCc1nc2cc(S(=O)(=O)N3CCCCC3)ccc2n1C)c1ccccc1\", \"label\": 0.0, \"pred\": 0.7292870879173279}\\n',\n",
              " '{\"smiles\": \"O=S(=O)(Cc1cccc(C(F)(F)F)c1)c1ncn[nH]1\", \"label\": 0.0, \"pred\": 0.7117418646812439}\\n',\n",
              " '{\"smiles\": \"CCc1ccc([C@H](C)NC(=O)CN(c2ccccc2Br)S(C)(=O)=O)cc1\", \"label\": 0.0, \"pred\": 1.0089186429977417}\\n',\n",
              " '{\"smiles\": \"COc1cc(N(CC(=O)Nc2c(C)cccc2C)C(C)=O)cc(OC)c1OC\", \"label\": 0.0, \"pred\": 1.0368973016738892}\\n',\n",
              " '{\"smiles\": \"CCN(Cc1ccccc1)C(=O)COc1ccccc1C(=O)Nc1ccccc1\", \"label\": 0.0, \"pred\": 0.9282383322715759}\\n',\n",
              " '{\"smiles\": \"CC(C(=O)O)N(C)Cc1cn(-c2ccccc2)nc1C(C)(C)C\", \"label\": 0.0, \"pred\": 0.9191222786903381}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)cc(N2CCC(=O)NC3(CCCC3)C2=O)c1\", \"label\": 0.0, \"pred\": 0.8652034401893616}\\n',\n",
              " '{\"smiles\": \"COc1ccc(CNNC(=O)NCN2C(=O)CCNC2=O)cc1\", \"label\": 0.0, \"pred\": 0.8874115347862244}\\n',\n",
              " '{\"smiles\": \"Cc1ccc([N+](=O)[O-])cc1NC(=O)CCN1C(=O)[C@H]2CC=CC[C@@H]2C1=O\", \"label\": 0.0, \"pred\": 0.47973698377609253}\\n',\n",
              " '{\"smiles\": \"COc1ccc(/N=C(/Cc2ccccc2)N(C)C)cc1\", \"label\": 0.0, \"pred\": 0.8870865702629089}\\n',\n",
              " '{\"smiles\": \"CC(=O)N1CCc2cc(-c3csc(NC(=O)CCc4ccccc4)n3)ccc21\", \"label\": 0.0, \"pred\": 1.3336493968963623}\\n',\n",
              " '{\"smiles\": \"COCOCCOc1cc(CC2CCNCC2)ccc1Br\", \"label\": 0.0, \"pred\": 0.9903218150138855}\\n',\n",
              " '{\"smiles\": \"CO[C@]1(c2ccccc2)CO[C@@](OC)(c2ccccc2)CO1\", \"label\": 0.0, \"pred\": 1.246062159538269}\\n',\n",
              " '{\"smiles\": \"CCc1ccc(CNOC(C)CO)c(Cl)c1\", \"label\": 0.0, \"pred\": 0.9563384056091309}\\n',\n",
              " '{\"smiles\": \"Cn1nccc1NC(=O)C1CCC(CN)O1\", \"label\": 0.0, \"pred\": 1.2415916919708252}\\n',\n",
              " '{\"smiles\": \"CC(=O)NCc1ccc(-c2csc(NC(=O)Cc3c(C)nn(CC(C)C)c3C)n2)o1\", \"label\": 0.0, \"pred\": 1.6277891397476196}\\n',\n",
              " '{\"smiles\": \"CC(C)C1C2C(CCC3C4CC(C5C6CCC(C6)C45)C31)C1CC2C2C3CCC(C3)C12\", \"label\": 0.0, \"pred\": 0.6024126410484314}\\n',\n",
              " '{\"smiles\": \"CC1(C)C(Cn2ccnc2NC2CC2)C1(C)C\", \"label\": 0.0, \"pred\": 1.5156344175338745}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(NC(=O)c2ccnc(C(=O)NCCN3CCOCC3)c2)cc1C\", \"label\": 0.0, \"pred\": 0.3545076251029968}\\n',\n",
              " '{\"smiles\": \"CCO[C@H]1CCOC2(C1)CN(S(=O)(=O)C(C)C)C2\", \"label\": 0.0, \"pred\": 0.5693482756614685}\\n',\n",
              " '{\"smiles\": \"Cc1ncsc1C(=O)N1CCc2cc(C(=O)O)ccc21\", \"label\": 0.0, \"pred\": 0.7692763209342957}\\n',\n",
              " '{\"smiles\": \"COc1ccc2oc(C(=O)Nc3ccc(F)c(CNc4cccnc4N)c3)c(C)c2c1\", \"label\": 0.0, \"pred\": 0.8012902140617371}\\n',\n",
              " '{\"smiles\": \"CCN(CC)CCNc1nnnc2ccc(Cl)cc12\", \"label\": 0.0, \"pred\": 1.0994899272918701}\\n',\n",
              " '{\"smiles\": \"CCOc1c(Br)cc(Br)cc1/C=C(/C#N)C(=O)Nc1ccc([N+](=O)[O-])cc1C\", \"label\": 0.0, \"pred\": 1.1814393997192383}\\n',\n",
              " '{\"smiles\": \"C=C(C)C(=O)OCCNC(=O)Nc1cccc2c(NC(C)=O)cccc12\", \"label\": 0.0, \"pred\": 1.018317699432373}\\n',\n",
              " '{\"smiles\": \"Cc1ccccc1Cn1ccc(NC(=S)Nc2cnn(C)c2C(=O)N2CCCCC2)n1\", \"label\": 0.0, \"pred\": 0.3297986388206482}\\n',\n",
              " '{\"smiles\": \"CCCCOCCN1C(=O)CNC1CC\", \"label\": 0.0, \"pred\": 0.5064745545387268}\\n',\n",
              " '{\"smiles\": \"C[C@@]1(c2ccc3c(c2)OCO3)NC(=O)N(Cc2ncc(-c3ccc(Cl)cc3)o2)C1=O\", \"label\": 0.0, \"pred\": 0.6972853541374207}\\n',\n",
              " '{\"smiles\": \"CC[C@H](C)CN(CC(=O)N1CCc2sccc2[C@@H]1COc1ccc(C)cc1)C(=O)C1CCCC1\", \"label\": 0.0, \"pred\": 1.2249720096588135}\\n',\n",
              " '{\"smiles\": \"NC1CCC(Nc2cccnn2)C1\", \"label\": 0.0, \"pred\": 0.8532918095588684}\\n',\n",
              " '{\"smiles\": \"CN1CCN(C)C(CNC(=O)C(C)(C)C(N)=NO)C1\", \"label\": 0.0, \"pred\": 0.6917988657951355}\\n',\n",
              " '{\"smiles\": \"Cc1[nH]cnc1C=C1C(=O)Nc2ccc(F)c(C#C[C@H](C)O)c21\", \"label\": 0.0, \"pred\": 0.9921013712882996}\\n',\n",
              " '{\"smiles\": \"CCNc1nc(C)cc(Nc2ccc(NC(=O)Nc3cccc(C(F)(F)F)c3)cc2)n1\", \"label\": 0.0, \"pred\": 0.6964086890220642}\\n',\n",
              " '{\"smiles\": \"CCOc1cc(C(=O)N(C)Cc2ccccc2[N+](=O)[O-])c([N+](=O)[O-])cc1OC\", \"label\": 0.0, \"pred\": 0.5387560725212097}\\n',\n",
              " '{\"smiles\": \"Cc1cc([C@H]2[C@H](c3ccccn3)NC(=S)N2c2ccc(N(C)C)cc2)c(C)n1Cc1ccccc1\", \"label\": 0.0, \"pred\": 0.15062041580677032}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)N1CC(NC(=O)C2CCC(=O)CC2)CC1=O\", \"label\": 0.0, \"pred\": 0.6078640818595886}\\n',\n",
              " '{\"smiles\": \"CC(Cc1ccccc1)c1ccccc1OC(=O)Oc1ccccc1C(C)Cc1ccccc1\", \"label\": 0.0, \"pred\": 0.7286414504051208}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C2CNCCN2)sc1C\", \"label\": 0.0, \"pred\": 1.6570639610290527}\\n',\n",
              " '{\"smiles\": \"O=C1CCCCC1C1CCCN1C(=O)c1n[nH]c2ccc(Br)cc12\", \"label\": 0.0, \"pred\": 0.9188453555107117}\\n',\n",
              " '{\"smiles\": \"NCCC(=O)Nc1ccccc1-n1cnnn1\", \"label\": 0.0, \"pred\": 0.8407836556434631}\\n',\n",
              " '{\"smiles\": \"COCC1CCCN(S(=O)(=O)c2ccc(CCl)cn2)C1\", \"label\": 0.0, \"pred\": 0.8612815737724304}\\n',\n",
              " '{\"smiles\": \"CCC1=C(C[C@H]2NCCc3cc(OC)c(OC)cc32)C[C@@H]2c3ccccc3CCN2C1\", \"label\": 0.0, \"pred\": 0.7339362502098083}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)[C@H]1NC(=S)N(c3ccccc3)[C@@](C)(O2)[C@@H]1C(=O)Nc1ccc(Cl)cc1\", \"label\": 0.0, \"pred\": 0.2572585940361023}\\n',\n",
              " '{\"smiles\": \"CCCc1nc(C2(OCC)CCC(C)CC2)nc(N)c1Br\", \"label\": 0.0, \"pred\": 0.7568355202674866}\\n',\n",
              " '{\"smiles\": \"c1ccc(-n2c(C3CCCC3)nc3c2CCNC3)cc1\", \"label\": 0.0, \"pred\": 0.7376277446746826}\\n',\n",
              " '{\"smiles\": \"CN(C)CCNC(=S)SC(C)(C)[C@H](NC(=O)c1ccc(F)cc1)C(=O)O\", \"label\": 0.0, \"pred\": 0.44252079725265503}\\n',\n",
              " '{\"smiles\": \"CCCCOc1ccc(C(=O)NCC(=O)N/N=C/c2cccc(OC(=O)c3ccc(Cl)cc3)c2)cc1\", \"label\": 0.0, \"pred\": 0.8313953280448914}\\n',\n",
              " '{\"smiles\": \"Cn1c2c(/c(=N\\\\\\\\C(=O)c3cccc(C(F)(F)F)c3F)n1-c1ccccc1)CSC2\", \"label\": 0.0, \"pred\": 0.9114165902137756}\\n',\n",
              " '{\"smiles\": \"CC1(C(=O)NC2(C(N)=NO)CCCCCC2)CCCC1\", \"label\": 0.0, \"pred\": 0.981170117855072}\\n',\n",
              " '{\"smiles\": \"CCCCOc1ccc2c(OCCCC)c(O)c(=O)[nH]c2c1\", \"label\": 0.0, \"pred\": 1.136672019958496}\\n',\n",
              " '{\"smiles\": \"CNC(=O)Nc1cn2nc(-c3ccccc3C)ccc2n1\", \"label\": 0.0, \"pred\": 0.8549239039421082}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(CC(=O)NN)cc1C\", \"label\": 0.0, \"pred\": 1.2269409894943237}\\n',\n",
              " '{\"smiles\": \"Nc1cccc(OCCCN2CCCC3C(=O)NCC32)c1\", \"label\": 0.0, \"pred\": 1.041685700416565}\\n',\n",
              " '{\"smiles\": \"C=CC1(O)CCOC(C)(CC)C1\", \"label\": 0.0, \"pred\": 1.4936758279800415}\\n',\n",
              " '{\"smiles\": \"C[C@H]1[C@@H](Nc2ccc(-c3ccc4[nH]ccc4c3)nc2)C2CCN1CC2\", \"label\": 0.0, \"pred\": 0.9686481356620789}\\n',\n",
              " '{\"smiles\": \"O=C(NCC1COC2(CCCCC2)O1)N1CCCC(c2ccn[nH]2)C1\", \"label\": 0.0, \"pred\": 1.2181838750839233}\\n',\n",
              " '{\"smiles\": \"CC(Sc1nc(N)cc(=O)[nH]1)C(=O)Nc1ccccc1Cl\", \"label\": 0.0, \"pred\": 0.8805504441261292}\\n',\n",
              " '{\"smiles\": \"CCN1CC(=NS(=O)(=O)N=C2CN(CC)C(=O)N2CC)N(CC)C1=O\", \"label\": 0.0, \"pred\": 0.841805636882782}\\n',\n",
              " '{\"smiles\": \"CCCCOC(CCCCO)[C@@H](O)CC1CCCCC1\", \"label\": 0.0, \"pred\": 0.3846129775047302}\\n',\n",
              " '{\"smiles\": \"COc1ccc(Cl)cc1NC(=O)C(C)Sc1nnc(N2CCOCC2)n1-c1cccc(C)c1\", \"label\": 0.0, \"pred\": 0.381570041179657}\\n',\n",
              " '{\"smiles\": \"CC(Br)C1(Cc2ccc(F)c(F)c2)CC1\", \"label\": 0.0, \"pred\": 0.9037043452262878}\\n',\n",
              " '{\"smiles\": \"COc1cc(Cl)c(C)cc1NC(=O)C(C)OC(=O)c1ccc2c(c1N)C(=O)c1ccccc1C2=O\", \"label\": 0.0, \"pred\": 0.6392366290092468}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(F)cc1C(C)Cl\", \"label\": 0.0, \"pred\": 0.8772248029708862}\\n',\n",
              " '{\"smiles\": \"O=C(NC1CCN(CC(F)(F)F)CC1)N1CC[C@@H](O)[C@H](C2CCCC2)C1\", \"label\": 0.0, \"pred\": 0.5513696074485779}\\n',\n",
              " '{\"smiles\": \"CCOc1ccccc1CC(C)(N)C(=O)OC\", \"label\": 0.0, \"pred\": 1.087167739868164}\\n',\n",
              " '{\"smiles\": \"COc1ccc2c(CC(=O)OC(C)C(=O)Nc3cccnc3Cl)coc2c1\", \"label\": 0.0, \"pred\": 1.2068891525268555}\\n',\n",
              " '{\"smiles\": \"C/N=C(\\\\\\\\NCC1(C)CCCS1)NCC1(N(C)C)CCOCC1\", \"label\": 0.0, \"pred\": 0.9433643221855164}\\n',\n",
              " '{\"smiles\": \"Cc1cc(CNC(C)(C)C)cc(C)c1OCCOCCO\", \"label\": 0.0, \"pred\": 0.965411365032196}\\n',\n",
              " '{\"smiles\": \"CC(=O)OCC1=C(C(=O)O)N2C(=O)[C@H](OC(=O)CSC(F)(F)F)[C@H]2SC1\", \"label\": 0.0, \"pred\": 0.9799944758415222}\\n',\n",
              " '{\"smiles\": \"Cc1c(C(=O)NCCC(C)C)oc2c1/C(=N/NC(N)=O)CCC2\", \"label\": 0.0, \"pred\": 2.192769765853882}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)Cn1ccc(=O)c2cc(C)c(Cl)cc21\", \"label\": 0.0, \"pred\": 0.8372926712036133}\\n',\n",
              " '{\"smiles\": \"C[C@@H]1[C@H](NC(=O)C(F)(F)F)CCCN1Cc1ccc(C(=O)O)cc1\", \"label\": 0.0, \"pred\": 0.6304407715797424}\\n',\n",
              " '{\"smiles\": \"CC(C)CNc1nc(N)c(C(=O)N2CCC(CN)C2)s1\", \"label\": 0.0, \"pred\": 1.1294169425964355}\\n',\n",
              " '{\"smiles\": \"Cc1cc(CNc2c(C)cccc2Cl)ccc1Br\", \"label\": 0.0, \"pred\": 0.8189120292663574}\\n',\n",
              " '{\"smiles\": \"CCC(C#N)NC(=O)C1C(C)(C)C1(C)C\", \"label\": 0.0, \"pred\": 0.5763822197914124}\\n',\n",
              " '{\"smiles\": \"CC1(CNCC(=O)Nc2ccc(F)cc2)COC1\", \"label\": 0.0, \"pred\": 0.9205474257469177}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)CCN1c2ccccc2N(Cc2cccc(Cl)c2Cl)C[C@H]1c1cccc(C(F)(F)F)c1\", \"label\": 0.0, \"pred\": 0.4641799330711365}\\n',\n",
              " '{\"smiles\": \"O=C(O)C1CCC(NC(=O)N2CCCC2CCCc2ccccc2)CC1\", \"label\": 0.0, \"pred\": 1.2932281494140625}\\n',\n",
              " '{\"smiles\": \"CSC[C@H]1CCN([C@H](C(N)=O)c2cccc(Br)c2)C1\", \"label\": 0.0, \"pred\": 0.914411723613739}\\n',\n",
              " '{\"smiles\": \"CCC(Nc1ccc2cn[nH]c2c1)c1ccc(C)cc1\", \"label\": 0.0, \"pred\": 0.9456835389137268}\\n',\n",
              " '{\"smiles\": \"CNC(Cc1cccc(Cl)c1)C(OC)OC\", \"label\": 0.0, \"pred\": 1.1472675800323486}\\n',\n",
              " '{\"smiles\": \"CCOC1(c2ncc3c(n2)CCCC3=O)CCOCC1\", \"label\": 0.0, \"pred\": 0.5583484768867493}\\n',\n",
              " '{\"smiles\": \"NC(=O)c1ccccc1Cn1ccc(C(F)(F)F)n1\", \"label\": 0.0, \"pred\": 0.46740835905075073}\\n',\n",
              " '{\"smiles\": \"CC(C)Cc1c2c3c(cccc3c3ccccc13)-c1cc3cc4ccccc4cc3cc1-2\", \"label\": 0.0, \"pred\": 1.1199432611465454}\\n',\n",
              " '{\"smiles\": \"COc1cc(OC)cc(C(=O)NC(C)c2ccc(Cl)cc2Cl)c1\", \"label\": 0.0, \"pred\": 1.0901497602462769}\\n',\n",
              " '{\"smiles\": \"Cc1c(Cc2cc3ccccc3s2)cc([C@@H]2O[C@H](CO)[C@@H](O)[C@H](O)[C@H]2O)c(O)c1O\", \"label\": 0.0, \"pred\": 0.746435821056366}\\n',\n",
              " '{\"smiles\": \"[C-]#[N+]C(=Cc1ccc(-c2ccc3c(c2)c2ccccc2n3-c2ccc(-n3c4ccccc4c4ccccc43)cc2)o1)C(=O)O\", \"label\": 0.0, \"pred\": 0.7320405840873718}\\n',\n",
              " '{\"smiles\": \"CC1(O)C(n2cnc3c(C(N)=O)ncnc32)OC(CO)[C@H]1O\", \"label\": 0.0, \"pred\": 1.4116194248199463}\\n',\n",
              " '{\"smiles\": \"CNc1nc(N)c(C(=O)NC(C)c2ccncc2)s1\", \"label\": 0.0, \"pred\": 1.268190860748291}\\n',\n",
              " '{\"smiles\": \"O=C1C(=O)N(c2ccc(OC(F)(F)F)cc2)C(c2ccccc2)/C1=C(\\\\\\\\O)c1ccc(F)cc1\", \"label\": 0.0, \"pred\": 0.369931161403656}\\n',\n",
              " '{\"smiles\": \"CCCn1cc(Oc2ccc(C(=O)O)cc2N)cn1\", \"label\": 0.0, \"pred\": 0.7916397452354431}\\n',\n",
              " '{\"smiles\": \"Cc1cc(F)ccc1C1CCCN1C(=O)NCCCC(=O)O\", \"label\": 0.0, \"pred\": 1.310319423675537}\\n',\n",
              " '{\"smiles\": \"COc1ccc(SC(C)C(=O)Nc2ccc(F)cc2F)cc1\", \"label\": 0.0, \"pred\": 1.0320295095443726}\\n',\n",
              " '{\"smiles\": \"Cc1nc(COc2ccc(F)cc2)sc1C(=O)NCC(C)(C)N\", \"label\": 0.0, \"pred\": 1.0631864070892334}\\n',\n",
              " '{\"smiles\": \"CC(C)N(CCSC(F)(F)F)CC(=O)O\", \"label\": 0.0, \"pred\": 0.3238987326622009}\\n',\n",
              " '{\"smiles\": \"CC(OC(=O)[C@@H](C)Oc1ccc(F)cc1)c1ccccc1\", \"label\": 0.0, \"pred\": 1.1393473148345947}\\n',\n",
              " '{\"smiles\": \"CC(NC(=O)COc1ccc(Cl)cc1)c1ccccc1N\", \"label\": 0.0, \"pred\": 0.7454795241355896}\\n',\n",
              " '{\"smiles\": \"COc1ccc(-c2c(-c3ccccc3)oc3ncnc(N[C@H]4CCC[C@H](OCCc5nn[nH]n5)C4)c23)cc1\", \"label\": 0.0, \"pred\": 0.9051396250724792}\\n',\n",
              " '{\"smiles\": \"Clc1cc(Cl)c2nnc(SCc3nc4ccccc4c4ccccc34)n2c1\", \"label\": 0.0, \"pred\": 0.5275443196296692}\\n',\n",
              " '{\"smiles\": \"CN(Cc1ccccc1CN)C(=O)C1(C)CCCO1\", \"label\": 0.0, \"pred\": 1.0438841581344604}\\n',\n",
              " '{\"smiles\": \"COc1ccc(S(=O)(=O)N2CCc3ccccc32)cc1C(=O)Nc1cc(F)cc(N2CCCC2)c1\", \"label\": 0.0, \"pred\": 0.5157472491264343}\\n',\n",
              " '{\"smiles\": \"CN(Cc1ccccc1)C(=O)c1ccc(N)cc1N\", \"label\": 0.0, \"pred\": 1.2550861835479736}\\n',\n",
              " '{\"smiles\": \"CCCOc1ccc(C(=O)Oc2ccc(/C=N\\\\\\\\NC(=O)CNC(=O)c3cc(OC)c(OC)c(OC)c3)cc2)cc1\", \"label\": 0.0, \"pred\": 0.8073803782463074}\\n',\n",
              " '{\"smiles\": \"CCCCCCCc1ccc(OC(F)(F)c2ccc(C(F)(F)Oc3ccc(CCCCCCC)cc3)cc2)cc1\", \"label\": 0.0, \"pred\": 0.8448869585990906}\\n',\n",
              " '{\"smiles\": \"CNCC(=O)Nc1ccc2c(c1O)C(O)=C1C(=O)[C@]3(O)C(O)=C(C(N)=O)C(=O)[C@@H](N(C)C)C3CC1C2\", \"label\": 0.0, \"pred\": 0.665813148021698}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)C(C(=O)N(CCO)C1CCCC1)C(C)(C)C\", \"label\": 0.0, \"pred\": 0.5309886336326599}\\n',\n",
              " '{\"smiles\": \"N#CCC(C#N)C(N)=O\", \"label\": 0.0, \"pred\": 0.7304545044898987}\\n',\n",
              " '{\"smiles\": \"O=C(O)CCC(=O)n1c(C(=O)O)cc2cccc(Cl)c21\", \"label\": 0.0, \"pred\": 0.6293618083000183}\\n',\n",
              " '{\"smiles\": \"CCOc1ccc(N(CC(=O)NCc2ccccc2-n2ccnc2C)S(=O)(=O)c2ccc(F)cc2)cc1\", \"label\": 0.0, \"pred\": 0.5724563002586365}\\n',\n",
              " '{\"smiles\": \"CCCC(CCO)CNC(C)c1cc(Br)cs1\", \"label\": 0.0, \"pred\": 1.3082133531570435}\\n',\n",
              " '{\"smiles\": \"CC1CCN(S(=O)(=O)Cc2cccc(C(F)(F)F)c2)CC1n1ccnc1\", \"label\": 0.0, \"pred\": 1.4179964065551758}\\n',\n",
              " '{\"smiles\": \"CCCC(=O)N1CCC2(CC1)CC(C(N)=O)=NO2\", \"label\": 0.0, \"pred\": 1.102481484413147}\\n',\n",
              " '{\"smiles\": \"COCCC(C)S(=O)(=O)c1cc(C(=O)O)cc(Br)c1C\", \"label\": 0.0, \"pred\": 0.6834045052528381}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(C)c1NC(=O)CCN(CC(=O)Nc1c(C)cccc1C)C1CC1\", \"label\": 0.0, \"pred\": 1.1987866163253784}\\n',\n",
              " '{\"smiles\": \"CNS(=O)(=O)c1cccc(C(=O)NC(C)CN2CCOCC2)c1\", \"label\": 0.0, \"pred\": 0.4697675108909607}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c(C(NN)c2ccc(F)c(C)c2)c(C)c1\", \"label\": 0.0, \"pred\": 0.7340981364250183}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)C(CN)Nc1cccnn1\", \"label\": 0.0, \"pred\": 0.6201386451721191}\\n',\n",
              " '{\"smiles\": \"COc1ccccc1C1CNCCN1C(=O)[C@@H](C)N\", \"label\": 0.0, \"pred\": 1.2693681716918945}\\n',\n",
              " '{\"smiles\": \"CCOCC(C)CS(=O)(=O)N1CCC(n2ccnc2)CC1\", \"label\": 0.0, \"pred\": 1.2021551132202148}\\n',\n",
              " '{\"smiles\": \"CCCCNC(=O)[C@@H](CC)N(Cc1ccc(Cl)cc1Cl)C(=O)CN(c1ccccc1F)S(=O)(=O)c1ccccc1\", \"label\": 0.0, \"pred\": 0.8424059748649597}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)OC(=O)c1cccc(NC(c2cccnc2)c2ccc(OC(F)F)c(OCC3CC3)n2)c1\", \"label\": 0.0, \"pred\": 0.7648434042930603}\\n',\n",
              " '{\"smiles\": \"CCN(C(=O)c1sc(NC)nc1N)C(C)COC\", \"label\": 0.0, \"pred\": 1.2249864339828491}\\n',\n",
              " '{\"smiles\": \"CCCNC1CCC2CN(S(=O)(=O)c3ccc(C(F)(F)F)cc3)CC21\", \"label\": 0.0, \"pred\": 0.43303269147872925}\\n',\n",
              " '{\"smiles\": \"O=C(c1cc(Cl)nc(Cl)c1)N1CCCCCC1CO\", \"label\": 0.0, \"pred\": 0.5803855061531067}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(-n2nc(C)c(CCC(=O)NC3CC3)c2Oc2ccccc2C)c1\", \"label\": 0.0, \"pred\": 0.7981180548667908}\\n',\n",
              " '{\"smiles\": \"CNC(C)c1cc(F)c(C)cc1Oc1cccc(F)c1F\", \"label\": 0.0, \"pred\": 0.8835325837135315}\\n',\n",
              " '{\"smiles\": \"CNC(=O)CCNCc1cc(Br)ccc1OC\", \"label\": 0.0, \"pred\": 1.1175047159194946}\\n',\n",
              " '{\"smiles\": \"CCOC(=O)c1cnn(C)c1CS(=O)Cc1ccccc1\", \"label\": 0.0, \"pred\": 1.0154988765716553}\\n',\n",
              " '{\"smiles\": \"COc1ncnc(N2CCc3ccc(N)cc3C2)c1C\", \"label\": 0.0, \"pred\": 1.0404713153839111}\\n',\n",
              " '{\"smiles\": \"CC(=O)c1ccc(NC(=O)CSc2nnc(CNc3ccc(C)cc3)n2-c2ccc(Cl)cc2)cc1\", \"label\": 0.0, \"pred\": 0.5267049670219421}\\n',\n",
              " '{\"smiles\": \"CC1CCNC1CN1CCN(C)c2ccccc21\", \"label\": 0.0, \"pred\": 0.7702423334121704}\\n',\n",
              " '{\"smiles\": \"O=C(Nc1ccc(Cl)cc1)Nc1ccc(-c2ccccc2)cc1\", \"label\": 0.0, \"pred\": 0.991609513759613}\\n',\n",
              " '{\"smiles\": \"NCc1nc(-c2cc3c(c(Cl)c2O)CCC3)no1\", \"label\": 0.0, \"pred\": 1.0745793581008911}\\n',\n",
              " '{\"smiles\": \"CCc1coc(C)n1\", \"label\": 0.0, \"pred\": 1.224820613861084}\\n',\n",
              " '{\"smiles\": \"Cc1cn2cc(-c3cc(=O)n4cc(N5CCN(C)CC5)ncc4n3)cc(C)c2n1\", \"label\": 0.0, \"pred\": 0.8551188111305237}\\n',\n",
              " '{\"smiles\": \"COc1cc2c(cc1OC)CN(C(=O)c1cccc(C(=O)NC(C)(C)C)c1)CC2\", \"label\": 0.0, \"pred\": 0.4971279501914978}\\n',\n",
              " '{\"smiles\": \"COC(=O)c1sccc1NC(=O)CCC(=O)n1ccc2ccccc21\", \"label\": 0.0, \"pred\": 1.2954810857772827}\\n',\n",
              " '{\"smiles\": \"CNC(C)CC(C)(C)O\", \"label\": 0.0, \"pred\": 0.5077990889549255}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)c1ccc(NC2CSCc3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.9130238890647888}\\n',\n",
              " '{\"smiles\": \"Cc1cc(=O)n2c(C(=O)Nc3ccc(I)cc3)c(C(=O)Nc3ccccc3)sc2n1\", \"label\": 0.0, \"pred\": 0.7772728800773621}\\n',\n",
              " '{\"smiles\": \"CCCCNS(=O)(=O)c1cn(Cc2ccccc2)nc1-c1cccs1\", \"label\": 0.0, \"pred\": 1.4858360290527344}\\n',\n",
              " '{\"smiles\": \"CN1CCN([C@@H]2COC[C@H]2N(C)C)CC1\", \"label\": 0.0, \"pred\": 0.12471790611743927}\\n',\n",
              " '{\"smiles\": \"C=CC[C@@H]1NC(=O)C(Oc2ccccc2)CCOC(=O)C/C=C/[C@@H](C)[C@@H](C2CC2)NC1=O\", \"label\": 0.0, \"pred\": 1.0467371940612793}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(Nc2nc(C)c(C(=O)NCCc3cccs3)s2)n1\", \"label\": 0.0, \"pred\": 0.8778315186500549}\\n',\n",
              " '{\"smiles\": \"CNCCCn1cncc1-c1ccc(Br)cc1\", \"label\": 0.0, \"pred\": 1.146822214126587}\\n',\n",
              " '{\"smiles\": \"COC[C@@H](C)NC(=O)N[C@@H]1CC(=O)N(c2cccc(F)c2)C1\", \"label\": 0.0, \"pred\": 1.0652521848678589}\\n',\n",
              " '{\"smiles\": \"CC(C(=O)O)[C@@H](O)CC#N\", \"label\": 0.0, \"pred\": 0.501951277256012}\\n',\n",
              " '{\"smiles\": \"CC(=O)Oc1ccc(NC2=CC(=O)c3ccccc3C2=O)c([N+](=O)[O-])c1\", \"label\": 0.0, \"pred\": 0.729033887386322}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(C(CNC(=O)c2cnn(-c3ccc(Br)cc3)c2C)N2CCOCC2)o1\", \"label\": 0.0, \"pred\": 0.7331628203392029}\\n',\n",
              " '{\"smiles\": \"O=Cc1nc2c(I)cc(Br)cn2c1Cl\", \"label\": 0.0, \"pred\": 0.6330271363258362}\\n',\n",
              " '{\"smiles\": \"CCc1oc(C(=O)N(C2CC2)C(C)c2ccccn2)cc1C\", \"label\": 0.0, \"pred\": 0.991247832775116}\\n',\n",
              " '{\"smiles\": \"CCOCCCc1nnc2n1CCNC2C\", \"label\": 0.0, \"pred\": 1.1547900438308716}\\n',\n",
              " '{\"smiles\": \"CNCCS(=O)(=O)c1ccc2cc(C)ccc2c1\", \"label\": 0.0, \"pred\": 1.0944980382919312}\\n',\n",
              " '{\"smiles\": \"C=CCCCCC=CC(=O)NCC1CCOCC1\", \"label\": 0.0, \"pred\": 0.5761985182762146}\\n',\n",
              " '{\"smiles\": \"Cc1cccc(Nc2cc(C)nc(Nc3ccc(C(C)C)cc3)n2)c1\", \"label\": 0.0, \"pred\": 0.8497185111045837}\\n',\n",
              " '{\"smiles\": \"CN1CCN(C)C(CNC(=O)N2CCN(C(=O)c3ccc(O)cc3)CC2)C1\", \"label\": 0.0, \"pred\": 0.7409133315086365}\\n',\n",
              " '{\"smiles\": \"CCCc1cc(-c2cccc3c2Cc2ccccc2-3)cc(CCC)c1OCCO\", \"label\": 0.0, \"pred\": 1.1624910831451416}\\n',\n",
              " '{\"smiles\": \"CC(C)(CC(=O)O)CC(=O)c1cc(F)cc(Cl)c1\", \"label\": 0.0, \"pred\": 0.502030074596405}\\n',\n",
              " '{\"smiles\": \"CC1CN(Cc2cccc(O)c2)CCCN1\", \"label\": 0.0, \"pred\": 0.684596598148346}\\n',\n",
              " '{\"smiles\": \"CC12CCC3c4c(-n5cnc6nc(N)[nH]c(=O)c65)cc(O)c(O)c4CCC3C1CCC2O\", \"label\": 0.0, \"pred\": 0.800128161907196}\\n',\n",
              " '{\"smiles\": \"CC(F)(F)c1cc(Oc2ccc(CNC(=O)C3(NC(=O)c4cncnc4)CC3)cc2)cc(C(F)(F)F)c1\", \"label\": 0.0, \"pred\": 0.9508954882621765}\\n',\n",
              " '{\"smiles\": \"NCC(N)CC(N)(N)CC(N)N\", \"label\": 0.0, \"pred\": 0.7844552397727966}\\n',\n",
              " '{\"smiles\": \"COC(=O)CC(C)Oc1cccc(S(C)(=O)=O)c1\", \"label\": 0.0, \"pred\": 0.833168089389801}\\n',\n",
              " '{\"smiles\": \"COc1ccc([C@H]2Nc3ccccc3C(=O)O2)cc1\", \"label\": 0.0, \"pred\": 0.7768072485923767}\\n',\n",
              " '{\"smiles\": \"CCc1ccccc1NC(=O)C1CC(=O)N(c2cc(C)c(Cl)cc2OC)C1\", \"label\": 0.0, \"pred\": 0.9221047759056091}\\n',\n",
              " '{\"smiles\": \"C[C@@H](C(=O)NCc1ccc(N2CCN(C)CC2)nc1)S(C)(=O)=O\", \"label\": 0.0, \"pred\": 1.0756111145019531}\\n',\n",
              " '{\"smiles\": \"O=C(c1nc(-c2cccs2)n(-c2ccccc2)n1)N1CCCN(c2ccc(F)cc2)CC1\", \"label\": 0.0, \"pred\": 0.7162372469902039}\\n',\n",
              " '{\"smiles\": \"CC1=CC(=O)CCC1(O)/C=C/C(C)=C\\\\\\\\C(=O)O\", \"label\": 0.0, \"pred\": 0.290693461894989}\\n',\n",
              " '{\"smiles\": \"O=C(Nc1ccc(F)cc1)C1CC1C(=O)NC1CCCC1\", \"label\": 0.0, \"pred\": 1.2551562786102295}\\n',\n",
              " '{\"smiles\": \"O=C(/C=C/c1ccc(-c2ccc(Br)cc2)o1)c1ccc(-c2ccccc2Cl)o1\", \"label\": 0.0, \"pred\": 1.1143931150436401}\\n',\n",
              " '{\"smiles\": \"Oc1cc(O)c(Br)c(C(F)(F)F)c1\", \"label\": 0.0, \"pred\": 1.0535047054290771}\\n',\n",
              " '{\"smiles\": \"O=C1C(=CNn2nccn2)C(=O)N(CCc2ccccc2)S(=O)(=O)N1CCc1ccccc1\", \"label\": 0.0, \"pred\": 1.1003544330596924}\\n',\n",
              " '{\"smiles\": \"CC1(C)CCC(C)(C)c2cc(-c3cc(-c4ccc(C(=O)O)cc4)ccc3OCCCCO[Si](C)(C)C(C)(C)C)ccc21\", \"label\": 0.0, \"pred\": 1.104099988937378}\\n',\n",
              " '{\"smiles\": \"Cc1nc(CN)cc(C(F)F)c1C=O\", \"label\": 0.0, \"pred\": 0.24274463951587677}\\n',\n",
              " '{\"smiles\": \"CC(C)C1C(=O)NCC(=O)N1c1ccc(Br)cc1Cl\", \"label\": 0.0, \"pred\": 0.8252696394920349}\\n',\n",
              " '{\"smiles\": \"COC(=O)c1cccc(C2NC(=O)NC(=O)C2C#N)c1\", \"label\": 0.0, \"pred\": 0.7123433947563171}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc3c(c2)C2(c4cc(N5c6ccccc6C(C)(C)c6ccccc65)ccc4-3)c3ccccc3S(=O)(=O)c3ccccc32)c2ccccc21\", \"label\": 0.0, \"pred\": 0.44031256437301636}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(-c2cc(C#N)c(-n3c4ccccc4c4ccccc43)cc2-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccccc32)cc1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": -0.1304347962141037}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)c1cc(C)ccc1n2-c1cccc(-n2c3ccc(C)cc3c3cc(C)ccc32)c1C#N\", \"label\": 0.0, \"pred\": -0.10480646789073944}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1cccc(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c1C#N\", \"label\": 0.0, \"pred\": 0.23058290779590607}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2c(-c3ccc(C#N)cc3)cc(C#N)cc2-c2ccc(C#N)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": 0.7846586108207703}\\n',\n",
              " '{\"smiles\": \"N#Cc1ccc(-c2cc(C#N)cc(-c3ccc(C#N)cc3)c2N2c3ccccc3C3(c4ccccc4-c4ccccc43)c3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.4408642649650574}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc2c3cc(-n4c5ccccc5c5ccccc54)ccc3n3c4ccc(-n5c6ccccc6c6ccccc65)cc4c(c1)c23\", \"label\": 0.0, \"pred\": 0.18560905754566193}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1ccc2c(c1)c1cc(C#N)cc3c4cc(-n5c6ccc(C(C)(C)C)cc6c6cc(C(C)(C)C)ccc65)ccc4n2c13\", \"label\": 0.0, \"pred\": 0.4179760813713074}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccc(-c4ccccc4)cc3c3cc(-c4ccccc4)ccc32)cc(-n2c3ccc(-c4ccccc4)cc3c3cc(-c4ccccc4)ccc32)c1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.7427985072135925}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1cc(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c(-n2c3ccccc3c3ccccc32)c(C#N)c1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.216687873005867}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)cc(-c2ccc(-n3c4ccccc4c4ccccc43)c(C#N)c2-n2c3ccccc3c3ccccc32)cc1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": -0.037518784403800964}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)C(c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1ccc2c(c1)Sc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.22542734444141388}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)C(c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1ccc2c(c1)Oc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.21718712151050568}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)C(c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1ccc2c(c1)N(c1ccccc1)c1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.21078939735889435}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)C(c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1cc(C(C)C)c(B2c3ccccc3Sc3ccccc32)c(C(C)C)c1\", \"label\": 0.0, \"pred\": 0.3286721110343933}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)[Si](c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1ccc2c(c1)Sc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.1251184493303299}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)[Si]1(c3ccccc3-c3ccccc31)c1cc(C)ccc1N2c1ccc2c(c1)Sc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.33671778440475464}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)[Ge](c1ccccc1)(c1ccccc1)c1cc(C)ccc1N2c1ccc2c(c1)Sc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.18506784737110138}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c2c(c1)c1cc(C)cc(C)c1n2-c1ccc2c(c1)Sc1ccccc1B2c1c(C(C)C)cc(C(C)C)cc1C(C)C\", \"label\": 0.0, \"pred\": 0.5402981638908386}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)B1c3cc(C(C)(C)C)ccc3Oc3cc(N4c5ccccc5C(C)(C)c5ccccc54)cc(c31)O2\", \"label\": 0.0, \"pred\": 0.057936862111091614}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)B1c3cc(C(C)(C)C)ccc3Oc3cc(-n4c5ccccc5c5c6c(c7ccccc7n6-c6ccccc6)c6c(c7ccccc7n6-c6ccccc6)c54)cc(c31)O2\", \"label\": 0.0, \"pred\": -0.1648877114057541}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c2c(c1)c1cc(C)cc(C)c1n2-c1cc2c3c(c1)Oc1ccccc1B3c1ccccc1O2\", \"label\": 0.0, \"pred\": 0.49764150381088257}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c2c(c1)c1cc(C)cc(C)c1n2-c1cc2c3c(c1)Oc1cc(-c4ccccc4)ccc1B3c1ccc(-c3ccccc3)cc1O2\", \"label\": 0.0, \"pred\": 0.4435955882072449}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1ccc(C(=O)c2ccc(-n3c4ccc(C(C)(C)C)cc4c4cc(C(C)(C)C)ccc43)nc2)cn1\", \"label\": 0.0, \"pred\": 0.37439364194869995}\\n',\n",
              " '{\"smiles\": \"CCCCCCn1c2ccc(-n3c4ccccc4c4ccccc43)cc2c(=O)c2cc(-n3c4ccccc4c4ccccc43)ccc21\", \"label\": 0.0, \"pred\": 0.2911297678947449}\\n',\n",
              " '{\"smiles\": \"c1ccc(N(c2ccccc2)c2ccc3c(c2)c2cccc4c5cc(N(c6ccccc6)c6ccccc6)ccc5n3c24)cc1\", \"label\": 0.0, \"pred\": 0.18327446281909943}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc3c(c2)c2cccc4c5cc(N6c7ccccc7C(C)(C)c7ccccc76)ccc5n3c24)c2ccccc21\", \"label\": 0.0, \"pred\": -0.12337617576122284}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccccc2)c2ccc(C(=O)c3ccc4c(c3)C(C)(C)c3ccccc3N4c3ccccc3)cc21\", \"label\": 0.0, \"pred\": 0.4306733012199402}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccccc2)c2ccc(-c3ccc(C(=O)c4ccc(-c5ccc6c(c5)C(C)(C)c5ccccc5N6c5ccccc5)cc4)cc3)cc21\", \"label\": 0.0, \"pred\": 0.40091198682785034}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccccc2)c2ccc(-c3nc(-c4ccccc4)nc(-c4ccccc4)n3)cc21\", \"label\": 0.0, \"pred\": 0.22476668655872345}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)c1cc(-c2ccc(-n3c4ccccc4c4ccccc43)cc2)cc(C(F)(F)F)c1\", \"label\": 0.0, \"pred\": 0.5806211829185486}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)c1ncc(-c2ccc(-n3c4ccccc4c4ccccc43)cc2)cn1\", \"label\": 0.0, \"pred\": 0.33754628896713257}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)c1ccc(-c2ccc(-n3c4ccccc4c4ccccc43)cc2)c(C(F)(F)F)n1\", \"label\": 0.0, \"pred\": 0.4782969355583191}\\n',\n",
              " '{\"smiles\": \"FC(F)(F)c1cc(-c2ccc(-n3c4ccccc4c4ccccc43)cc2)cc(C(F)(F)F)n1\", \"label\": 0.0, \"pred\": 0.3551623225212097}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc(N2c3ccc(C(C)(C)C)cc3B3c4cc(C(C)(C)C)ccc4N(c4ccc(C(C)(C)C)cc4)c4cc(-n5c6ccc(C(C)(C)C)cc6c6cc(C(C)(C)C)ccc65)cc2c43)cc1\", \"label\": 0.0, \"pred\": 0.1749989539384842}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(N2c3ccc(C)cc3B3c4cc(C)ccc4N4c5ccc(C)cc5B5c6cc(C)ccc6N(c6ccc(C)cc6)c6cc2c3c4c65)cc1\", \"label\": 0.0, \"pred\": 0.831591784954071}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)B1c3cc(C)ccc3N3c4ccc(C)cc4B4c5cc(C)ccc5N5c6ccc(C)cc6B6c7cc(C)ccc7N2c2c1c3c4c5c26\", \"label\": 0.0, \"pred\": 1.0178349018096924}\\n',\n",
              " '{\"smiles\": \"Cc1ccc2c(c1)B1c3cc(C)ccc3N3c4ccc(C)cc4B4c5cc(C)cc6c5N5c7c(cc(C)cc7B7c8cc(C)ccc8N2c2c1c3c4c5c27)B6O\", \"label\": 0.0, \"pred\": 1.043335199356079}\\n',\n",
              " '{\"smiles\": \"O=c1c2ccccc2n2c3ccc(-c4ccccc4)cc3c(=O)c3cccc1c32\", \"label\": 0.0, \"pred\": 0.8379983305931091}\\n',\n",
              " '{\"smiles\": \"O=c1c2ccccc2n2c3ccccc3c(=O)c3cc(-c4ccccc4)cc1c32\", \"label\": 0.0, \"pred\": 0.8497404456138611}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)cc3c1n2-c1cc(-c2ccccc2F)cc2c1B3c1cc(C(C)(C)C)cc3c4cc(C(C)(C)C)ccc4n-2c13\", \"label\": 0.0, \"pred\": 0.5967180132865906}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)cc3c1n2-c1cc(-c2cccc(F)c2)cc2c1B3c1cc(C(C)(C)C)cc3c4cc(C(C)(C)C)ccc4n-2c13\", \"label\": 0.0, \"pred\": 0.5545055270195007}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)cc3c1n2-c1cc(-c2ccc(F)cc2)cc2c1B3c1cc(C(C)(C)C)cc3c4cc(C(C)(C)C)ccc4n-2c13\", \"label\": 0.0, \"pred\": 0.6005489230155945}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc(N2c3ccc(C(C)(C)C)cc3B3c4cc(C(C)(C)C)ccc4N(c4ccc(C(C)(C)C)cc4)c4cccc2c43)cc1\", \"label\": 0.0, \"pred\": 0.21353788673877716}\\n',\n",
              " '{\"smiles\": \"c1ccc(N(c2ccccc2)c2cc3c4c(c2)N(c2ccccc2)c2cc5c(cc2B4c2ccccc2N3c2ccccc2)B2c3ccccc3N(c3ccccc3)c3cc(N(c4ccccc4)c4ccccc4)cc(c32)N5c2ccccc2)cc1\", \"label\": 0.0, \"pred\": -0.20640210807323456}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c(-c2ccc3c(c2)c(=O)c2cc(-c4c(C)cc(C)cc4C)cc4c(=O)c5cc(-c6c(C)cc(C)cc6C)ccc5n3c24)c(C)c1\", \"label\": 0.0, \"pred\": 0.5466670393943787}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc(-c2ccc3c(c2)c2cc(-c4ccc(C(C)(C)C)cc4)cc4c2n3-c2cccc3c2B4c2cc(-c4ccc(C(C)(C)C)cc4)cc4c5cc(-c6ccc(C(C)(C)C)cc6)ccc5n-3c24)cc1\", \"label\": 0.0, \"pred\": 0.6856505274772644}\\n',\n",
              " '{\"smiles\": \"O=c1c2ccccc2n2c3ccc(-c4ccc5c(c4)c(=O)c4cccc6c(=O)c7ccccc7n5c64)cc3c(=O)c3cccc1c32\", \"label\": 0.0, \"pred\": 0.8764387965202332}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)nc(-n2c3ccccc3c3ccccc32)c(C#N)c1-c1ccccc1\", \"label\": 0.0, \"pred\": 0.4258853793144226}\\n',\n",
              " '{\"smiles\": \"N#Cc1ccc2c(c1)C1(c3cc(C#N)ccc3-2)c2ccccc2N(c2ccccc2)c2ccccc21\", \"label\": 0.0, \"pred\": 0.4425639510154724}\\n',\n",
              " '{\"smiles\": \"Cc1ccc(N(c2ccc(C)cc2)c2ccc3c(c2)C2(c4cc(C#N)ccc4-c4ccc(C#N)cc42)c2cc(N(c4ccc(C)cc4)c4ccc(C)cc4)ccc2-3)cc1\", \"label\": 0.0, \"pred\": 0.40529173612594604}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)c(F)c(-n2c3ccccc3c3ccccc32)c(F)c1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.3321377635002136}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)c(F)c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccccc32)c1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.12570162117481232}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(C#N)c(-n2c3ccccc3c3c(-c4cccc5c4c4ccccc4n5-c4cc(-n5c6ccccc6c6ccccc65)c(C#N)cc4C#N)cccc32)cc1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": -0.049190327525138855}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(C#N)cc(-n2c3ccccc3c3cc(-c4ccc5c(c4)c4ccccc4n5-c4cc(C#N)cc(C#N)c4)ccc32)c1\", \"label\": 0.0, \"pred\": 0.1925615817308426}\\n',\n",
              " '{\"smiles\": \"N#Cc1cccc(C#N)c1-n1c2ccccc2c2cc(-c3ccc4c(c3)c3ccccc3n4-c3c(C#N)cccc3C#N)ccc21\", \"label\": 0.0, \"pred\": 0.6378516554832458}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1cc(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c(C#N)c1-n1c2ccc(C(C)(C)C)cc2c2cc(C(C)(C)C)ccc21\", \"label\": 0.0, \"pred\": -0.059833332896232605}\\n',\n",
              " '{\"smiles\": \"O=C(c1ccc(-n2c3ccccc3c3ccccc32)cc1)c1ccc(-n2c3ccccc3c3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.48633164167404175}\\n',\n",
              " '{\"smiles\": \"O=C(c1ccncc1)c1cc(-n2c3ccccc3c3ccccc32)cc(-n2c3ccccc3c3ccccc32)c1\", \"label\": 0.0, \"pred\": 0.07003851234912872}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc(-c3nc(C#N)c(C#N)nc3-c3ccc(N4c5ccccc5C(C)(C)c5ccccc54)cc3)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": -0.0060823410749435425}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3ccc(N4c5ccccc5[Si](c5ccccc5)(c5ccccc5)c5ccccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.026960089802742004}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(C#N)c(-n2c3ccccc3c3cc(-c4ccc5c(c4)c4ccccc4n5-c4cc(-n5c6ccccc6c6ccccc65)c(C#N)cc4C#N)ccc32)cc1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.09459467232227325}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(N2c3ccccc3Oc3ccccc32)c(N2c3ccccc3Oc3ccccc32)cc1C#N\", \"label\": 0.0, \"pred\": 0.291179358959198}\\n',\n",
              " '{\"smiles\": \"CC(C)c1cc(C(C)C)c(B2c3ccccc3Oc3cc(N4c5ccccc5C(C)(C)c5ccccc54)ccc32)c(C(C)C)c1\", \"label\": 0.0, \"pred\": 0.11301679909229279}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2-c2cc3c(cc21)N(c1ccc(-c2nc(-c4ccccc4)nc(-c4ccccc4)n2)cc1)c1ccccc1C3(C)C\", \"label\": 0.0, \"pred\": 0.47719401121139526}\\n',\n",
              " '{\"smiles\": \"O=S(=O)(c1ccc(N2c3ccccc3N(c3ccccc3)c3ccccc32)cc1)c1ccc(N2c3ccccc3N(c3ccccc3)c3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.15388841927051544}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1ccc(S(=O)(=O)c2cccc(S(=O)(=O)c3ccc(-n4c5ccc(C(C)(C)C)cc5c5cc(C(C)(C)C)ccc54)cc3)c2)cc1\", \"label\": 0.0, \"pred\": 0.49777716398239136}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3ccc(N(c4ccc(N(c5ccccc5)c5ccccc5)cc4)c4ccc(N(c5ccccc5)c5ccccc5)cc4)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.1252882033586502}\\n',\n",
              " '{\"smiles\": \"Cc1cc(C)c(B(c2c(C)cc(C)cc2C)c2c(C)cc(-n3c4ccc(N(c5ccccc5)c5ccccc5)cc4c4cc(N(c5ccccc5)c5ccccc5)ccc43)cc2C)c(C)c1\", \"label\": 0.0, \"pred\": 0.4477950930595398}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc(-c3nc(-c4ccc(N5c6ccccc6C(C)(C)c6ccccc65)cc4)nc(-c4ccc(N5c6ccccc6C(C)(C)c6ccccc65)cc4)n3)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": -0.2879202961921692}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-n3c4ccccc4c4cc5c6ccccc6n(-c6ccccc6)c5cc43)nc(-n3c4ccccc4c4cc5c6ccccc6n(-c6ccccc6)c5cc43)n2)cc1\", \"label\": 0.0, \"pred\": 0.44534605741500854}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3ccc(-n4c5ccccc5c5cc(-n6c7ccccc7c7ccccc76)ccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.21161861717700958}\\n',\n",
              " '{\"smiles\": \"N#Cc1ccc2c(c1)C1(c3cc(C#N)ccc3-2)c2ccccc2N2c3ccccc3Oc3cccc1c32\", \"label\": 0.0, \"pred\": 0.35065335035324097}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccc(-n4c5ccccc5c5cc(-c6ccc7c(c6)c6ccccc6n7-c6ccccc6)ccc54)cc3)nc(-c3ccc(-n4c5ccccc5c5cc(-c6ccc7c(c6)c6ccccc6n7-c6ccccc6)ccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.0018069297075271606}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3cccc(-n4c5ccccc5c5c6oc7ccccc7c6ccc54)c3)n2)cc1\", \"label\": 0.0, \"pred\": 0.5826355814933777}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3ccc(-n4c5ccccc5c5c6oc7ccccc7c6ccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.5194217562675476}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc(C(=O)c3ccc(N4c5ccccc5C(C)(C)c5ccccc54)cc3)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": -0.044209763407707214}\\n',\n",
              " '{\"smiles\": \"CC(C)(C)c1ccc2c(c1)c1cc(C(C)(C)C)ccc1n2-c1c(C#N)c(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c(-n2c3ccc(C(C)(C)C)cc3c3cc(C(C)(C)C)ccc32)c1C#N\", \"label\": 0.0, \"pred\": -0.04897241294384003}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(-n2c3ccccc3c3c4oc5ccccc5c4ccc32)c(-n2c3ccccc3c3c4oc5ccccc5c4ccc32)cc1C#N\", \"label\": 0.0, \"pred\": 0.8243305087089539}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(-n2c3ccccc3c3c4sc5ccccc5c4ccc32)c(-n2c3ccccc3c3c4sc5ccccc5c4ccc32)cc1C#N\", \"label\": 0.0, \"pred\": 0.7041146159172058}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc(-c3cc(C#N)c(C#N)cc3-c3ccc(N4c5ccccc5C(C)(C)c5ccccc54)cc3)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": 0.30373162031173706}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(-c2ccc(N3c4ccccc4Oc4ccccc43)cc2)c(-c2ccc(N3c4ccccc4Oc4ccccc43)cc2)cc1C#N\", \"label\": 0.0, \"pred\": 0.11954469978809357}\\n',\n",
              " '{\"smiles\": \"N#Cc1cc(C#N)cc(-n2c3ccc(-n4c5ccccc5c5ccccc54)cc3c3cc(-n4c5ccccc5c5ccccc54)ccc32)c1\", \"label\": 0.0, \"pred\": 0.11489696800708771}\\n',\n",
              " '{\"smiles\": \"N#Cc1ccc(N2c3ccccc3N(c3ccc(C#N)cc3)c3ccccc32)cc1\", \"label\": 0.0, \"pred\": 0.3258017897605896}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-n3c4ccccc4c4ccc5c(c6ccccc6n5-c5ccccc5)c43)n2)cc1\", \"label\": 0.0, \"pred\": 0.4390046000480652}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccc(N4c5ccccc5Oc5ccccc54)cc3)nc(-c3ccc(N4c5ccccc5Oc5ccccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": -0.2841952443122864}\\n',\n",
              " '{\"smiles\": \"c1ccc(-c2nc(-c3ccccc3)nc(-c3ccc(N4c5ccccc5Sc5ccccc54)cc3)n2)cc1\", \"label\": 0.0, \"pred\": 0.03668256103992462}\\n',\n",
              " '{\"smiles\": \"C1=c2c(n(-c3ccc4c(c3)c3cc(-n5c6ccccc6c6ccccc65)ccc3n4-c3ccc(-c4nc(-c5ccc(-n6c7ccc(-n8c9ccccc9c9ccccc98)cc7c7cc(-n8c9ccccc9c9ccccc98)ccc76)cc5)nc(-c5ccc(-n6c7ccc(-n8c9ccccc9c9ccccc98)cc7c7cc(-n8c9ccccc9c9ccccc98)ccc76)cc5)n4)cc3)c3ccccc23)=CCC1\", \"label\": 0.0, \"pred\": -0.8540356755256653}\\n',\n",
              " '{\"smiles\": \"C1=c2c(n(-c3ccc4c(c3)c3cc(-n5c6ccccc6c6ccccc65)ccc3n4-c3ccc4c(c3)c3cc(-n5c6ccc(-n7c8ccccc8c8ccccc87)cc6c6cc(-n7c8ccccc8c8ccccc87)ccc65)ccc3n4-c3ccc(-c4nc(-c5ccc(-n6c7ccc(-n8c9ccc(-n%10c%11c(c%12ccccc%12%10)=CCCC=%11)cc9c9cc(-n%10c%11ccccc%11c%11ccccc%11%10)ccc98)cc7c7cc(-n8c9ccc(-n%10c%11ccccc%11c%11ccccc%11%10)cc9c9cc(-n%10c%11ccccc%11c%11ccccc%11%10)ccc98)ccc76)cc5)nc(-c5ccc(-n6c7ccc(-n8c9ccc(-n%10c%11c(c%12ccccc%12%10)=CCCC=%11)cc9c9cc(-n%10c%11ccccc%11c%11ccccc%11%10)ccc98)cc7c7cc(-n8c9ccc(-n%10c%11ccccc%11c%11ccccc%11%10)cc9c9cc(-n%10c%11ccccc%11c%11ccccc%11%10)ccc98)ccc76)cc5)n4)cc3)c3ccccc23)=CCC1\", \"label\": 0.0, \"pred\": -2.4697296619415283}\\n',\n",
              " '{\"smiles\": \"c1ccc2c(c1)Oc1ccccc1N2c1ccc2c(c1)c1cc(N3c4ccccc4Oc4ccccc43)ccc1c1nccnc21\", \"label\": 0.0, \"pred\": -0.21330194175243378}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc3c(c2)c2cc(N4c5ccccc5C(C)(C)c5ccccc54)ccc2c2nccnc32)c2ccccc21\", \"label\": 0.0, \"pred\": -0.057606980204582214}\\n',\n",
              " '{\"smiles\": \"c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2cnc3ccccc3n2)cc1\", \"label\": 0.0, \"pred\": 0.28990429639816284}\\n',\n",
              " '{\"smiles\": \"c1ccc(N(c2ccccc2)c2ccc3c(c2)c2cc(N(c4ccccc4)c4ccccc4)ccc2n3-c2ccc(-c3cnc4ccccc4n3)cc2)cc1\", \"label\": 0.0, \"pred\": 0.24684448540210724}\\n',\n",
              " '{\"smiles\": \"c1ccc(N2c3ccccc3C3(c4ccccc42)c2cccnc2-c2ncccc23)cc1\", \"label\": 0.0, \"pred\": 0.03480692207813263}\\n',\n",
              " '{\"smiles\": \"c1ccc(N(c2ccccc2)c2ccc3c(c2)C2(c4cc(N(c5ccccc5)c5ccccc5)ccc4N3c3ccccc3)c3cccnc3-c3ncccc32)cc1\", \"label\": 0.0, \"pred\": -0.14852742850780487}\\n',\n",
              " '{\"smiles\": \"N#Cc1c(-n2c3ccccc3c3ccccc32)c(-n2c3ccccc3c3ccccc32)nc(-n2c3ccccc3c3ccccc32)c1-n1c2ccccc2c2ccccc21\", \"label\": 0.0, \"pred\": 0.21603937447071075}\\n',\n",
              " '{\"smiles\": \"CC1(C)c2ccccc2N(c2ccc(-c3cc(-c4ccc(N5c6ccccc6C(C)(C)c6ccccc65)cc4)ncn3)cc2)c2ccccc21\", \"label\": 0.0, \"pred\": 0.2946445345878601}\\n',\n",
              " '{\"smiles\": \"Cc1nc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)cc(-c2ccc(N3c4ccccc4C(C)(C)c4ccccc43)cc2)n1\", \"label\": 0.0, \"pred\": 0.30342596769332886}\\n',\n",
              " '{\"smiles\": \"c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3ccccc3s2)cc1\", \"label\": 0.0, \"pred\": 0.43030327558517456}\\n',\n",
              " '{\"smiles\": \"c1ccc2c(c1)Oc1ccccc1N2c1ccc(-c2nc3cc4sc(-c5ccc(N6c7ccccc7Oc7ccccc76)cc5)nc4cc3s2)cc1\", \"label\": 0.0, \"pred\": 0.06262274086475372}\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKlNKq9r3plG"
      },
      "source": [
        "for x in range(len(results)):\n",
        "  if results[x]['smiles'] != test_data['SMILES'][x]:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTqHu8E5Ukc"
      },
      "source": [
        "sample_submission['ST1_GAP(eV)'] = sample_submission['ST1_GAP(eV)'].astype('float')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McR03gz43Sjq",
        "outputId": "3a16267a-1ee2-4add-8fa3-09dcc4fa4b70"
      },
      "source": [
        "for x in range(len(results)): \n",
        "  if results[x]['pred'] >= 0:\n",
        "    sample_submission['ST1_GAP(eV)'][x] = results[x]['pred']\n",
        "  else:\n",
        "    sample_submission['ST1_GAP(eV)'][x] = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "yvE2Q_Sx5JWt",
        "outputId": "7d8ded8d-cee0-46ba-9fd3-599e37e6bf6e"
      },
      "source": [
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>ST1_GAP(eV)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_0</td>\n",
              "      <td>0.841114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_1</td>\n",
              "      <td>1.884196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_2</td>\n",
              "      <td>1.193880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test_3</td>\n",
              "      <td>1.017924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test_4</td>\n",
              "      <td>1.018836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>test_597</td>\n",
              "      <td>0.079643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>test_598</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>test_599</td>\n",
              "      <td>0.003348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>test_600</td>\n",
              "      <td>0.484055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>test_601</td>\n",
              "      <td>0.234786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>602 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          uid  ST1_GAP(eV)\n",
              "0      test_0     0.841114\n",
              "1      test_1     1.884196\n",
              "2      test_2     1.193880\n",
              "3      test_3     1.017924\n",
              "4      test_4     1.018836\n",
              "..        ...          ...\n",
              "597  test_597     0.079643\n",
              "598  test_598     0.000000\n",
              "599  test_599     0.003348\n",
              "600  test_600     0.484055\n",
              "601  test_601     0.234786\n",
              "\n",
              "[602 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ABTCgeO51zm"
      },
      "source": [
        "sample_submission.to_csv(directory+'result_new_new_0.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQvp5tpG3Htq"
      },
      "source": [
        "sub3 = pd.read_csv(directory+'result_0.csv')\n",
        "sub1 = pd.read_csv(directory+'result_old_0.csv')\n",
        "sub2 = pd.read_csv(directory+'result_old_old_0.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh4tdEaD3Si-"
      },
      "source": [
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUacSOP3Owt"
      },
      "source": [
        "mom = copy.deepcopy(sample_submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvOEFPs83W_O"
      },
      "source": [
        "mom['ST1_GAP(eV)'] = (sub1['ST1_GAP(eV)']+sub2['ST1_GAP(eV)']+sub3['ST1_GAP(eV)']+sample_submission['ST1_GAP(eV)'])/3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M79JvLEI3uth",
        "outputId": "250f5e19-da0a-4f1f-f7df-98cf74b6b2da"
      },
      "source": [
        "mom['ST1_GAP(eV)'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2310205300649006"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnLC-zNS3mhw",
        "outputId": "7c273d17-091c-433a-8fe7-6cf589f4eb31"
      },
      "source": [
        "\n",
        "sub2['ST1_GAP(eV)'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7835195064544678"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRmp8Z_63xYo"
      },
      "source": [
        "mom.to_csv(directory+'result_newww_0.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "W7CHJJpS6pVK",
        "outputId": "12611e20-d9ed-44f7-9f7c-83546fbe5e74"
      },
      "source": [
        "data[data['s1_t1_gap']<=0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>S1_energy(eV)</th>\n",
              "      <th>T1_energy(eV)</th>\n",
              "      <th>s1_t1_gap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>train_378</td>\n",
              "      <td>C=C1NC(=S)C=CC1[C@@H]1O[C@H](CCP(=C)(C)C)[C@@H...</td>\n",
              "      <td>2.1578</td>\n",
              "      <td>2.1578</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>train_4808</td>\n",
              "      <td>CC(=O)N(C)CCN(C)C(=O)OCc1ccc(NCC(=O)OCCOCCc2cn...</td>\n",
              "      <td>2.8607</td>\n",
              "      <td>2.8607</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9978</th>\n",
              "      <td>train_9978</td>\n",
              "      <td>O=C(O)CC(CS(=O)(=O)c1ccccc1)NC(=O)C1CC(CCCCNc2...</td>\n",
              "      <td>3.6282</td>\n",
              "      <td>3.6282</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16554</th>\n",
              "      <td>train_16554</td>\n",
              "      <td>COc1ccc(CCNC(=O)COC(=O)C(C(C)C)N2C(=O)c3ccccc3...</td>\n",
              "      <td>3.4715</td>\n",
              "      <td>3.4715</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26247</th>\n",
              "      <td>train_26247</td>\n",
              "      <td>COc1ccc(N(CC(=O)NCc2ccccc2-n2ccnc2C)S(=O)(=O)c...</td>\n",
              "      <td>3.0881</td>\n",
              "      <td>3.0881</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               uid  ... s1_t1_gap\n",
              "378      train_378  ...       0.0\n",
              "4808    train_4808  ...       0.0\n",
              "9978    train_9978  ...       0.0\n",
              "16554  train_16554  ...       0.0\n",
              "26247  train_26247  ...       0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAX5ggo55tkA",
        "outputId": "9ba73456-1085-4075-a11d-e39846aa66b1"
      },
      "source": [
        "results[601]['pred']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.09035389125347137"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ]
}